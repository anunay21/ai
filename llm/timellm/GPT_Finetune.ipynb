{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27550940-538f-428c-8fd7-166ddd82a9f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# uploaded data to:\n",
    "# training dataset to: s3://sagemaker-ap-south-1-179750807597/processed/samsum-sagemaker/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a452105-0f35-46df-9eec-a9b48624600c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/homebrew/lib/python3.11/site-packages (4.33.3)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.11/site-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /opt/homebrew/lib/python3.11/site-packages (from transformers) (0.17.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/homebrew/lib/python3.11/site-packages (from transformers) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/lib/python3.11/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/homebrew/lib/python3.11/site-packages (from transformers) (2023.8.8)\n",
      "Requirement already satisfied: requests in /opt/homebrew/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/homebrew/lib/python3.11/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/homebrew/lib/python3.11/site-packages (from transformers) (0.3.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/homebrew/lib/python3.11/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.11/site-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.11/site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: datasets in /opt/homebrew/lib/python3.11/site-packages (2.14.5)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/homebrew/lib/python3.11/site-packages (from datasets) (1.26.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/homebrew/lib/python3.11/site-packages (from datasets) (13.0.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/homebrew/lib/python3.11/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /opt/homebrew/lib/python3.11/site-packages (from datasets) (2.1.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/homebrew/lib/python3.11/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/homebrew/lib/python3.11/site-packages (from datasets) (4.66.1)\n",
      "Requirement already satisfied: xxhash in /opt/homebrew/lib/python3.11/site-packages (from datasets) (3.3.0)\n",
      "Requirement already satisfied: multiprocess in /opt/homebrew/lib/python3.11/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /opt/homebrew/lib/python3.11/site-packages (from datasets) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in /opt/homebrew/lib/python3.11/site-packages (from datasets) (3.8.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /opt/homebrew/lib/python3.11/site-packages (from datasets) (0.17.3)\n",
      "Requirement already satisfied: packaging in /opt/homebrew/lib/python3.11/site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/lib/python3.11/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp->datasets) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.8.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/lib/python3.11/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.11/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/homebrew/lib/python3.11/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: py7zr in /opt/homebrew/lib/python3.11/site-packages (0.20.6)\n",
      "Requirement already satisfied: texttable in /opt/homebrew/lib/python3.11/site-packages (from py7zr) (1.6.7)\n",
      "Requirement already satisfied: pycryptodomex>=3.6.6 in /opt/homebrew/lib/python3.11/site-packages (from py7zr) (3.19.0)\n",
      "Requirement already satisfied: pyzstd>=0.14.4 in /opt/homebrew/lib/python3.11/site-packages (from py7zr) (0.15.9)\n",
      "Requirement already satisfied: pyppmd<1.1.0,>=0.18.1 in /opt/homebrew/lib/python3.11/site-packages (from py7zr) (1.0.0)\n",
      "Requirement already satisfied: pybcj>=0.6.0 in /opt/homebrew/lib/python3.11/site-packages (from py7zr) (1.0.1)\n",
      "Requirement already satisfied: multivolumefile>=0.2.3 in /opt/homebrew/lib/python3.11/site-packages (from py7zr) (0.2.3)\n",
      "Requirement already satisfied: brotli>=1.0.9 in /opt/homebrew/lib/python3.11/site-packages (from py7zr) (1.1.0)\n",
      "Requirement already satisfied: inflate64>=0.3.1 in /opt/homebrew/lib/python3.11/site-packages (from py7zr) (0.3.1)\n",
      "Requirement already satisfied: psutil in /opt/homebrew/lib/python3.11/site-packages (from py7zr) (5.9.5)\n",
      "Requirement already satisfied: sagemaker in /opt/homebrew/lib/python3.11/site-packages (2.188.0)\n",
      "Requirement already satisfied: attrs<24,>=23.1.0 in /opt/homebrew/lib/python3.11/site-packages (from sagemaker) (23.1.0)\n",
      "Requirement already satisfied: boto3<2.0,>=1.26.131 in /opt/homebrew/lib/python3.11/site-packages (from sagemaker) (1.28.57)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /opt/homebrew/lib/python3.11/site-packages (from sagemaker) (2.2.1)\n",
      "Requirement already satisfied: google-pasta in /opt/homebrew/lib/python3.11/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /opt/homebrew/lib/python3.11/site-packages (from sagemaker) (1.26.0)\n",
      "Requirement already satisfied: protobuf<5.0,>=3.12 in /opt/homebrew/lib/python3.11/site-packages (from sagemaker) (4.24.3)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/homebrew/lib/python3.11/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /opt/homebrew/lib/python3.11/site-packages (from sagemaker) (6.8.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/lib/python3.11/site-packages (from sagemaker) (23.1)\n",
      "Requirement already satisfied: pandas in /opt/homebrew/lib/python3.11/site-packages (from sagemaker) (2.1.1)\n",
      "Requirement already satisfied: pathos in /opt/homebrew/lib/python3.11/site-packages (from sagemaker) (0.3.1)\n",
      "Requirement already satisfied: schema in /opt/homebrew/lib/python3.11/site-packages (from sagemaker) (0.7.5)\n",
      "Requirement already satisfied: PyYAML~=6.0 in /opt/homebrew/lib/python3.11/site-packages (from sagemaker) (6.0.1)\n",
      "Requirement already satisfied: jsonschema in /opt/homebrew/lib/python3.11/site-packages (from sagemaker) (4.19.1)\n",
      "Requirement already satisfied: platformdirs in /opt/homebrew/lib/python3.11/site-packages (from sagemaker) (3.10.0)\n",
      "Requirement already satisfied: tblib==1.7.0 in /opt/homebrew/lib/python3.11/site-packages (from sagemaker) (1.7.0)\n",
      "Requirement already satisfied: botocore<1.32.0,>=1.31.57 in /opt/homebrew/lib/python3.11/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (1.31.57)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/homebrew/lib/python3.11/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.8.0,>=0.7.0 in /opt/homebrew/lib/python3.11/site-packages (from boto3<2.0,>=1.26.131->sagemaker) (0.7.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/homebrew/lib/python3.11/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker) (3.17.0)\n",
      "Requirement already satisfied: six in /opt/homebrew/lib/python3.11/site-packages (from google-pasta->sagemaker) (1.16.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/homebrew/lib/python3.11/site-packages (from jsonschema->sagemaker) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/homebrew/lib/python3.11/site-packages (from jsonschema->sagemaker) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/homebrew/lib/python3.11/site-packages (from jsonschema->sagemaker) (0.10.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/lib/python3.11/site-packages (from pandas->sagemaker) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.11/site-packages (from pandas->sagemaker) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/homebrew/lib/python3.11/site-packages (from pandas->sagemaker) (2023.3)\n",
      "Requirement already satisfied: ppft>=1.7.6.7 in /opt/homebrew/lib/python3.11/site-packages (from pathos->sagemaker) (1.7.6.7)\n",
      "Requirement already satisfied: dill>=0.3.7 in /opt/homebrew/lib/python3.11/site-packages (from pathos->sagemaker) (0.3.7)\n",
      "Requirement already satisfied: pox>=0.3.3 in /opt/homebrew/lib/python3.11/site-packages (from pathos->sagemaker) (0.3.3)\n",
      "Requirement already satisfied: multiprocess>=0.70.15 in /opt/homebrew/lib/python3.11/site-packages (from pathos->sagemaker) (0.70.15)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /opt/homebrew/lib/python3.11/site-packages (from schema->sagemaker) (21.6.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/homebrew/lib/python3.11/site-packages (from botocore<1.32.0,>=1.31.57->boto3<2.0,>=1.26.131->sagemaker) (1.26.16)\n",
      "Collecting langchain\n",
      "  Obtaining dependency information for langchain from https://files.pythonhosted.org/packages/ab/75/262c3e01208c27068144eb76bdf668fad8be97283febaa44f9395ece288b/langchain-0.0.305-py3-none-any.whl.metadata\n",
      "  Downloading langchain-0.0.305-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (6.0.1)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Obtaining dependency information for SQLAlchemy<3,>=1.4 from https://files.pythonhosted.org/packages/ff/b6/fccd627d09045033defba0969b44bb4fc11475846b9ad59f6c5fa5ac23b8/SQLAlchemy-2.0.21-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading SQLAlchemy-2.0.21-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (3.8.5)\n",
      "Collecting anyio<4.0 (from langchain)\n",
      "  Obtaining dependency information for anyio<4.0 from https://files.pythonhosted.org/packages/19/24/44299477fe7dcc9cb58d0a57d5a7588d6af2ff403fdd2d47a246c91a3246/anyio-3.7.1-py3-none-any.whl.metadata\n",
      "  Downloading anyio-3.7.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
      "  Obtaining dependency information for dataclasses-json<0.7,>=0.5.7 from https://files.pythonhosted.org/packages/21/1f/1cff009cff64420572b9f75b70e4a054095719179a172297dfdd65843162/dataclasses_json-0.6.1-py3-none-any.whl.metadata\n",
      "  Downloading dataclasses_json-0.6.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
      "  Obtaining dependency information for jsonpatch<2.0,>=1.33 from https://files.pythonhosted.org/packages/73/07/02e16ed01e04a374e644b575638ec7987ae846d25ad97bcc9945a3ee4b0e/jsonpatch-1.33-py2.py3-none-any.whl.metadata\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langsmith<0.1.0,>=0.0.38 (from langchain)\n",
      "  Obtaining dependency information for langsmith<0.1.0,>=0.0.38 from https://files.pythonhosted.org/packages/70/31/4bd6640c0e2033849630fefe885430236948c91e3b501fae32705d5118dc/langsmith-0.0.41-py3-none-any.whl.metadata\n",
      "  Downloading langsmith-0.0.41-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting numexpr<3.0.0,>=2.8.4 (from langchain)\n",
      "  Obtaining dependency information for numexpr<3.0.0,>=2.8.4 from https://files.pythonhosted.org/packages/0a/89/1b180ac1a8e0ee81f497ff491cfe917173b0fe42b3ad77e4afdbf3d5aecc/numexpr-2.8.7-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading numexpr-2.8.7-cp311-cp311-macosx_11_0_arm64.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (1.26.0)\n",
      "Collecting pydantic<3,>=1 (from langchain)\n",
      "  Obtaining dependency information for pydantic<3,>=1 from https://files.pythonhosted.org/packages/73/66/0a72c9fcde42e5650c8d8d5c5c1873b9a3893018020c77ca8eb62708b923/pydantic-2.4.2-py3-none-any.whl.metadata\n",
      "  Downloading pydantic-2.4.2-py3-none-any.whl.metadata (158 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.6/158.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (2.31.0)\n",
      "Collecting tenacity<9.0.0,>=8.1.0 (from langchain)\n",
      "  Obtaining dependency information for tenacity<9.0.0,>=8.1.0 from https://files.pythonhosted.org/packages/f4/f1/990741d5bb2487d529d20a433210ffa136a367751e454214013b441c4575/tenacity-8.2.3-py3-none-any.whl.metadata\n",
      "  Downloading tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/homebrew/lib/python3.11/site-packages (from anyio<4.0->langchain) (3.4)\n",
      "Collecting sniffio>=1.1 (from anyio<4.0->langchain)\n",
      "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Obtaining dependency information for marshmallow<4.0.0,>=3.18.0 from https://files.pythonhosted.org/packages/ed/3c/cebfdcad015240014ff08b883d1c0c427f2ba45ae8c6572851b6ef136cad/marshmallow-3.20.1-py3-none-any.whl.metadata\n",
      "  Downloading marshmallow-3.20.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Obtaining dependency information for typing-inspect<1,>=0.4.0 from https://files.pythonhosted.org/packages/65/f3/107a22063bf27bdccf2024833d3445f4eea42b2e598abfbd46f6a63b6cb0/typing_inspect-0.9.0-py3-none-any.whl.metadata\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
      "  Obtaining dependency information for jsonpointer>=1.9 from https://files.pythonhosted.org/packages/12/f6/0232cc0c617e195f06f810534d00b74d2f348fe71b2118009ad8ad31f878/jsonpointer-2.4-py2.py3-none-any.whl.metadata\n",
      "  Downloading jsonpointer-2.4-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1->langchain)\n",
      "  Obtaining dependency information for annotated-types>=0.4.0 from https://files.pythonhosted.org/packages/d8/f0/a2ee543a96cc624c35a9086f39b1ed2aa403c6d355dfe47a11ee5c64a164/annotated_types-0.5.0-py3-none-any.whl.metadata\n",
      "  Downloading annotated_types-0.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting pydantic-core==2.10.1 (from pydantic<3,>=1->langchain)\n",
      "  Obtaining dependency information for pydantic-core==2.10.1 from https://files.pythonhosted.org/packages/8d/ab/baf66342f1d18228ed3e54a05308b967c3de3692517f3237c570447e6256/pydantic_core-2.10.1-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading pydantic_core-2.10.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/homebrew/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (4.8.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.11/site-packages (from requests<3,>=2->langchain) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Requirement already satisfied: packaging>=17.0 in /opt/homebrew/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.1)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Downloading langchain-0.0.305-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0mm\n",
      "\u001b[?25hDownloading anyio-3.7.1-py3-none-any.whl (80 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.9/80.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.1-py3-none-any.whl (27 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langsmith-0.0.41-py3-none-any.whl (39 kB)\n",
      "Downloading numexpr-2.8.7-cp311-cp311-macosx_11_0_arm64.whl (91 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.8/91.8 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.4.2-py3-none-any.whl (395 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.8/395.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.10.1-cp311-cp311-macosx_11_0_arm64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading SQLAlchemy-2.0.21-cp311-cp311-macosx_11_0_arm64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Downloading annotated_types-0.5.0-py3-none-any.whl (11 kB)\n",
      "Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
      "Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Installing collected packages: tenacity, SQLAlchemy, sniffio, pydantic-core, numexpr, mypy-extensions, marshmallow, jsonpointer, annotated-types, typing-inspect, pydantic, jsonpatch, anyio, langsmith, dataclasses-json, langchain\n",
      "Successfully installed SQLAlchemy-2.0.21 annotated-types-0.5.0 anyio-3.7.1 dataclasses-json-0.6.1 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.305 langsmith-0.0.41 marshmallow-3.20.1 mypy-extensions-1.0.0 numexpr-2.8.7 pydantic-2.4.2 pydantic-core-2.10.1 sniffio-1.3.0 tenacity-8.2.3 typing-inspect-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install transformers\n",
    "!pip3 install datasets\n",
    "!pip3 install py7zr\n",
    "!pip3 install sagemaker\n",
    "!pip3 install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80b9c2fa-09ec-4da9-8bb6-08c515846dd3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got exec role\n",
      "sagemaker role arn: arn:aws:iam::179750807597:role/service-role/SageMaker-LargeLanguageModel-2\n",
      "sagemaker bucket: sagemaker-ap-south-1-179750807597\n",
      "sagemaker session region: ap-south-1\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it does not exist\n",
    "sagemaker_session_bucket = None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "    print(\"got exec role\")\n",
    "except ValueError:\n",
    "    print(\"exception in getting execution role\")\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='AmazonSageMaker-ExecutionRole-20200630T104003')['Role']['Arn']\n",
    "    #role = iam.get_role(RoleName='SageMaker-LargeLanguageModel-2')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "514f657d-8db8-4f6b-9c0c-7975ebde3f7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "Downloading (…)okenizer_config.json: 100%|██████| 223/223 [00:00<00:00, 379kB/s]\n",
      "Downloading tokenizer.json: 100%|██████████| 14.5M/14.5M [00:02<00:00, 6.23MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|████| 85.0/85.0 [00:00<00:00, 159kB/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_id=\"bigscience/bloomz-7b1\"\n",
    "\n",
    "# Load tokenizer of BLOOMZ\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.model_max_length = 2048 # overwrite wrong value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3a26a192-cb88-4605-a255-2bc0e4626516",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"Summarize the chat dialogue:\\nTim: Hi, what's up?\\r\\nKim: Bad mood tbh, I was going to do lots of stuff but ended up procrastinating\\r\\nTim: What did you plan on doing?\\r\\nKim: Oh you know, uni stuff and unfucking my room\\r\\nKim: Maybe tomorrow I'll move my ass and do everything\\r\\nKim: We were going to defrost a fridge so instead of shopping I'll eat some defrosted veggies\\r\\nTim: For doing stuff I recommend Pomodoro technique where u use breaks for doing chores\\r\\nTim: It really helps\\r\\nKim: thanks, maybe I'll do that\\r\\nTim: I also like using post-its in kaban style\\n---\\nSummary:\\nKim may try the pomodoro technique recommended by Tim to get more stuff done.</s>\"}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff8e5e8a72344348b8f9ab7301f7b423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14732 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfd3a12de6394f75b46df1e7df2ccbbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14732 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids\n",
      "attention_mask\n",
      "input_ids\n",
      "attention_mask\n",
      "input_ids\n",
      "attention_mask\n",
      "input_ids\n",
      "attention_mask\n",
      "input_ids\n",
      "attention_mask\n",
      "input_ids\n",
      "attention_mask\n",
      "input_ids\n",
      "attention_mask\n",
      "input_ids\n",
      "attention_mask\n",
      "input_ids\n",
      "attention_mask\n",
      "input_ids\n",
      "attention_mask\n",
      "input_ids\n",
      "attention_mask\n",
      "input_ids\n",
      "attention_mask\n",
      "input_ids\n",
      "attention_mask\n",
      "input_ids\n",
      "attention_mask\n",
      "input_ids\n",
      "attention_mask\n",
      "Total number of samples: 1289\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "from itertools import chain\n",
    "from functools import partial\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"samsum\")\n",
    "train_dataset = dataset[\"train\"]\n",
    "# custom instruct prompt start\n",
    "prompt_template = f\"Summarize the chat dialogue:\\n{{dialogue}}\\n---\\nSummary:\\n{{summary}}{{eos_token}}\"\n",
    "\n",
    "# template dataset to add prompt to each sample\n",
    "def template_dataset(sample):\n",
    "    sample[\"text\"] = prompt_template.format(dialogue=sample[\"dialogue\"],\n",
    "                                            summary=sample[\"summary\"],\n",
    "                                            eos_token=tokenizer.eos_token)\n",
    "    return sample\n",
    "\n",
    "\n",
    "# apply prompt template per sample\n",
    "train_dataset = train_dataset.map(template_dataset, remove_columns={\"id\",\"dialogue\",\"summary\"})\n",
    "\n",
    "print(train_dataset[randint(0, len(dataset))])\n",
    "\n",
    "# empty list to save remainder from batches to use in next batch\n",
    "remainder = {\"input_ids\": [], \"attention_mask\": []}\n",
    "\n",
    "\n",
    "def chunk(sample, chunk_length=2048):\n",
    "    # define global remainder variable to save remainder from batches to use in next batch\n",
    "    global remainder\n",
    "    # Concatenate all texts and add remainder from previous batch\n",
    "    for k in sample.keys():\n",
    "        print(k)\n",
    "    concatenated_examples = {k: list(chain(*sample[k])) for k in sample.keys()}\n",
    "    concatenated_examples = {k: remainder[k] + concatenated_examples[k] for k in concatenated_examples.keys()}\n",
    "    # get total number of tokens for batch\n",
    "    batch_total_length = len(concatenated_examples[list(sample.keys())[0]])\n",
    "\n",
    "    # get max number of chunks for batch\n",
    "    if batch_total_length >= chunk_length:\n",
    "        batch_chunk_length = (batch_total_length // chunk_length) * chunk_length\n",
    "\n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i + chunk_length] for i in range(0, batch_chunk_length, chunk_length)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    # add remainder to global variable for next batch\n",
    "    remainder = {k: concatenated_examples[k][batch_chunk_length:] for k in concatenated_examples.keys()}\n",
    "    # prepare labels\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result\n",
    "\n",
    "\n",
    "# tokenize and chunk dataset\n",
    "lm_dataset = train_dataset.map(\n",
    "    lambda sample: tokenizer(sample[\"text\"]), batched=True,remove_columns={\"text\"}\n",
    ").map(\n",
    "    partial(chunk, chunk_length=2048),\n",
    "    batched=True,\n",
    ")\n",
    "\n",
    "# Print total number of samples\n",
    "print(f\"Total number of samples: {len(lm_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "46db461b-b28b-478f-a01e-09d52f87ea47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e8b57aa39fc40b2a62887f92b0a2284",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1289 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded data to:\n",
      "training dataset to: s3://sagemaker-ap-south-1-179750807597/processed/samsum-sagemaker/train\n"
     ]
    }
   ],
   "source": [
    "# save train_dataset to s3\n",
    "training_input_path = f's3://{sess.default_bucket()}/processed/samsum-sagemaker/train'\n",
    "lm_dataset.save_to_disk(training_input_path)\n",
    "\n",
    "print(\"uploaded data to:\")\n",
    "print(f\"training dataset to: {training_input_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6309388-99d8-47c8-88cf-307df8bb5f3d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'role' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 23\u001b[0m\n\u001b[1;32m      8\u001b[0m hyperparameters \u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m      9\u001b[0m   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_id\u001b[39m\u001b[38;5;124m'\u001b[39m: model_id,                                \u001b[38;5;66;03m# pre-trained model\u001b[39;00m\n\u001b[1;32m     10\u001b[0m   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset_path\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/opt/ml/input/data/training\u001b[39m\u001b[38;5;124m'\u001b[39m,       \u001b[38;5;66;03m# path where sagemaker will save training dataset\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m2e-4\u001b[39m,                                          \u001b[38;5;66;03m# learning rate used during training\u001b[39;00m\n\u001b[1;32m     14\u001b[0m }\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# create the Estimator\u001b[39;00m\n\u001b[1;32m     17\u001b[0m huggingface_estimator \u001b[38;5;241m=\u001b[39m HuggingFace(\n\u001b[1;32m     18\u001b[0m     entry_point          \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrun_clm.py\u001b[39m\u001b[38;5;124m'\u001b[39m,      \u001b[38;5;66;03m# train script\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     source_dir           \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/ec2-user/SageMaker/notebooks/sagemaker/24_train_bloom_peft_lora/scripts/\u001b[39m\u001b[38;5;124m'\u001b[39m,         \u001b[38;5;66;03m# directory which includes all the files needed for training\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     instance_type        \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mml.g5.2xlarge\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;66;03m# instances type used for the training job\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     instance_count       \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m,                 \u001b[38;5;66;03m# the number of instances used for training\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     base_job_name        \u001b[38;5;241m=\u001b[39m job_name,          \u001b[38;5;66;03m# the name of the training job\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m     role                 \u001b[38;5;241m=\u001b[39m \u001b[43mrole\u001b[49m,              \u001b[38;5;66;03m# IAM role used in training job to access AWS resources, e.g. S3\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     volume_size          \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m300\u001b[39m,               \u001b[38;5;66;03m# the size of the EBS volume in GB\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     transformers_version \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m4.26\u001b[39m\u001b[38;5;124m'\u001b[39m,            \u001b[38;5;66;03m# the transformers version used in the training job\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     pytorch_version      \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1.13\u001b[39m\u001b[38;5;124m'\u001b[39m,            \u001b[38;5;66;03m# the pytorch_version version used in the training job\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     py_version           \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpy39\u001b[39m\u001b[38;5;124m'\u001b[39m,            \u001b[38;5;66;03m# the python version used in the training job\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     hyperparameters      \u001b[38;5;241m=\u001b[39m  hyperparameters\n\u001b[1;32m     29\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'role' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# define Training Job Name \n",
    "job_name = f'huggingface-peft-{time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime())}'\n",
    "\n",
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "# hyperparameters, which are passed into the training job\n",
    "hyperparameters ={\n",
    "  'model_id': model_id,                                # pre-trained model\n",
    "  'dataset_path': '/opt/ml/input/data/training',       # path where sagemaker will save training dataset\n",
    "  'epochs': 3,                                         # number of training epochs\n",
    "  'per_device_train_batch_size': 1,                    # batch size for training\n",
    "  'lr': 2e-4,                                          # learning rate used during training\n",
    "}\n",
    "\n",
    "# create the Estimator\n",
    "huggingface_estimator = HuggingFace(\n",
    "    entry_point          = 'run_clm.py',      # train script\n",
    "    source_dir           = '/home/ec2-user/SageMaker/notebooks/sagemaker/24_train_bloom_peft_lora/scripts/',         # directory which includes all the files needed for training\n",
    "    instance_type        = 'ml.g5.2xlarge', # instances type used for the training job\n",
    "    instance_count       = 1,                 # the number of instances used for training\n",
    "    base_job_name        = job_name,          # the name of the training job\n",
    "    role                 = role,              # IAM role used in training job to access AWS resources, e.g. S3\n",
    "    volume_size          = 300,               # the size of the EBS volume in GB\n",
    "    transformers_version = '4.26',            # the transformers version used in the training job\n",
    "    pytorch_version      = '1.13',            # the pytorch_version version used in the training job\n",
    "    py_version           = 'py39',            # the python version used in the training job\n",
    "    hyperparameters      =  hyperparameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "188b5e2e-d7ac-47d4-b89c-adaed876d507",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: huggingface-peft-2023-08-09-02-23-03-2023-08-09-02-23-06-065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-09 02:23:06 Starting - Starting the training job...\n",
      "2023-08-09 02:23:24 Starting - Preparing the instances for training......\n",
      "2023-08-09 02:24:33 Downloading - Downloading input data\n",
      "2023-08-09 02:24:33 Training - Downloading the training image.....................\n",
      "2023-08-09 02:28:04 Training - Training image download completed. Training in progress.....\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2023-08-09 02:28:35,650 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2023-08-09 02:28:35,665 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-08-09 02:28:35,674 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2023-08-09 02:28:35,676 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2023-08-09 02:28:35,866 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.9 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting peft==0.3.0\u001b[0m\n",
      "\u001b[34mDownloading peft-0.3.0-py3-none-any.whl (56 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.8/56.8 kB 8.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting transformers==4.27.1\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.27.1-py3-none-any.whl (6.7 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.7/6.7 MB 97.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting accelerate==0.17.1\u001b[0m\n",
      "\u001b[34mDownloading accelerate-0.17.1-py3-none-any.whl (212 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 212.8/212.8 kB 49.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting bitsandbytes==0.37.1\u001b[0m\n",
      "\u001b[34mDownloading bitsandbytes-0.37.1-py3-none-any.whl (76.3 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 76.3/76.3 MB 2.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from peft==0.3.0->-r requirements.txt (line 1)) (23.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from peft==0.3.0->-r requirements.txt (line 1)) (1.23.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: psutil in /opt/conda/lib/python3.9/site-packages (from peft==0.3.0->-r requirements.txt (line 1)) (5.9.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml in /opt/conda/lib/python3.9/site-packages (from peft==0.3.0->-r requirements.txt (line 1)) (5.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.9/site-packages (from peft==0.3.0->-r requirements.txt (line 1)) (1.13.1+cu117)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.9/site-packages (from transformers==4.27.1->-r requirements.txt (line 2)) (0.13.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/lib/python3.9/site-packages (from transformers==4.27.1->-r requirements.txt (line 2)) (0.12.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from transformers==4.27.1->-r requirements.txt (line 2)) (3.9.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from transformers==4.27.1->-r requirements.txt (line 2)) (2.28.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.9/site-packages (from transformers==4.27.1->-r requirements.txt (line 2)) (4.64.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.9/site-packages (from transformers==4.27.1->-r requirements.txt (line 2)) (2022.10.31)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.27.1->-r requirements.txt (line 2)) (4.4.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.27.1->-r requirements.txt (line 2)) (1.26.14)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.27.1->-r requirements.txt (line 2)) (3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.27.1->-r requirements.txt (line 2)) (2.1.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.27.1->-r requirements.txt (line 2)) (2022.12.7)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: bitsandbytes, accelerate, transformers, peft\u001b[0m\n",
      "\u001b[34mAttempting uninstall: accelerate\u001b[0m\n",
      "\u001b[34mFound existing installation: accelerate 0.16.0\u001b[0m\n",
      "\u001b[34mUninstalling accelerate-0.16.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled accelerate-0.16.0\u001b[0m\n",
      "\u001b[34mAttempting uninstall: transformers\u001b[0m\n",
      "\u001b[34mFound existing installation: transformers 4.26.0\u001b[0m\n",
      "\u001b[34mUninstalling transformers-4.26.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled transformers-4.26.0\u001b[0m\n",
      "\u001b[34mSuccessfully installed accelerate-0.17.1 bitsandbytes-0.37.1 peft-0.3.0 transformers-4.27.1\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip is available: 23.0 -> 23.2.1\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m2023-08-09 02:29:02,481 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-08-09 02:29:02,481 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-08-09 02:29:02,520 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-08-09 02:29:02,546 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-08-09 02:29:02,571 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-08-09 02:29:02,581 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g5.2xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"dataset_path\": \"/opt/ml/input/data/training\",\n",
      "        \"epochs\": 3,\n",
      "        \"lr\": 0.0002,\n",
      "        \"model_id\": \"bigscience/bloomz-7b1\",\n",
      "        \"per_device_train_batch_size\": 1\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g5.2xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": true,\n",
      "    \"job_name\": \"huggingface-peft-2023-08-09-02-23-03-2023-08-09-02-23-06-065\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-ap-south-1-179750807597/huggingface-peft-2023-08-09-02-23-03-2023-08-09-02-23-06-065/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"run_clm\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g5.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"run_clm.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"dataset_path\":\"/opt/ml/input/data/training\",\"epochs\":3,\"lr\":0.0002,\"model_id\":\"bigscience/bloomz-7b1\",\"per_device_train_batch_size\":1}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=run_clm.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.g5.2xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=run_clm\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-ap-south-1-179750807597/huggingface-peft-2023-08-09-02-23-03-2023-08-09-02-23-06-065/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g5.2xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"dataset_path\":\"/opt/ml/input/data/training\",\"epochs\":3,\"lr\":0.0002,\"model_id\":\"bigscience/bloomz-7b1\",\"per_device_train_batch_size\":1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"job_name\":\"huggingface-peft-2023-08-09-02-23-03-2023-08-09-02-23-06-065\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-south-1-179750807597/huggingface-peft-2023-08-09-02-23-03-2023-08-09-02-23-06-065/source/sourcedir.tar.gz\",\"module_name\":\"run_clm\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"run_clm.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--dataset_path\",\"/opt/ml/input/data/training\",\"--epochs\",\"3\",\"--lr\",\"0.0002\",\"--model_id\",\"bigscience/bloomz-7b1\",\"--per_device_train_batch_size\",\"1\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_DATASET_PATH=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=3\u001b[0m\n",
      "\u001b[34mSM_HP_LR=0.0002\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_ID=bigscience/bloomz-7b1\u001b[0m\n",
      "\u001b[34mSM_HP_PER_DEVICE_TRAIN_BATCH_SIZE=1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python39.zip:/opt/conda/lib/python3.9:/opt/conda/lib/python3.9/lib-dynload:/opt/conda/lib/python3.9/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.9 run_clm.py --dataset_path /opt/ml/input/data/training --epochs 3 --lr 0.0002 --model_id bigscience/bloomz-7b1 --per_device_train_batch_size 1\u001b[0m\n",
      "\u001b[34m[2023-08-09 02:29:04.135: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.27.1 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\u001b[0m\n",
      "\u001b[34m2023-08-09 02:29:04,139 root         INFO     Using NamedTuple = typing._NamedTuple instead.\u001b[0m\n",
      "\u001b[34m2023-08-09 02:29:04,159 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34m===================================BUG REPORT===================================\u001b[0m\n",
      "\u001b[34mWelcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\u001b[0m\n",
      "\u001b[34m================================================================================\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/nvidia/lib'), PosixPath('/usr/local/nvidia/lib64')}\n",
      "  warn(msg)\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: /opt/conda/lib/python3.9/site-packages/smdistributed/dataparallel/lib:/opt/amazon/openmpi/lib/:/opt/amazon/efa/lib/:/opt/conda/lib:/usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/lib did not contain libcudart.so as expected! Searching further paths...\n",
      "  warn(msg)\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('arn'), PosixPath('aws'), PosixPath('sagemaker'), PosixPath('179750807597'), PosixPath('training-job/huggingface-peft-2023-08-09-02-23-03-2023-08-09-02-23-06-065'), PosixPath('ap-south-1')}\n",
      "  warn(msg)\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/v2/credentials/proxy-a5387207861e031a0ca82af1af6e0f6053edc2565f32c921c8cedba148f135ba-customer')}\n",
      "  warn(msg)\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//sagemaker-ap-south-1-179750807597/huggingface-peft-2023-08-09-02-23-03-2023-08-09-02-23-06-065/source/sourcedir.tar.gz'), PosixPath('s3')}\n",
      "  warn(msg)\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('bigscience/bloomz-7b1')}\n",
      "  warn(msg)\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('{\"homogeneousCluster\"'), PosixPath('\"ml.g5.2xlarge\"}},\"is_hetero\"'), PosixPath('{\"additional_framework_parameters\"'), PosixPath('\"/opt/ml/output/data\",\"output_dir\"'), PosixPath('\"run_clm\",\"network_interface_name\"'), PosixPath('\"eth0\",\"num_cpus\"'), PosixPath('[],\"distribution_instance_groups\"'), PosixPath('{\"current_group_name\"'), PosixPath('\"run_clm.py\"}'), PosixPath('\"/opt/ml/input/config\",\"input_data_config\"'), PosixPath('{\"dataset_path\"'), PosixPath('\"sagemaker_pytorch_container.training'), PosixPath('20,\"master_hostname\"'), PosixPath('[],\"framework_module\"'), PosixPath('\"None\",\"S3DistributionType\"'), PosixPath('\"homogeneousCluster\",\"current_instance_group_hosts\"'), PosixPath('\"homogeneousCluster\",\"instance_type\"'), PosixPath('\"algo-1\",\"current_instance_type\"'), PosixPath('\"File\"}},\"input_dir\"'), PosixPath('[{\"hosts\"'), PosixPath('//sagemaker-ap-south-1-179750807597/huggingface-peft-2023-08-09-02-23-03-2023-08-09-02-23-06-065/source/sourcedir.tar.gz\",\"module_name\"'), PosixPath('{\"RecordWrapperType\"'), PosixPath('\"/opt/ml/output/intermediate\",\"resource_config\"'), PosixPath('[\"algo-1\"],\"instance_groups\"'), PosixPath('\"algo-1\",\"model_dir\"'), PosixPath('\"ml.g5.2xlarge\"}],\"network_interface_name\"'), PosixPath('\"bigscience/bloomz-7b1\",\"per_device_train_batch_size\"'), PosixPath('\"FullyReplicated\",\"TrainingInputMode\"'), PosixPath('\"homogeneousCluster\",\"current_host\"'), PosixPath('\"/opt/ml/input/data/training\",\"epochs\"'), PosixPath('0.0002,\"model_id\"'), PosixPath('\"ml.g5.2xlarge\",\"distribution_hosts\"'), PosixPath('{},\"channel_input_dirs\"'), PosixPath('{\"hosts\"'), PosixPath('\"/opt/ml/model\",\"module_dir\"'), PosixPath('1,\"num_neurons\"'), PosixPath('true,\"is_modelparallel_enabled\"'), PosixPath('1},\"input_config_dir\"'), PosixPath('[\"algo-1\"],\"current_instance_type\"'), PosixPath('\"ml.g5.2xlarge\",\"hosts\"'), PosixPath('true,\"job_name\"'), PosixPath('3,\"lr\"'), PosixPath('false,\"is_master\"'), PosixPath('null,\"is_smddpmprun_installed\"'), PosixPath('0,\"output_data_dir\"'), PosixPath('[\"algo-1\"],\"hyperparameters\"'), PosixPath('[\"algo-1\"],\"instance_group_name\"'), PosixPath('{\"training\"'), PosixPath('[\"homogeneousCluster\"],\"instance_groups_dict\"'), PosixPath('\"eth0\"},\"user_entry_point\"'), PosixPath('\"/opt/ml/input/data/training\"},\"current_host\"'), PosixPath('\"/opt/ml/output\",\"output_intermediate_dir\"'), PosixPath('\"algo-1\",\"current_instance_group\"'), PosixPath('\"/opt/ml/input\",\"instance_groups\"'), PosixPath('\"s3'), PosixPath('\"huggingface-peft-2023-08-09-02-23-03-2023-08-09-02-23-06-065\",\"log_level\"'), PosixPath('8,\"num_gpus\"'), PosixPath('main\",\"hosts\"')}\n",
      "  warn(msg)\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('\"bigscience/bloomz-7b1\",\"per_device_train_batch_size\"'), PosixPath('0.0002,\"model_id\"'), PosixPath('1}'), PosixPath('{\"dataset_path\"'), PosixPath('\"/opt/ml/input/data/training\",\"epochs\"'), PosixPath('3,\"lr\"')}\n",
      "  warn(msg)\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/opt/ml/output/intermediate')}\n",
      "  warn(msg)\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/opt/conda/lib/python39.zip')}\n",
      "  warn(msg)\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('[\"--dataset_path\",\"/opt/ml/input/data/training\",\"--epochs\",\"3\",\"--lr\",\"0.0002\",\"--model_id\",\"bigscience/bloomz-7b1\",\"--per_device_train_batch_size\",\"1\"]')}\n",
      "  warn(msg)\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('$(dirname $(which conda))/..')}\n",
      "  warn(msg)\u001b[0m\n",
      "\u001b[34mCUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching /usr/local/cuda/lib64...\u001b[0m\n",
      "\u001b[34mCUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\u001b[0m\n",
      "\u001b[34mCUDA SETUP: Highest compute capability among GPUs detected: 8.6\u001b[0m\n",
      "\u001b[34mCUDA SETUP: Detected CUDA version 117\u001b[0m\n",
      "\u001b[34mCUDA SETUP: Loading binary /opt/conda/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cuda117.so...\u001b[0m\n",
      "\u001b[34mDownloading (…)lve/main/config.json:   0%|          | 0.00/747 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)lve/main/config.json: 100%|██████████| 747/747 [00:00<00:00, 214kB/s]\u001b[0m\n",
      "\u001b[34mOverriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in mixed int8. Either pass torch_dtype=torch.float16 or don't pass this argument at all to remove this warning.\u001b[0m\n",
      "\u001b[34mOverriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in mixed int8. Either pass torch_dtype=torch.float16 or don't pass this argument at all to remove this warning.\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/14.1G [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   0%|          | 10.5M/14.1G [00:01<37:24, 6.29MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   0%|          | 21.0M/14.1G [00:02<22:40, 10.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   0%|          | 31.5M/14.1G [00:02<16:11, 14.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   0%|          | 41.9M/14.1G [00:03<16:18, 14.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   0%|          | 52.4M/14.1G [00:03<14:54, 15.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   0%|          | 62.9M/14.1G [00:04<12:45, 18.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   1%|          | 73.4M/14.1G [00:04<12:37, 18.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   1%|          | 83.9M/14.1G [00:05<12:32, 18.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   1%|          | 94.4M/14.1G [00:05<11:16, 20.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   1%|          | 105M/14.1G [00:06<11:37, 20.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   1%|          | 115M/14.1G [00:06<11:52, 19.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   1%|          | 126M/14.1G [00:07<10:49, 21.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   1%|          | 136M/14.1G [00:07<11:17, 20.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   1%|          | 147M/14.1G [00:08<12:52, 18.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   1%|          | 157M/14.1G [00:08<11:31, 20.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   1%|          | 168M/14.1G [00:09<11:46, 19.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   1%|▏         | 178M/14.1G [00:10<12:04, 19.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   1%|▏         | 189M/14.1G [00:10<12:00, 19.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   1%|▏         | 199M/14.1G [00:10<10:55, 21.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   1%|▏         | 210M/14.1G [00:11<11:19, 20.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   2%|▏         | 220M/14.1G [00:11<10:27, 22.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   2%|▏         | 231M/14.1G [00:12<11:01, 21.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   2%|▏         | 241M/14.1G [00:13<11:22, 20.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   2%|▏         | 252M/14.1G [00:13<11:38, 19.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   2%|▏         | 262M/14.1G [00:14<11:51, 19.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   2%|▏         | 273M/14.1G [00:14<11:59, 19.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   2%|▏         | 283M/14.1G [00:15<12:04, 19.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   2%|▏         | 294M/14.1G [00:15<12:07, 19.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   2%|▏         | 304M/14.1G [00:16<12:10, 18.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   2%|▏         | 315M/14.1G [00:16<12:12, 18.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   2%|▏         | 325M/14.1G [00:17<12:13, 18.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   2%|▏         | 336M/14.1G [00:18<12:12, 18.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   2%|▏         | 346M/14.1G [00:18<12:11, 18.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   3%|▎         | 357M/14.1G [00:19<12:11, 18.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   3%|▎         | 367M/14.1G [00:20<14:32, 15.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   3%|▎         | 377M/14.1G [00:20<14:52, 15.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   3%|▎         | 388M/14.1G [00:21<15:12, 15.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   3%|▎         | 398M/14.1G [00:22<14:27, 15.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   3%|▎         | 409M/14.1G [00:22<14:45, 15.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   3%|▎         | 419M/14.1G [00:23<14:09, 16.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   3%|▎         | 430M/14.1G [00:24<14:42, 15.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   3%|▎         | 440M/14.1G [00:24<13:56, 16.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   3%|▎         | 451M/14.1G [00:25<14:17, 16.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   3%|▎         | 461M/14.1G [00:26<13:53, 16.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   3%|▎         | 472M/14.1G [00:26<13:25, 17.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   3%|▎         | 482M/14.1G [00:27<14:06, 16.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   3%|▎         | 493M/14.1G [00:27<13:30, 16.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   4%|▎         | 503M/14.1G [00:28<13:48, 16.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   4%|▎         | 514M/14.1G [00:29<13:43, 16.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   4%|▎         | 524M/14.1G [00:29<13:13, 17.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   4%|▍         | 535M/14.1G [00:30<13:57, 16.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   4%|▍         | 545M/14.1G [00:31<13:26, 16.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   4%|▍         | 556M/14.1G [00:31<13:01, 17.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   4%|▍         | 566M/14.1G [00:32<13:52, 16.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   4%|▍         | 577M/14.1G [00:32<13:18, 17.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   4%|▍         | 587M/14.1G [00:33<12:56, 17.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   4%|▍         | 598M/14.1G [00:34<13:45, 16.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   4%|▍         | 608M/14.1G [00:34<13:14, 17.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   4%|▍         | 619M/14.1G [00:35<12:50, 17.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   4%|▍         | 629M/14.1G [00:36<13:41, 16.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   5%|▍         | 640M/14.1G [00:36<13:10, 17.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   5%|▍         | 650M/14.1G [00:37<12:48, 17.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   5%|▍         | 661M/14.1G [00:37<12:32, 17.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   5%|▍         | 671M/14.1G [00:38<12:21, 18.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   5%|▍         | 682M/14.1G [00:38<12:13, 18.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   5%|▍         | 692M/14.1G [00:39<12:06, 18.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   5%|▍         | 703M/14.1G [00:39<12:01, 18.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   5%|▌         | 713M/14.1G [00:40<11:58, 18.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   5%|▌         | 724M/14.1G [00:41<11:55, 18.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   5%|▌         | 734M/14.1G [00:41<10:46, 20.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   5%|▌         | 744M/14.1G [00:41<11:05, 20.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   5%|▌         | 755M/14.1G [00:42<10:10, 21.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   5%|▌         | 765M/14.1G [00:42<10:40, 20.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   5%|▌         | 776M/14.1G [00:43<11:00, 20.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   6%|▌         | 786M/14.1G [00:43<10:08, 22.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   6%|▌         | 797M/14.1G [00:44<10:36, 20.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   6%|▌         | 807M/14.1G [00:44<09:54, 22.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   6%|▌         | 818M/14.1G [00:45<10:24, 21.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   6%|▌         | 828M/14.1G [00:45<10:48, 20.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   6%|▌         | 839M/14.1G [00:46<11:04, 20.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   6%|▌         | 849M/14.1G [00:46<10:11, 21.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   6%|▌         | 860M/14.1G [00:47<10:38, 20.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   6%|▌         | 870M/14.1G [00:47<10:57, 20.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   6%|▌         | 881M/14.1G [00:48<11:09, 19.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   6%|▋         | 891M/14.1G [00:48<10:14, 21.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   6%|▋         | 902M/14.1G [00:49<10:41, 20.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   6%|▋         | 912M/14.1G [00:49<09:53, 22.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   7%|▋         | 923M/14.1G [00:50<10:24, 21.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   7%|▋         | 933M/14.1G [00:50<09:45, 22.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   7%|▋         | 944M/14.1G [00:51<10:16, 21.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   7%|▋         | 954M/14.1G [00:51<10:40, 20.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   7%|▋         | 965M/14.1G [00:52<11:03, 19.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   7%|▋         | 975M/14.1G [00:53<12:14, 17.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   7%|▋         | 986M/14.1G [00:53<12:09, 18.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   7%|▋         | 996M/14.1G [00:54<11:59, 18.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   7%|▋         | 1.01G/14.1G [00:54<10:47, 20.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   7%|▋         | 1.02G/14.1G [00:55<11:02, 19.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   7%|▋         | 1.03G/14.1G [00:55<11:11, 19.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   7%|▋         | 1.04G/14.1G [00:56<11:18, 19.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   7%|▋         | 1.05G/14.1G [00:56<11:22, 19.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   7%|▋         | 1.06G/14.1G [00:57<10:20, 21.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   8%|▊         | 1.07G/14.1G [00:57<10:40, 20.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   8%|▊         | 1.08G/14.1G [00:58<09:50, 22.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   8%|▊         | 1.09G/14.1G [00:58<10:20, 21.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   8%|▊         | 1.10G/14.1G [00:59<10:40, 20.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   8%|▊         | 1.11G/14.1G [00:59<09:49, 22.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   8%|▊         | 1.12G/14.1G [01:00<10:19, 21.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   8%|▊         | 1.13G/14.1G [01:00<10:40, 20.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   8%|▊         | 1.14G/14.1G [01:01<09:49, 22.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   8%|▊         | 1.15G/14.1G [01:01<10:18, 21.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   8%|▊         | 1.16G/14.1G [01:02<09:34, 22.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   8%|▊         | 1.17G/14.1G [01:02<10:08, 21.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   8%|▊         | 1.18G/14.1G [01:03<10:30, 20.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   8%|▊         | 1.20G/14.1G [01:03<09:42, 22.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   9%|▊         | 1.21G/14.1G [01:04<10:13, 21.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   9%|▊         | 1.22G/14.1G [01:04<09:31, 22.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   9%|▊         | 1.23G/14.1G [01:05<10:03, 21.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   9%|▉         | 1.24G/14.1G [01:05<10:27, 20.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   9%|▉         | 1.25G/14.1G [01:06<09:39, 22.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   9%|▉         | 1.26G/14.1G [01:06<10:14, 20.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   9%|▉         | 1.27G/14.1G [01:07<09:32, 22.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   9%|▉         | 1.28G/14.1G [01:07<10:05, 21.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   9%|▉         | 1.29G/14.1G [01:08<10:25, 20.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   9%|▉         | 1.30G/14.1G [01:08<09:40, 22.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   9%|▉         | 1.31G/14.1G [01:09<10:09, 21.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   9%|▉         | 1.32G/14.1G [01:09<10:30, 20.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   9%|▉         | 1.33G/14.1G [01:09<09:41, 22.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:   9%|▉         | 1.34G/14.1G [01:10<10:10, 21.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  10%|▉         | 1.35G/14.1G [01:10<09:25, 22.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  10%|▉         | 1.36G/14.1G [01:11<09:58, 21.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  10%|▉         | 1.37G/14.1G [01:12<10:21, 20.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  10%|▉         | 1.38G/14.1G [01:12<09:35, 22.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  10%|▉         | 1.39G/14.1G [01:12<10:06, 21.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  10%|▉         | 1.41G/14.1G [01:13<10:27, 20.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  10%|█         | 1.42G/14.1G [01:13<09:38, 22.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  10%|█         | 1.43G/14.1G [01:14<10:07, 20.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  10%|█         | 1.44G/14.1G [01:15<10:28, 20.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  10%|█         | 1.45G/14.1G [01:15<09:37, 22.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  10%|█         | 1.46G/14.1G [01:15<10:05, 20.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  10%|█         | 1.47G/14.1G [01:16<10:25, 20.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  10%|█         | 1.48G/14.1G [01:16<09:37, 21.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  11%|█         | 1.49G/14.1G [01:17<10:03, 21.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  11%|█         | 1.50G/14.1G [01:18<10:23, 20.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  11%|█         | 1.51G/14.1G [01:18<09:35, 22.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  11%|█         | 1.52G/14.1G [01:18<10:06, 20.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  11%|█         | 1.53G/14.1G [01:19<10:24, 20.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  11%|█         | 1.54G/14.1G [01:19<09:34, 21.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  11%|█         | 1.55G/14.1G [01:20<10:01, 20.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  11%|█         | 1.56G/14.1G [01:21<10:20, 20.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  11%|█         | 1.57G/14.1G [01:21<09:30, 22.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  11%|█         | 1.58G/14.1G [01:21<09:58, 21.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  11%|█▏        | 1.59G/14.1G [01:22<09:16, 22.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  11%|█▏        | 1.60G/14.1G [01:22<09:50, 21.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  11%|█▏        | 1.61G/14.1G [01:23<10:10, 20.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  11%|█▏        | 1.63G/14.1G [01:24<10:25, 20.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  12%|█▏        | 1.64G/14.1G [01:24<09:34, 21.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  12%|█▏        | 1.65G/14.1G [01:24<10:02, 20.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  12%|█▏        | 1.66G/14.1G [01:25<10:19, 20.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  12%|█▏        | 1.67G/14.1G [01:25<09:29, 21.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  12%|█▏        | 1.68G/14.1G [01:26<09:56, 20.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  12%|█▏        | 1.69G/14.1G [01:26<09:13, 22.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  12%|█▏        | 1.70G/14.1G [01:27<09:44, 21.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  12%|█▏        | 1.71G/14.1G [01:27<10:07, 20.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  12%|█▏        | 1.72G/14.1G [01:28<09:21, 22.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  12%|█▏        | 1.73G/14.1G [01:28<09:50, 21.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  12%|█▏        | 1.74G/14.1G [01:29<09:07, 22.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  12%|█▏        | 1.75G/14.1G [01:29<09:39, 21.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  12%|█▏        | 1.76G/14.1G [01:30<10:03, 20.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  13%|█▎        | 1.77G/14.1G [01:30<09:15, 22.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  13%|█▎        | 1.78G/14.1G [01:31<09:46, 21.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  13%|█▎        | 1.79G/14.1G [01:31<10:06, 20.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  13%|█▎        | 1.80G/14.1G [01:32<09:19, 22.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  13%|█▎        | 1.81G/14.1G [01:32<09:47, 21.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  13%|█▎        | 1.82G/14.1G [01:33<09:06, 22.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  13%|█▎        | 1.84G/14.1G [01:33<09:37, 21.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  13%|█▎        | 1.85G/14.1G [01:34<09:59, 20.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  13%|█▎        | 1.86G/14.1G [01:34<09:14, 22.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  13%|█▎        | 1.87G/14.1G [01:35<09:41, 21.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  13%|█▎        | 1.88G/14.1G [01:35<09:00, 22.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  13%|█▎        | 1.89G/14.1G [01:36<09:33, 21.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  13%|█▎        | 1.90G/14.1G [01:36<09:57, 20.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  13%|█▎        | 1.91G/14.1G [01:37<10:12, 20.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  14%|█▎        | 1.92G/14.1G [01:37<09:22, 21.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  14%|█▎        | 1.93G/14.1G [01:38<09:46, 20.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  14%|█▎        | 1.94G/14.1G [01:38<09:04, 22.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  14%|█▍        | 1.95G/14.1G [01:39<09:35, 21.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  14%|█▍        | 1.96G/14.1G [01:39<09:55, 20.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  14%|█▍        | 1.97G/14.1G [01:40<09:11, 22.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  14%|█▍        | 1.98G/14.1G [01:40<09:37, 21.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  14%|█▍        | 1.99G/14.1G [01:41<09:00, 22.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  14%|█▍        | 2.00G/14.1G [01:41<09:31, 21.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  14%|█▍        | 2.01G/14.1G [01:42<09:48, 20.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  14%|█▍        | 2.02G/14.1G [01:42<09:06, 22.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  14%|█▍        | 2.03G/14.1G [01:43<09:35, 21.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  14%|█▍        | 2.04G/14.1G [01:43<09:54, 20.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  15%|█▍        | 2.06G/14.1G [01:44<09:10, 22.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  15%|█▍        | 2.07G/14.1G [01:44<09:33, 21.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  15%|█▍        | 2.08G/14.1G [01:44<08:54, 22.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  15%|█▍        | 2.09G/14.1G [01:45<09:25, 21.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  15%|█▍        | 2.10G/14.1G [01:46<09:44, 20.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  15%|█▍        | 2.11G/14.1G [01:46<09:01, 22.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  15%|█▍        | 2.12G/14.1G [01:47<09:28, 21.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  15%|█▌        | 2.13G/14.1G [01:47<08:52, 22.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  15%|█▌        | 2.14G/14.1G [01:47<09:22, 21.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  15%|█▌        | 2.15G/14.1G [01:48<09:43, 20.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  15%|█▌        | 2.16G/14.1G [01:48<09:01, 22.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  15%|█▌        | 2.17G/14.1G [01:49<09:26, 21.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  15%|█▌        | 2.18G/14.1G [01:49<08:51, 22.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  16%|█▌        | 2.19G/14.1G [01:50<09:16, 21.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  16%|█▌        | 2.20G/14.1G [01:50<08:43, 22.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  16%|█▌        | 2.21G/14.1G [01:51<09:12, 21.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  16%|█▌        | 2.22G/14.1G [01:51<09:34, 20.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  16%|█▌        | 2.23G/14.1G [01:52<08:55, 22.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  16%|█▌        | 2.24G/14.1G [01:52<09:20, 21.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  16%|█▌        | 2.25G/14.1G [01:53<08:44, 22.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  16%|█▌        | 2.26G/14.1G [01:53<09:12, 21.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  16%|█▌        | 2.28G/14.1G [01:54<08:38, 22.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  16%|█▌        | 2.29G/14.1G [01:54<09:08, 21.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  16%|█▌        | 2.30G/14.1G [01:55<08:34, 23.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  16%|█▋        | 2.31G/14.1G [01:55<09:08, 21.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  16%|█▋        | 2.32G/14.1G [01:56<09:29, 20.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  16%|█▋        | 2.33G/14.1G [01:56<08:49, 22.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  17%|█▋        | 2.34G/14.1G [01:57<09:14, 21.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  17%|█▋        | 2.35G/14.1G [01:57<08:46, 22.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  17%|█▋        | 2.36G/14.1G [01:58<09:15, 21.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  17%|█▋        | 2.37G/14.1G [01:58<09:28, 20.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  17%|█▋        | 2.38G/14.1G [01:59<08:52, 22.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  17%|█▋        | 2.39G/14.1G [01:59<09:12, 21.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  17%|█▋        | 2.40G/14.1G [01:59<08:41, 22.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  17%|█▋        | 2.41G/14.1G [02:00<09:02, 21.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  17%|█▋        | 2.42G/14.1G [02:00<08:35, 22.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  17%|█▋        | 2.43G/14.1G [02:01<09:06, 21.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  17%|█▋        | 2.44G/14.1G [02:02<09:18, 20.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  17%|█▋        | 2.45G/14.1G [02:02<08:48, 22.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  17%|█▋        | 2.46G/14.1G [02:02<09:16, 21.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  18%|█▊        | 2.47G/14.1G [02:03<08:36, 22.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  18%|█▊        | 2.49G/14.1G [02:03<09:08, 21.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  18%|█▊        | 2.50G/14.1G [02:04<08:32, 22.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  18%|█▊        | 2.51G/14.1G [02:04<09:04, 21.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  18%|█▊        | 2.52G/14.1G [02:05<09:25, 20.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  18%|█▊        | 2.53G/14.1G [02:05<08:41, 22.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  18%|█▊        | 2.54G/14.1G [02:06<09:10, 21.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  18%|█▊        | 2.55G/14.1G [02:06<09:27, 20.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  18%|█▊        | 2.56G/14.1G [02:07<08:45, 22.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  18%|█▊        | 2.57G/14.1G [02:07<09:09, 21.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  18%|█▊        | 2.58G/14.1G [02:08<08:32, 22.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  18%|█▊        | 2.59G/14.1G [02:08<08:59, 21.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  18%|█▊        | 2.60G/14.1G [02:09<09:21, 20.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  18%|█▊        | 2.61G/14.1G [02:09<08:38, 22.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  19%|█▊        | 2.62G/14.1G [02:10<09:05, 21.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  19%|█▊        | 2.63G/14.1G [02:10<08:28, 22.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  19%|█▊        | 2.64G/14.1G [02:11<08:56, 21.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  19%|█▉        | 2.65G/14.1G [02:11<09:23, 20.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  19%|█▉        | 2.66G/14.1G [02:12<08:37, 22.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  19%|█▉        | 2.67G/14.1G [02:12<09:04, 21.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  19%|█▉        | 2.68G/14.1G [02:13<08:28, 22.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  19%|█▉        | 2.69G/14.1G [02:13<08:58, 21.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  19%|█▉        | 2.71G/14.1G [02:14<09:17, 20.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  19%|█▉        | 2.72G/14.1G [02:14<08:38, 22.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  19%|█▉        | 2.73G/14.1G [02:15<08:59, 21.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  19%|█▉        | 2.74G/14.1G [02:15<08:26, 22.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  19%|█▉        | 2.75G/14.1G [02:16<08:56, 21.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  20%|█▉        | 2.76G/14.1G [02:16<09:11, 20.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  20%|█▉        | 2.77G/14.1G [02:17<08:36, 22.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  20%|█▉        | 2.78G/14.1G [02:17<08:57, 21.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  20%|█▉        | 2.79G/14.1G [02:17<08:24, 22.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  20%|█▉        | 2.80G/14.1G [02:18<08:48, 21.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  20%|█▉        | 2.81G/14.1G [02:18<08:16, 22.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  20%|█▉        | 2.82G/14.1G [02:19<08:44, 21.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  20%|██        | 2.83G/14.1G [02:20<09:06, 20.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  20%|██        | 2.84G/14.1G [02:20<09:22, 20.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  20%|██        | 2.85G/14.1G [02:20<08:37, 21.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  20%|██        | 2.86G/14.1G [02:21<09:05, 20.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  20%|██        | 2.87G/14.1G [02:22<09:21, 20.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  20%|██        | 2.88G/14.1G [02:22<08:36, 21.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  20%|██        | 2.89G/14.1G [02:23<08:59, 20.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  21%|██        | 2.90G/14.1G [02:23<08:19, 22.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  21%|██        | 2.92G/14.1G [02:23<08:49, 21.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  21%|██        | 2.93G/14.1G [02:24<09:07, 20.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  21%|██        | 2.94G/14.1G [02:24<08:26, 22.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  21%|██        | 2.95G/14.1G [02:25<08:51, 21.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  21%|██        | 2.96G/14.1G [02:25<08:13, 22.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  21%|██        | 2.97G/14.1G [02:26<08:43, 21.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  21%|██        | 2.98G/14.1G [02:26<08:13, 22.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  21%|██        | 2.99G/14.1G [02:27<08:39, 21.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  21%|██        | 3.00G/14.1G [02:27<09:01, 20.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  21%|██▏       | 3.01G/14.1G [02:28<08:24, 22.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  21%|██▏       | 3.02G/14.1G [02:28<08:45, 21.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  21%|██▏       | 3.03G/14.1G [02:29<09:03, 20.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  22%|██▏       | 3.04G/14.1G [02:29<08:20, 22.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  22%|██▏       | 3.05G/14.1G [02:30<08:46, 21.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  22%|██▏       | 3.06G/14.1G [02:30<09:04, 20.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  22%|██▏       | 3.07G/14.1G [02:31<08:34, 21.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  22%|██▏       | 3.08G/14.1G [02:31<08:46, 21.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  22%|██▏       | 3.09G/14.1G [02:32<08:18, 22.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  22%|██▏       | 3.10G/14.1G [02:32<08:43, 21.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  22%|██▏       | 3.11G/14.1G [02:33<08:09, 22.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  22%|██▏       | 3.12G/14.1G [02:33<08:36, 21.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  22%|██▏       | 3.14G/14.1G [02:34<08:47, 20.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  22%|██▏       | 3.15G/14.1G [02:34<08:18, 22.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  22%|██▏       | 3.16G/14.1G [02:35<08:34, 21.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  22%|██▏       | 3.17G/14.1G [02:35<08:54, 20.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  22%|██▏       | 3.18G/14.1G [02:36<08:17, 22.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  23%|██▎       | 3.19G/14.1G [02:36<08:40, 21.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  23%|██▎       | 3.20G/14.1G [02:37<08:10, 22.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  23%|██▎       | 3.21G/14.1G [02:37<08:31, 21.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  23%|██▎       | 3.22G/14.1G [02:38<08:53, 20.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  23%|██▎       | 3.23G/14.1G [02:38<08:21, 21.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  23%|██▎       | 3.24G/14.1G [02:39<08:38, 21.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  23%|██▎       | 3.25G/14.1G [02:39<08:08, 22.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  23%|██▎       | 3.26G/14.1G [02:40<08:34, 21.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  23%|██▎       | 3.27G/14.1G [02:40<08:47, 20.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  23%|██▎       | 3.28G/14.1G [02:41<08:25, 21.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  23%|██▎       | 3.29G/14.1G [02:41<08:45, 20.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  23%|██▎       | 3.30G/14.1G [02:42<08:47, 20.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  23%|██▎       | 3.31G/14.1G [02:42<08:32, 21.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  24%|██▎       | 3.32G/14.1G [02:43<08:25, 21.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  24%|██▎       | 3.33G/14.1G [02:43<08:18, 21.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  24%|██▎       | 3.34G/14.1G [02:44<08:39, 20.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  24%|██▎       | 3.36G/14.1G [02:44<08:04, 22.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  24%|██▍       | 3.37G/14.1G [02:45<08:29, 21.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  24%|██▍       | 3.38G/14.1G [02:45<08:49, 20.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  24%|██▍       | 3.39G/14.1G [02:46<09:07, 19.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  24%|██▍       | 3.40G/14.1G [02:46<08:29, 21.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  24%|██▍       | 3.41G/14.1G [02:47<08:43, 20.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  24%|██▍       | 3.42G/14.1G [02:47<08:56, 20.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  24%|██▍       | 3.43G/14.1G [02:48<08:16, 21.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  24%|██▍       | 3.44G/14.1G [02:48<08:33, 20.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  24%|██▍       | 3.45G/14.1G [02:49<08:57, 19.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  24%|██▍       | 3.46G/14.1G [02:49<09:07, 19.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  25%|██▍       | 3.47G/14.1G [02:50<09:15, 19.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  25%|██▍       | 3.48G/14.1G [02:50<09:19, 19.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  25%|██▍       | 3.49G/14.1G [02:51<09:22, 18.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  25%|██▍       | 3.50G/14.1G [02:52<09:23, 18.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  25%|██▍       | 3.51G/14.1G [02:52<08:30, 20.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  25%|██▍       | 3.52G/14.1G [02:53<08:46, 20.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  25%|██▍       | 3.53G/14.1G [02:53<08:57, 19.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  25%|██▌       | 3.54G/14.1G [02:54<09:05, 19.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  25%|██▌       | 3.55G/14.1G [02:54<09:10, 19.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  25%|██▌       | 3.57G/14.1G [02:55<08:21, 21.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  25%|██▌       | 3.58G/14.1G [02:55<08:38, 20.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  25%|██▌       | 3.59G/14.1G [02:56<08:50, 19.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  25%|██▌       | 3.60G/14.1G [02:56<08:11, 21.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  26%|██▌       | 3.61G/14.1G [02:57<08:29, 20.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  26%|██▌       | 3.62G/14.1G [02:57<07:54, 22.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  26%|██▌       | 3.63G/14.1G [02:58<08:20, 21.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  26%|██▌       | 3.64G/14.1G [02:58<08:37, 20.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  26%|██▌       | 3.65G/14.1G [02:59<07:55, 22.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  26%|██▌       | 3.66G/14.1G [02:59<08:20, 20.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  26%|██▌       | 3.67G/14.1G [03:00<08:36, 20.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  26%|██▌       | 3.68G/14.1G [03:00<07:55, 22.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  26%|██▌       | 3.69G/14.1G [03:01<08:21, 20.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  26%|██▌       | 3.70G/14.1G [03:01<08:37, 20.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  26%|██▋       | 3.71G/14.1G [03:02<07:57, 21.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  26%|██▋       | 3.72G/14.1G [03:02<08:21, 20.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  26%|██▋       | 3.73G/14.1G [03:03<08:37, 20.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  26%|██▋       | 3.74G/14.1G [03:03<08:46, 19.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  27%|██▋       | 3.75G/14.1G [03:04<08:05, 21.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  27%|██▋       | 3.76G/14.1G [03:04<08:24, 20.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  27%|██▋       | 3.77G/14.1G [03:05<07:49, 22.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  27%|██▋       | 3.79G/14.1G [03:05<08:15, 20.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  27%|██▋       | 3.80G/14.1G [03:06<08:27, 20.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  27%|██▋       | 3.81G/14.1G [03:06<07:53, 21.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  27%|██▋       | 3.82G/14.1G [03:07<08:11, 21.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  27%|██▋       | 3.83G/14.1G [03:07<08:30, 20.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  27%|██▋       | 3.84G/14.1G [03:08<08:46, 19.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  27%|██▋       | 3.85G/14.1G [03:08<08:52, 19.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  27%|██▋       | 3.86G/14.1G [03:09<08:56, 19.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  27%|██▋       | 3.87G/14.1G [03:09<08:58, 19.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  27%|██▋       | 3.88G/14.1G [03:10<09:00, 19.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  28%|██▊       | 3.89G/14.1G [03:11<09:03, 18.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  28%|██▊       | 3.90G/14.1G [03:11<09:04, 18.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  28%|██▊       | 3.91G/14.1G [03:12<09:04, 18.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  28%|██▊       | 3.92G/14.1G [03:12<08:15, 20.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  28%|██▊       | 3.93G/14.1G [03:13<08:27, 20.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  28%|██▊       | 3.94G/14.1G [03:13<07:49, 21.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  28%|██▊       | 3.95G/14.1G [03:14<08:10, 20.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  28%|██▊       | 3.96G/14.1G [03:14<09:16, 18.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  28%|██▊       | 3.97G/14.1G [03:15<09:16, 18.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  28%|██▊       | 3.98G/14.1G [03:15<09:12, 18.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  28%|██▊       | 4.00G/14.1G [03:16<09:59, 16.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  28%|██▊       | 4.01G/14.1G [03:17<09:43, 17.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  28%|██▊       | 4.02G/14.1G [03:17<09:31, 17.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  28%|██▊       | 4.03G/14.1G [03:18<09:55, 17.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  29%|██▊       | 4.04G/14.1G [03:19<09:55, 17.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  29%|██▊       | 4.05G/14.1G [03:19<09:37, 17.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  29%|██▊       | 4.06G/14.1G [03:20<09:25, 17.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  29%|██▉       | 4.07G/14.1G [03:20<09:16, 18.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  29%|██▉       | 4.08G/14.1G [03:21<09:08, 18.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  29%|██▉       | 4.09G/14.1G [03:22<10:29, 16.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  29%|██▉       | 4.10G/14.1G [03:22<10:51, 15.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  29%|██▉       | 4.11G/14.1G [03:23<11:08, 15.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  29%|██▉       | 4.12G/14.1G [03:24<11:16, 14.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  29%|██▉       | 4.13G/14.1G [03:25<11:21, 14.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  29%|██▉       | 4.14G/14.1G [03:25<10:40, 15.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  29%|██▉       | 4.15G/14.1G [03:26<10:56, 15.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  29%|██▉       | 4.16G/14.1G [03:27<10:21, 16.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  30%|██▉       | 4.17G/14.1G [03:27<10:44, 15.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  30%|██▉       | 4.18G/14.1G [03:28<10:51, 15.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  30%|██▉       | 4.19G/14.1G [03:29<10:25, 15.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  30%|██▉       | 4.20G/14.1G [03:29<10:37, 15.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  30%|██▉       | 4.22G/14.1G [03:30<10:14, 16.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  30%|██▉       | 4.23G/14.1G [03:31<10:27, 15.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  30%|██▉       | 4.24G/14.1G [03:31<10:10, 16.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  30%|███       | 4.25G/14.1G [03:32<10:31, 15.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  30%|███       | 4.26G/14.1G [03:32<10:03, 16.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  30%|███       | 4.27G/14.1G [03:33<10:29, 15.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  30%|███       | 4.28G/14.1G [03:34<10:06, 16.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  30%|███       | 4.29G/14.1G [03:34<10:21, 15.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  30%|███       | 4.30G/14.1G [03:35<10:01, 16.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  30%|███       | 4.31G/14.1G [03:36<10:19, 15.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  31%|███       | 4.32G/14.1G [03:36<09:53, 16.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  31%|███       | 4.33G/14.1G [03:37<09:59, 16.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  31%|███       | 4.34G/14.1G [03:38<09:57, 16.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  31%|███       | 4.35G/14.1G [03:38<09:58, 16.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  31%|███       | 4.36G/14.1G [03:39<09:57, 16.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  31%|███       | 4.37G/14.1G [03:39<09:35, 17.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  31%|███       | 4.38G/14.1G [03:40<09:23, 17.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  31%|███       | 4.39G/14.1G [03:41<09:09, 17.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  31%|███       | 4.40G/14.1G [03:41<09:36, 16.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  31%|███       | 4.41G/14.1G [03:42<08:39, 18.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  31%|███▏      | 4.42G/14.1G [03:42<09:21, 17.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  31%|███▏      | 4.44G/14.1G [03:43<08:20, 19.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  31%|███▏      | 4.45G/14.1G [03:43<08:24, 19.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  32%|███▏      | 4.46G/14.1G [03:44<07:39, 21.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  32%|███▏      | 4.47G/14.1G [03:44<07:55, 20.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  32%|███▏      | 4.48G/14.1G [03:45<08:05, 19.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  32%|███▏      | 4.49G/14.1G [03:45<07:27, 21.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  32%|███▏      | 4.50G/14.1G [03:46<07:44, 20.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  32%|███▏      | 4.51G/14.1G [03:47<08:49, 18.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  32%|███▏      | 4.52G/14.1G [03:47<08:46, 18.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  32%|███▏      | 4.53G/14.1G [03:48<08:42, 18.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  32%|███▏      | 4.54G/14.1G [03:48<08:38, 18.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  32%|███▏      | 4.55G/14.1G [03:49<08:42, 18.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  32%|███▏      | 4.56G/14.1G [03:49<08:36, 18.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  32%|███▏      | 4.57G/14.1G [03:50<08:38, 18.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  32%|███▏      | 4.58G/14.1G [03:50<08:01, 19.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  32%|███▏      | 4.59G/14.1G [03:51<08:11, 19.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  33%|███▎      | 4.60G/14.1G [03:51<08:04, 19.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  33%|███▎      | 4.61G/14.1G [03:52<08:11, 19.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  33%|███▎      | 4.62G/14.1G [03:52<07:34, 20.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  33%|███▎      | 4.63G/14.1G [03:53<07:48, 20.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  33%|███▎      | 4.65G/14.1G [03:54<07:55, 20.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  33%|███▎      | 4.66G/14.1G [03:54<07:21, 21.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  33%|███▎      | 4.67G/14.1G [03:54<07:35, 20.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  33%|███▎      | 4.68G/14.1G [03:55<07:49, 20.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  33%|███▎      | 4.69G/14.1G [03:55<07:16, 21.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  33%|███▎      | 4.70G/14.1G [03:56<07:32, 20.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  33%|███▎      | 4.71G/14.1G [03:56<07:08, 22.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  33%|███▎      | 4.72G/14.1G [03:57<07:29, 21.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  33%|███▎      | 4.73G/14.1G [03:58<07:45, 20.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  34%|███▎      | 4.74G/14.1G [03:58<07:54, 19.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  34%|███▎      | 4.75G/14.1G [03:58<07:17, 21.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  34%|███▎      | 4.76G/14.1G [03:59<08:23, 18.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  34%|███▎      | 4.77G/14.1G [04:00<08:22, 18.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  34%|███▍      | 4.78G/14.1G [04:00<08:26, 18.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  34%|███▍      | 4.79G/14.1G [04:01<09:03, 17.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  34%|███▍      | 4.80G/14.1G [04:02<08:50, 17.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  34%|███▍      | 4.81G/14.1G [04:02<08:43, 17.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  34%|███▍      | 4.82G/14.1G [04:03<08:35, 18.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  34%|███▍      | 4.83G/14.1G [04:03<08:29, 18.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  34%|███▍      | 4.84G/14.1G [04:04<08:25, 18.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  34%|███▍      | 4.85G/14.1G [04:04<08:24, 18.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  34%|███▍      | 4.87G/14.1G [04:05<08:20, 18.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  34%|███▍      | 4.88G/14.1G [04:06<08:17, 18.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  35%|███▍      | 4.89G/14.1G [04:06<08:13, 18.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  35%|███▍      | 4.90G/14.1G [04:07<08:12, 18.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  35%|███▍      | 4.91G/14.1G [04:07<08:11, 18.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  35%|███▍      | 4.92G/14.1G [04:08<08:07, 18.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  35%|███▍      | 4.93G/14.1G [04:08<08:09, 18.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  35%|███▍      | 4.94G/14.1G [04:09<08:05, 19.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  35%|███▌      | 4.95G/14.1G [04:09<08:07, 18.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  35%|███▌      | 4.96G/14.1G [04:10<07:29, 20.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  35%|███▌      | 4.97G/14.1G [04:10<07:40, 19.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  35%|███▌      | 4.98G/14.1G [04:11<07:41, 19.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  35%|███▌      | 4.99G/14.1G [04:11<07:48, 19.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  35%|███▌      | 5.00G/14.1G [04:12<07:53, 19.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  35%|███▌      | 5.01G/14.1G [04:13<07:55, 19.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  36%|███▌      | 5.02G/14.1G [04:13<07:53, 19.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  36%|███▌      | 5.03G/14.1G [04:14<07:55, 19.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  36%|███▌      | 5.04G/14.1G [04:14<07:18, 20.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  36%|███▌      | 5.05G/14.1G [04:15<07:31, 20.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  36%|███▌      | 5.06G/14.1G [04:15<07:38, 19.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  36%|███▌      | 5.08G/14.1G [04:16<07:41, 19.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  36%|███▌      | 5.09G/14.1G [04:16<07:07, 21.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  36%|███▌      | 5.10G/14.1G [04:17<07:23, 20.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  36%|███▌      | 5.11G/14.1G [04:17<07:29, 20.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  36%|███▌      | 5.12G/14.1G [04:18<07:38, 19.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  36%|███▋      | 5.13G/14.1G [04:18<07:03, 21.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  36%|███▋      | 5.14G/14.1G [04:19<07:16, 20.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  36%|███▋      | 5.15G/14.1G [04:19<07:27, 20.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  36%|███▋      | 5.16G/14.1G [04:20<06:55, 21.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  37%|███▋      | 5.17G/14.1G [04:20<07:08, 20.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  37%|███▋      | 5.18G/14.1G [04:21<06:43, 22.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  37%|███▋      | 5.19G/14.1G [04:21<07:04, 21.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  37%|███▋      | 5.20G/14.1G [04:22<07:14, 20.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  37%|███▋      | 5.21G/14.1G [04:22<06:45, 22.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  37%|███▋      | 5.22G/14.1G [04:23<07:00, 21.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  37%|███▋      | 5.23G/14.1G [04:23<06:35, 22.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  37%|███▋      | 5.24G/14.1G [04:24<06:54, 21.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  37%|███▋      | 5.25G/14.1G [04:24<07:11, 20.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  37%|███▋      | 5.26G/14.1G [04:25<06:42, 22.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  37%|███▋      | 5.27G/14.1G [04:25<06:59, 21.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  37%|███▋      | 5.28G/14.1G [04:26<06:33, 22.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  37%|███▋      | 5.30G/14.1G [04:26<06:52, 21.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  38%|███▊      | 5.31G/14.1G [04:27<07:09, 20.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  38%|███▊      | 5.32G/14.1G [04:27<06:39, 22.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  38%|███▊      | 5.33G/14.1G [04:28<06:58, 21.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  38%|███▊      | 5.34G/14.1G [04:28<06:31, 22.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  38%|███▊      | 5.35G/14.1G [04:29<06:52, 21.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  38%|███▊      | 5.36G/14.1G [04:29<07:53, 18.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  38%|███▊      | 5.37G/14.1G [04:30<07:51, 18.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  38%|███▊      | 5.38G/14.1G [04:30<07:49, 18.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  38%|███▊      | 5.39G/14.1G [04:31<07:47, 18.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  38%|███▊      | 5.40G/14.1G [04:31<07:46, 18.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  38%|███▊      | 5.41G/14.1G [04:32<07:36, 19.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  38%|███▊      | 5.42G/14.1G [04:32<07:04, 20.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  38%|███▊      | 5.43G/14.1G [04:33<07:15, 20.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  38%|███▊      | 5.44G/14.1G [04:34<07:22, 19.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  39%|███▊      | 5.45G/14.1G [04:34<06:45, 21.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  39%|███▊      | 5.46G/14.1G [04:34<07:00, 20.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  39%|███▊      | 5.47G/14.1G [04:35<07:12, 20.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  39%|███▉      | 5.48G/14.1G [04:35<06:36, 21.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  39%|███▉      | 5.49G/14.1G [04:36<06:54, 20.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  39%|███▉      | 5.51G/14.1G [04:37<07:06, 20.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  39%|███▉      | 5.52G/14.1G [04:37<06:32, 22.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  39%|███▉      | 5.53G/14.1G [04:37<06:51, 20.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  39%|███▉      | 5.54G/14.1G [04:38<06:21, 22.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  39%|███▉      | 5.55G/14.1G [04:38<06:43, 21.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  39%|███▉      | 5.56G/14.1G [04:39<06:58, 20.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  39%|███▉      | 5.57G/14.1G [04:39<06:26, 22.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  39%|███▉      | 5.58G/14.1G [04:40<06:46, 21.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  40%|███▉      | 5.59G/14.1G [04:40<06:17, 22.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  40%|███▉      | 5.60G/14.1G [04:41<06:39, 21.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  40%|███▉      | 5.61G/14.1G [04:41<06:54, 20.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  40%|███▉      | 5.62G/14.1G [04:42<06:23, 22.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  40%|███▉      | 5.63G/14.1G [04:42<06:42, 21.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  40%|███▉      | 5.64G/14.1G [04:43<06:14, 22.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  40%|███▉      | 5.65G/14.1G [04:43<06:36, 21.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  40%|████      | 5.66G/14.1G [04:44<06:09, 22.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  40%|████      | 5.67G/14.1G [04:44<06:33, 21.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  40%|████      | 5.68G/14.1G [04:45<06:49, 20.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  40%|████      | 5.69G/14.1G [04:45<06:18, 22.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  40%|████      | 5.70G/14.1G [04:46<06:39, 21.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  40%|████      | 5.71G/14.1G [04:46<06:53, 20.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  40%|████      | 5.73G/14.1G [04:47<06:20, 22.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  41%|████      | 5.74G/14.1G [04:47<06:40, 21.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  41%|████      | 5.75G/14.1G [04:48<06:54, 20.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  41%|████      | 5.76G/14.1G [04:48<06:20, 22.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  41%|████      | 5.77G/14.1G [04:49<07:22, 18.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  41%|████      | 5.78G/14.1G [04:49<07:23, 18.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  41%|████      | 5.79G/14.1G [04:50<07:24, 18.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  41%|████      | 5.80G/14.1G [04:51<08:05, 17.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  41%|████      | 5.81G/14.1G [04:51<07:53, 17.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  41%|████      | 5.82G/14.1G [04:52<08:22, 16.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  41%|████      | 5.83G/14.1G [04:53<08:05, 17.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  41%|████▏     | 5.84G/14.1G [04:53<07:51, 17.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  41%|████▏     | 5.85G/14.1G [04:54<07:40, 18.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  41%|████▏     | 5.86G/14.1G [04:54<07:34, 18.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  42%|████▏     | 5.87G/14.1G [04:55<07:29, 18.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  42%|████▏     | 5.88G/14.1G [04:55<07:26, 18.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  42%|████▏     | 5.89G/14.1G [04:56<07:23, 18.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  42%|████▏     | 5.90G/14.1G [04:56<07:20, 18.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  42%|████▏     | 5.91G/14.1G [04:57<07:17, 18.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  42%|████▏     | 5.92G/14.1G [04:58<07:19, 18.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  42%|████▏     | 5.93G/14.1G [04:58<07:46, 17.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  42%|████▏     | 5.95G/14.1G [04:59<07:36, 17.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  42%|████▏     | 5.96G/14.1G [04:59<07:28, 18.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  42%|████▏     | 5.97G/14.1G [05:00<06:53, 19.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  42%|████▏     | 5.98G/14.1G [05:00<06:59, 19.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  42%|████▏     | 5.99G/14.1G [05:01<07:29, 18.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  42%|████▏     | 6.00G/14.1G [05:02<07:23, 18.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  42%|████▏     | 6.01G/14.1G [05:02<06:52, 19.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  43%|████▎     | 6.02G/14.1G [05:03<06:57, 19.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  43%|████▎     | 6.03G/14.1G [05:03<07:25, 18.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  43%|████▎     | 6.04G/14.1G [05:04<06:57, 19.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  43%|████▎     | 6.05G/14.1G [05:04<06:58, 19.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  43%|████▎     | 6.06G/14.1G [05:05<07:00, 19.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  43%|████▎     | 6.07G/14.1G [05:05<07:02, 19.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  43%|████▎     | 6.08G/14.1G [05:06<07:02, 19.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  43%|████▎     | 6.09G/14.1G [05:06<07:00, 19.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  43%|████▎     | 6.10G/14.1G [05:07<06:49, 19.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  43%|████▎     | 6.11G/14.1G [05:07<06:30, 20.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  43%|████▎     | 6.12G/14.1G [05:08<06:41, 20.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  43%|████▎     | 6.13G/14.1G [05:08<06:30, 20.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  43%|████▎     | 6.14G/14.1G [05:09<06:17, 21.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  44%|████▎     | 6.16G/14.1G [05:09<06:14, 21.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  44%|████▎     | 6.17G/14.1G [05:10<06:28, 20.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  44%|████▎     | 6.18G/14.1G [05:10<06:15, 21.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  44%|████▍     | 6.19G/14.1G [05:11<06:11, 21.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  44%|████▍     | 6.20G/14.1G [05:11<06:04, 21.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  44%|████▍     | 6.21G/14.1G [05:12<06:20, 20.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  44%|████▍     | 6.22G/14.1G [05:12<06:15, 21.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  44%|████▍     | 6.23G/14.1G [05:13<06:05, 21.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  44%|████▍     | 6.24G/14.1G [05:13<06:05, 21.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  44%|████▍     | 6.25G/14.1G [05:14<05:59, 21.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  44%|████▍     | 6.26G/14.1G [05:14<05:59, 21.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  44%|████▍     | 6.27G/14.1G [05:15<06:16, 20.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  44%|████▍     | 6.28G/14.1G [05:15<06:06, 21.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  44%|████▍     | 6.29G/14.1G [05:16<06:03, 21.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  45%|████▍     | 6.30G/14.1G [05:16<05:58, 21.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  45%|████▍     | 6.31G/14.1G [05:17<06:15, 20.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  45%|████▍     | 6.32G/14.1G [05:17<06:08, 21.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  45%|████▍     | 6.33G/14.1G [05:18<06:02, 21.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  45%|████▍     | 6.34G/14.1G [05:18<05:58, 21.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  45%|████▍     | 6.35G/14.1G [05:19<05:55, 21.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  45%|████▌     | 6.36G/14.1G [05:19<06:53, 18.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  45%|████▌     | 6.38G/14.1G [05:20<06:52, 18.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  45%|████▌     | 6.39G/14.1G [05:21<06:52, 18.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  45%|████▌     | 6.40G/14.1G [05:21<06:28, 19.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  45%|████▌     | 6.41G/14.1G [05:21<06:20, 20.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  45%|████▌     | 6.42G/14.1G [05:22<06:29, 19.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  45%|████▌     | 6.43G/14.1G [05:23<07:15, 17.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  46%|████▌     | 6.44G/14.1G [05:23<07:08, 18.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  46%|████▌     | 6.45G/14.1G [05:24<07:39, 16.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  46%|████▌     | 6.46G/14.1G [05:25<07:26, 17.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  46%|████▌     | 6.47G/14.1G [05:25<07:48, 16.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  46%|████▌     | 6.48G/14.1G [05:26<07:34, 16.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  46%|████▌     | 6.49G/14.1G [05:26<07:20, 17.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  46%|████▌     | 6.50G/14.1G [05:27<07:09, 17.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  46%|████▌     | 6.51G/14.1G [05:28<07:32, 16.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  46%|████▌     | 6.52G/14.1G [05:28<07:17, 17.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  46%|████▌     | 6.53G/14.1G [05:29<07:15, 17.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  46%|████▋     | 6.54G/14.1G [05:29<07:05, 17.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  46%|████▋     | 6.55G/14.1G [05:30<07:00, 18.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  46%|████▋     | 6.56G/14.1G [05:31<06:53, 18.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  47%|████▋     | 6.57G/14.1G [05:31<06:54, 18.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  47%|████▋     | 6.59G/14.1G [05:32<06:50, 18.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  47%|████▋     | 6.60G/14.1G [05:32<06:54, 18.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  47%|████▋     | 6.61G/14.1G [05:33<07:02, 17.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  47%|████▋     | 6.62G/14.1G [05:34<07:08, 17.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  47%|████▋     | 6.63G/14.1G [05:34<07:00, 17.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  47%|████▋     | 6.64G/14.1G [05:35<06:53, 18.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  47%|████▋     | 6.65G/14.1G [05:35<06:48, 18.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  47%|████▋     | 6.66G/14.1G [05:36<06:43, 18.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  47%|████▋     | 6.67G/14.1G [05:36<06:41, 18.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  47%|████▋     | 6.68G/14.1G [05:37<06:40, 18.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  47%|████▋     | 6.69G/14.1G [05:37<06:38, 18.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  47%|████▋     | 6.70G/14.1G [05:38<06:38, 18.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  47%|████▋     | 6.71G/14.1G [05:39<06:37, 18.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  48%|████▊     | 6.72G/14.1G [05:39<06:37, 18.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  48%|████▊     | 6.73G/14.1G [05:40<06:36, 18.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  48%|████▊     | 6.74G/14.1G [05:40<06:34, 18.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  48%|████▊     | 6.75G/14.1G [05:41<06:33, 18.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  48%|████▊     | 6.76G/14.1G [05:41<06:32, 18.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  48%|████▊     | 6.77G/14.1G [05:42<06:15, 19.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  48%|████▊     | 6.78G/14.1G [05:42<06:00, 20.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  48%|████▊     | 6.79G/14.1G [05:43<06:08, 19.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  48%|████▊     | 6.81G/14.1G [05:43<06:13, 19.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  48%|████▊     | 6.82G/14.1G [05:44<05:42, 21.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  48%|████▊     | 6.83G/14.1G [05:44<05:54, 20.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  48%|████▊     | 6.84G/14.1G [05:45<05:27, 22.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  48%|████▊     | 6.85G/14.1G [05:45<05:45, 21.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  49%|████▊     | 6.86G/14.1G [05:46<05:58, 20.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  49%|████▊     | 6.87G/14.1G [05:46<05:30, 22.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  49%|████▊     | 6.88G/14.1G [05:47<05:46, 21.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  49%|████▊     | 6.89G/14.1G [05:47<05:22, 22.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  49%|████▉     | 6.90G/14.1G [05:48<05:40, 21.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  49%|████▉     | 6.91G/14.1G [05:48<05:53, 20.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  49%|████▉     | 6.92G/14.1G [05:49<05:27, 22.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  49%|████▉     | 6.93G/14.1G [05:49<05:41, 21.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  49%|████▉     | 6.94G/14.1G [05:50<05:19, 22.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  49%|████▉     | 6.95G/14.1G [05:50<05:34, 21.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  49%|████▉     | 6.96G/14.1G [05:51<05:48, 20.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  49%|████▉     | 6.97G/14.1G [05:51<05:24, 22.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  49%|████▉     | 6.98G/14.1G [05:52<05:37, 21.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  49%|████▉     | 6.99G/14.1G [05:52<05:16, 22.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  50%|████▉     | 7.00G/14.1G [05:53<05:31, 21.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  50%|████▉     | 7.01G/14.1G [05:53<05:47, 20.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  50%|████▉     | 7.03G/14.1G [05:54<05:21, 22.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  50%|████▉     | 7.04G/14.1G [05:54<05:34, 21.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  50%|████▉     | 7.05G/14.1G [05:54<05:14, 22.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  50%|████▉     | 7.06G/14.1G [05:55<05:32, 21.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  50%|████▉     | 7.07G/14.1G [05:56<05:41, 20.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  50%|█████     | 7.08G/14.1G [05:56<05:18, 22.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  50%|█████     | 7.09G/14.1G [05:57<05:30, 21.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  50%|█████     | 7.10G/14.1G [05:57<05:12, 22.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  50%|█████     | 7.11G/14.1G [05:57<05:30, 21.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  50%|█████     | 7.12G/14.1G [05:58<05:37, 20.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  50%|█████     | 7.13G/14.1G [05:58<05:16, 22.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  51%|█████     | 7.14G/14.1G [05:59<05:28, 21.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  51%|█████     | 7.15G/14.1G [05:59<05:09, 22.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  51%|█████     | 7.16G/14.1G [06:00<05:27, 21.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  51%|█████     | 7.17G/14.1G [06:00<05:35, 20.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  51%|█████     | 7.18G/14.1G [06:01<05:14, 22.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  51%|█████     | 7.19G/14.1G [06:01<05:25, 21.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  51%|█████     | 7.20G/14.1G [06:02<05:37, 20.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  51%|█████     | 7.21G/14.1G [06:02<05:17, 21.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  51%|█████     | 7.22G/14.1G [06:03<05:25, 21.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  51%|█████     | 7.24G/14.1G [06:03<05:08, 22.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  51%|█████     | 7.25G/14.1G [06:04<05:24, 21.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  51%|█████▏    | 7.26G/14.1G [06:04<05:31, 20.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  51%|█████▏    | 7.27G/14.1G [06:05<05:11, 22.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  51%|█████▏    | 7.28G/14.1G [06:05<05:21, 21.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  52%|█████▏    | 7.29G/14.1G [06:06<05:04, 22.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  52%|█████▏    | 7.30G/14.1G [06:06<05:21, 21.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  52%|█████▏    | 7.31G/14.1G [06:07<05:28, 20.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  52%|█████▏    | 7.32G/14.1G [06:07<05:08, 22.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  52%|█████▏    | 7.33G/14.1G [06:08<05:18, 21.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  52%|█████▏    | 7.34G/14.1G [06:08<05:02, 22.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  52%|█████▏    | 7.35G/14.1G [06:09<05:18, 21.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  52%|█████▏    | 7.36G/14.1G [06:09<05:30, 20.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  52%|█████▏    | 7.37G/14.1G [06:10<05:06, 22.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  52%|█████▏    | 7.38G/14.1G [06:10<05:55, 19.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  52%|█████▏    | 7.39G/14.1G [06:11<05:56, 18.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  52%|█████▏    | 7.40G/14.1G [06:11<05:57, 18.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  52%|█████▏    | 7.41G/14.1G [06:12<05:57, 18.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  53%|█████▎    | 7.42G/14.1G [06:13<05:57, 18.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  53%|█████▎    | 7.43G/14.1G [06:13<05:55, 18.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  53%|█████▎    | 7.44G/14.1G [06:14<05:55, 18.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  53%|█████▎    | 7.46G/14.1G [06:14<05:54, 18.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  53%|█████▎    | 7.47G/14.1G [06:15<05:21, 20.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  53%|█████▎    | 7.48G/14.1G [06:15<05:30, 20.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  53%|█████▎    | 7.49G/14.1G [06:16<05:36, 19.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  53%|█████▎    | 7.50G/14.1G [06:16<05:08, 21.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  53%|█████▎    | 7.51G/14.1G [06:17<05:20, 20.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  53%|█████▎    | 7.52G/14.1G [06:17<05:29, 20.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  53%|█████▎    | 7.53G/14.1G [06:18<05:02, 21.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  53%|█████▎    | 7.54G/14.1G [06:18<05:16, 20.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  53%|█████▎    | 7.55G/14.1G [06:19<05:25, 20.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  53%|█████▎    | 7.56G/14.1G [06:19<04:59, 22.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  54%|█████▎    | 7.57G/14.1G [06:20<05:13, 20.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  54%|█████▎    | 7.58G/14.1G [06:20<04:50, 22.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  54%|█████▎    | 7.59G/14.1G [06:21<05:07, 21.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  54%|█████▍    | 7.60G/14.1G [06:21<05:18, 20.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  54%|█████▍    | 7.61G/14.1G [06:22<04:53, 22.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  54%|█████▍    | 7.62G/14.1G [06:22<05:08, 21.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  54%|█████▍    | 7.63G/14.1G [06:22<04:46, 22.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  54%|█████▍    | 7.64G/14.1G [06:23<05:04, 21.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  54%|█████▍    | 7.65G/14.1G [06:24<05:16, 20.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  54%|█████▍    | 7.67G/14.1G [06:24<04:55, 21.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  54%|█████▍    | 7.68G/14.1G [06:25<05:05, 21.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  54%|█████▍    | 7.69G/14.1G [06:25<04:43, 22.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  54%|█████▍    | 7.70G/14.1G [06:25<05:00, 21.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  55%|█████▍    | 7.71G/14.1G [06:26<05:12, 20.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  55%|█████▍    | 7.72G/14.1G [06:26<04:48, 22.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  55%|█████▍    | 7.73G/14.1G [06:27<05:04, 21.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  55%|█████▍    | 7.74G/14.1G [06:28<05:14, 20.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  55%|█████▍    | 7.75G/14.1G [06:28<04:49, 22.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  55%|█████▍    | 7.76G/14.1G [06:28<05:03, 21.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  55%|█████▍    | 7.77G/14.1G [06:29<05:13, 20.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  55%|█████▌    | 7.78G/14.1G [06:29<04:48, 22.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  55%|█████▌    | 7.79G/14.1G [06:30<05:02, 21.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  55%|█████▌    | 7.80G/14.1G [06:31<05:12, 20.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  55%|█████▌    | 7.81G/14.1G [06:31<04:47, 22.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  55%|█████▌    | 7.82G/14.1G [06:31<05:01, 21.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  55%|█████▌    | 7.83G/14.1G [06:32<05:10, 20.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  55%|█████▌    | 7.84G/14.1G [06:32<04:45, 22.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  56%|█████▌    | 7.85G/14.1G [06:33<05:00, 20.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  56%|█████▌    | 7.86G/14.1G [06:34<05:09, 20.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  56%|█████▌    | 7.87G/14.1G [06:34<04:44, 22.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  56%|█████▌    | 7.89G/14.1G [06:34<04:58, 21.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  56%|█████▌    | 7.90G/14.1G [06:35<04:36, 22.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  56%|█████▌    | 7.91G/14.1G [06:35<04:52, 21.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  56%|█████▌    | 7.92G/14.1G [06:36<05:03, 20.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  56%|█████▌    | 7.93G/14.1G [06:36<04:40, 22.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  56%|█████▌    | 7.94G/14.1G [06:37<04:55, 21.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  56%|█████▌    | 7.95G/14.1G [06:37<04:32, 22.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  56%|█████▋    | 7.96G/14.1G [06:38<04:48, 21.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  56%|█████▋    | 7.97G/14.1G [06:38<04:59, 20.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  56%|█████▋    | 7.98G/14.1G [06:39<04:36, 22.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  57%|█████▋    | 7.99G/14.1G [06:39<04:50, 21.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  57%|█████▋    | 8.00G/14.1G [06:40<04:30, 22.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  57%|█████▋    | 8.01G/14.1G [06:40<04:46, 21.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  57%|█████▋    | 8.02G/14.1G [06:41<04:26, 22.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  57%|█████▋    | 8.03G/14.1G [06:41<04:43, 21.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  57%|█████▋    | 8.04G/14.1G [06:42<04:55, 20.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  57%|█████▋    | 8.05G/14.1G [06:42<04:32, 22.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  57%|█████▋    | 8.06G/14.1G [06:43<04:47, 21.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  57%|█████▋    | 8.07G/14.1G [06:43<04:33, 22.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  57%|█████▋    | 8.08G/14.1G [06:44<04:41, 21.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  57%|█████▋    | 8.10G/14.1G [06:44<04:52, 20.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  57%|█████▋    | 8.11G/14.1G [06:45<05:01, 20.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  57%|█████▋    | 8.12G/14.1G [06:45<04:36, 21.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  57%|█████▋    | 8.13G/14.1G [06:46<04:48, 20.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  58%|█████▊    | 8.14G/14.1G [06:46<04:57, 20.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  58%|█████▊    | 8.15G/14.1G [06:47<04:33, 21.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  58%|█████▊    | 8.16G/14.1G [06:47<04:46, 20.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  58%|█████▊    | 8.17G/14.1G [06:48<04:55, 20.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  58%|█████▊    | 8.18G/14.1G [06:48<04:31, 22.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  58%|█████▊    | 8.19G/14.1G [06:49<04:44, 20.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  58%|█████▊    | 8.20G/14.1G [06:49<04:52, 20.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  58%|█████▊    | 8.21G/14.1G [06:50<04:29, 22.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  58%|█████▊    | 8.22G/14.1G [06:50<04:42, 21.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  58%|█████▊    | 8.23G/14.1G [06:51<04:52, 20.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  58%|█████▊    | 8.24G/14.1G [06:51<05:28, 18.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  58%|█████▊    | 8.25G/14.1G [06:52<05:36, 17.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  58%|█████▊    | 8.26G/14.1G [06:53<05:46, 17.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  59%|█████▊    | 8.27G/14.1G [06:53<05:47, 16.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  59%|█████▊    | 8.28G/14.1G [06:54<05:54, 16.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  59%|█████▊    | 8.29G/14.1G [06:55<05:40, 17.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  59%|█████▊    | 8.30G/14.1G [06:55<05:31, 17.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  59%|█████▉    | 8.32G/14.1G [06:56<05:33, 17.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  59%|█████▉    | 8.33G/14.1G [06:56<05:44, 16.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  59%|█████▉    | 8.34G/14.1G [06:57<05:36, 17.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  59%|█████▉    | 8.35G/14.1G [06:58<05:27, 17.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  59%|█████▉    | 8.36G/14.1G [06:58<05:20, 18.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  59%|█████▉    | 8.37G/14.1G [06:59<05:16, 18.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  59%|█████▉    | 8.38G/14.1G [06:59<05:13, 18.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  59%|█████▉    | 8.39G/14.1G [07:00<05:10, 18.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  59%|█████▉    | 8.40G/14.1G [07:01<05:36, 17.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  59%|█████▉    | 8.41G/14.1G [07:01<05:26, 17.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  60%|█████▉    | 8.42G/14.1G [07:02<05:19, 17.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  60%|█████▉    | 8.43G/14.1G [07:02<05:14, 18.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  60%|█████▉    | 8.44G/14.1G [07:03<05:10, 18.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  60%|█████▉    | 8.45G/14.1G [07:03<05:08, 18.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  60%|█████▉    | 8.46G/14.1G [07:04<05:05, 18.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  60%|█████▉    | 8.47G/14.1G [07:04<05:04, 18.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  60%|██████    | 8.48G/14.1G [07:05<05:03, 18.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  60%|██████    | 8.49G/14.1G [07:06<05:02, 18.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  60%|██████    | 8.50G/14.1G [07:06<05:00, 18.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  60%|██████    | 8.51G/14.1G [07:07<05:00, 18.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  60%|██████    | 8.52G/14.1G [07:07<04:59, 18.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  60%|██████    | 8.54G/14.1G [07:08<04:58, 18.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  60%|██████    | 8.55G/14.1G [07:08<04:57, 18.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  61%|██████    | 8.56G/14.1G [07:09<04:57, 18.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  61%|██████    | 8.57G/14.1G [07:09<04:56, 18.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  61%|██████    | 8.58G/14.1G [07:10<04:55, 18.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  61%|██████    | 8.59G/14.1G [07:10<04:28, 20.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  61%|██████    | 8.60G/14.1G [07:11<04:35, 20.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  61%|██████    | 8.61G/14.1G [07:12<04:40, 19.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  61%|██████    | 8.62G/14.1G [07:12<04:16, 21.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  61%|██████    | 8.63G/14.1G [07:12<04:28, 20.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  61%|██████    | 8.64G/14.1G [07:13<04:33, 20.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  61%|██████    | 8.65G/14.1G [07:13<04:10, 21.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  61%|██████▏   | 8.66G/14.1G [07:14<04:22, 20.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  61%|██████▏   | 8.67G/14.1G [07:15<04:30, 20.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  61%|██████▏   | 8.68G/14.1G [07:15<04:08, 21.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  61%|██████▏   | 8.69G/14.1G [07:15<04:20, 20.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  62%|██████▏   | 8.70G/14.1G [07:16<04:28, 20.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  62%|██████▏   | 8.71G/14.1G [07:16<04:06, 22.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  62%|██████▏   | 8.72G/14.1G [07:17<04:18, 21.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  62%|██████▏   | 8.73G/14.1G [07:17<04:26, 20.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  62%|██████▏   | 8.75G/14.1G [07:18<04:05, 22.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  62%|██████▏   | 8.76G/14.1G [07:18<04:16, 21.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  62%|██████▏   | 8.77G/14.1G [07:19<04:24, 20.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  62%|██████▏   | 8.78G/14.1G [07:19<04:04, 21.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  62%|██████▏   | 8.79G/14.1G [07:20<04:16, 20.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  62%|██████▏   | 8.80G/14.1G [07:20<04:24, 20.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  62%|██████▏   | 8.81G/14.1G [07:21<04:29, 19.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  62%|██████▏   | 8.82G/14.1G [07:21<04:08, 21.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  62%|██████▏   | 8.83G/14.1G [07:22<04:16, 20.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  63%|██████▎   | 8.84G/14.1G [07:22<03:58, 22.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  63%|██████▎   | 8.85G/14.1G [07:23<04:08, 21.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  63%|██████▎   | 8.86G/14.1G [07:23<03:52, 22.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  63%|██████▎   | 8.87G/14.1G [07:24<04:06, 21.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  63%|██████▎   | 8.88G/14.1G [07:24<04:14, 20.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  63%|██████▎   | 8.89G/14.1G [07:25<03:56, 22.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  63%|██████▎   | 8.90G/14.1G [07:25<04:06, 21.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  63%|██████▎   | 8.91G/14.1G [07:26<03:51, 22.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  63%|██████▎   | 8.92G/14.1G [07:26<04:04, 21.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  63%|██████▎   | 8.93G/14.1G [07:27<03:47, 22.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  63%|██████▎   | 8.94G/14.1G [07:27<04:01, 21.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  63%|██████▎   | 8.95G/14.1G [07:28<04:11, 20.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  63%|██████▎   | 8.97G/14.1G [07:28<03:52, 22.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  63%|██████▎   | 8.98G/14.1G [07:29<04:04, 21.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  64%|██████▎   | 8.99G/14.1G [07:29<04:12, 20.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  64%|██████▎   | 9.00G/14.1G [07:30<03:52, 22.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  64%|██████▎   | 9.01G/14.1G [07:30<04:03, 21.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  64%|██████▍   | 9.02G/14.1G [07:31<03:46, 22.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  64%|██████▍   | 9.03G/14.1G [07:31<03:59, 21.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  64%|██████▍   | 9.04G/14.1G [07:32<03:43, 22.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  64%|██████▍   | 9.05G/14.1G [07:32<03:56, 21.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  64%|██████▍   | 9.06G/14.1G [07:33<04:06, 20.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  64%|██████▍   | 9.07G/14.1G [07:33<04:13, 20.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  64%|██████▍   | 9.08G/14.1G [07:34<03:52, 21.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  64%|██████▍   | 9.09G/14.1G [07:34<04:03, 20.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  64%|██████▍   | 9.10G/14.1G [07:35<04:10, 20.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  64%|██████▍   | 9.11G/14.1G [07:35<03:49, 21.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  65%|██████▍   | 9.12G/14.1G [07:36<04:00, 20.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  65%|██████▍   | 9.13G/14.1G [07:36<04:07, 20.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  65%|██████▍   | 9.14G/14.1G [07:37<03:47, 22.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  65%|██████▍   | 9.15G/14.1G [07:37<03:57, 20.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  65%|██████▍   | 9.16G/14.1G [07:38<04:07, 20.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  65%|██████▍   | 9.18G/14.1G [07:38<04:12, 19.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  65%|██████▍   | 9.19G/14.1G [07:39<03:50, 21.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  65%|██████▌   | 9.20G/14.1G [07:39<03:59, 20.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  65%|██████▌   | 9.21G/14.1G [07:40<03:40, 22.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  65%|██████▌   | 9.22G/14.1G [07:40<03:52, 21.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  65%|██████▌   | 9.23G/14.1G [07:41<04:00, 20.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  65%|██████▌   | 9.24G/14.1G [07:41<04:05, 19.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  65%|██████▌   | 9.25G/14.1G [07:42<03:45, 21.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  65%|██████▌   | 9.26G/14.1G [07:42<03:55, 20.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  66%|██████▌   | 9.27G/14.1G [07:43<04:02, 20.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  66%|██████▌   | 9.28G/14.1G [07:43<03:42, 21.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  66%|██████▌   | 9.29G/14.1G [07:44<03:52, 20.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  66%|██████▌   | 9.30G/14.1G [07:44<03:59, 20.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  66%|██████▌   | 9.31G/14.1G [07:45<03:40, 21.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  66%|██████▌   | 9.32G/14.1G [07:45<03:50, 20.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  66%|██████▌   | 9.33G/14.1G [07:46<03:33, 22.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  66%|██████▌   | 9.34G/14.1G [07:46<03:45, 21.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  66%|██████▌   | 9.35G/14.1G [07:47<03:53, 20.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  66%|██████▌   | 9.36G/14.1G [07:47<03:59, 20.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  66%|██████▋   | 9.37G/14.1G [07:48<03:39, 21.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  66%|██████▋   | 9.38G/14.1G [07:48<03:48, 20.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  66%|██████▋   | 9.40G/14.1G [07:49<03:31, 22.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  67%|██████▋   | 9.41G/14.1G [07:49<03:47, 20.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  67%|██████▋   | 9.42G/14.1G [07:50<03:54, 20.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  67%|██████▋   | 9.43G/14.1G [07:50<03:35, 21.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  67%|██████▋   | 9.44G/14.1G [07:51<03:44, 20.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  67%|██████▋   | 9.45G/14.1G [07:51<03:29, 22.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  67%|██████▋   | 9.46G/14.1G [07:52<03:40, 21.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  67%|██████▋   | 9.47G/14.1G [07:52<03:25, 22.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  67%|██████▋   | 9.48G/14.1G [07:53<03:37, 21.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  67%|██████▋   | 9.49G/14.1G [07:53<03:46, 20.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  67%|██████▋   | 9.50G/14.1G [07:54<03:51, 20.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  67%|██████▋   | 9.51G/14.1G [07:54<03:32, 21.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  67%|██████▋   | 9.52G/14.1G [07:55<03:42, 20.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  67%|██████▋   | 9.53G/14.1G [07:55<03:25, 22.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  67%|██████▋   | 9.54G/14.1G [07:56<03:36, 21.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  68%|██████▊   | 9.55G/14.1G [07:56<03:44, 20.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  68%|██████▊   | 9.56G/14.1G [07:56<03:26, 22.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  68%|██████▊   | 9.57G/14.1G [07:57<03:36, 21.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  68%|██████▊   | 9.58G/14.1G [07:57<03:21, 22.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  68%|██████▊   | 9.59G/14.1G [07:58<03:33, 21.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  68%|██████▊   | 9.60G/14.1G [07:59<03:40, 20.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  68%|██████▊   | 9.62G/14.1G [07:59<03:23, 22.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  68%|██████▊   | 9.63G/14.1G [07:59<03:35, 21.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  68%|██████▊   | 9.64G/14.1G [08:00<03:41, 20.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  68%|██████▊   | 9.65G/14.1G [08:00<03:23, 22.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  68%|██████▊   | 9.66G/14.1G [08:01<03:33, 21.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  68%|██████▊   | 9.67G/14.1G [08:01<03:18, 22.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  68%|██████▊   | 9.68G/14.1G [08:02<03:29, 21.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  69%|██████▊   | 9.69G/14.1G [08:02<03:38, 20.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  69%|██████▊   | 9.70G/14.1G [08:03<03:44, 19.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  69%|██████▊   | 9.71G/14.1G [08:03<03:24, 21.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  69%|██████▉   | 9.72G/14.1G [08:04<03:33, 20.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  69%|██████▉   | 9.73G/14.1G [08:04<03:17, 22.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  69%|██████▉   | 9.74G/14.1G [08:05<03:27, 21.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  69%|██████▉   | 9.75G/14.1G [08:06<03:58, 18.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  69%|██████▉   | 9.76G/14.1G [08:06<03:56, 18.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  69%|██████▉   | 9.77G/14.1G [08:07<03:55, 18.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  69%|██████▉   | 9.78G/14.1G [08:07<03:53, 18.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  69%|██████▉   | 9.79G/14.1G [08:08<03:52, 18.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  69%|██████▉   | 9.80G/14.1G [08:08<03:51, 18.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  69%|██████▉   | 9.81G/14.1G [08:09<03:29, 20.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  69%|██████▉   | 9.83G/14.1G [08:09<03:35, 20.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  70%|██████▉   | 9.84G/14.1G [08:10<03:17, 21.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  70%|██████▉   | 9.85G/14.1G [08:10<03:26, 20.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  70%|██████▉   | 9.86G/14.1G [08:11<03:32, 20.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  70%|██████▉   | 9.87G/14.1G [08:11<03:14, 21.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  70%|██████▉   | 9.88G/14.1G [08:12<03:24, 20.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  70%|██████▉   | 9.89G/14.1G [08:12<03:30, 20.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  70%|███████   | 9.90G/14.1G [08:13<03:13, 21.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  70%|███████   | 9.91G/14.1G [08:13<03:21, 20.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  70%|███████   | 9.92G/14.1G [08:14<03:28, 20.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  70%|███████   | 9.93G/14.1G [08:14<03:11, 22.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  70%|███████   | 9.94G/14.1G [08:15<03:20, 21.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  70%|███████   | 9.95G/14.1G [08:15<03:26, 20.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  70%|███████   | 9.96G/14.1G [08:16<03:09, 22.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  71%|███████   | 9.97G/14.1G [08:16<03:18, 20.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  71%|███████   | 9.98G/14.1G [08:17<03:24, 20.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  71%|███████   | 9.99G/14.1G [08:17<03:08, 22.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  71%|███████   | 10.0G/14.1G [08:18<03:17, 21.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  71%|███████   | 10.0G/14.1G [08:18<03:03, 22.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  71%|███████   | 10.0G/14.1G [08:19<03:13, 21.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  71%|███████   | 10.0G/14.1G [08:19<03:20, 20.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  71%|███████   | 10.0G/14.1G [08:20<03:05, 22.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  71%|███████   | 10.1G/14.1G [08:20<03:13, 21.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  71%|███████   | 10.1G/14.1G [08:21<03:00, 22.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  71%|███████▏  | 10.1G/14.1G [08:21<03:10, 21.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  71%|███████▏  | 10.1G/14.1G [08:22<03:17, 20.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  71%|███████▏  | 10.1G/14.1G [08:22<03:21, 20.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  71%|███████▏  | 10.1G/14.1G [08:23<03:05, 21.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  72%|███████▏  | 10.1G/14.1G [08:23<03:13, 20.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  72%|███████▏  | 10.1G/14.1G [08:24<03:18, 20.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  72%|███████▏  | 10.1G/14.1G [08:24<03:02, 21.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  72%|███████▏  | 10.2G/14.1G [08:25<03:11, 20.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  72%|███████▏  | 10.2G/14.1G [08:25<03:16, 20.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  72%|███████▏  | 10.2G/14.1G [08:26<03:05, 21.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  72%|███████▏  | 10.2G/14.1G [08:26<03:08, 21.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  72%|███████▏  | 10.2G/14.1G [08:27<03:14, 20.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  72%|███████▏  | 10.2G/14.1G [08:27<02:58, 22.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  72%|███████▏  | 10.2G/14.1G [08:28<03:07, 21.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  72%|███████▏  | 10.2G/14.1G [08:28<03:13, 20.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  72%|███████▏  | 10.2G/14.1G [08:29<02:57, 22.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  72%|███████▏  | 10.2G/14.1G [08:29<03:05, 21.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  73%|███████▎  | 10.3G/14.1G [08:30<02:52, 22.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  73%|███████▎  | 10.3G/14.1G [08:30<03:01, 21.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  73%|███████▎  | 10.3G/14.1G [08:31<03:08, 20.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  73%|███████▎  | 10.3G/14.1G [08:31<02:55, 22.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  73%|███████▎  | 10.3G/14.1G [08:32<03:03, 20.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  73%|███████▎  | 10.3G/14.1G [08:32<03:08, 20.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  73%|███████▎  | 10.3G/14.1G [08:33<02:53, 22.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  73%|███████▎  | 10.3G/14.1G [08:33<03:01, 21.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  73%|███████▎  | 10.3G/14.1G [08:34<02:52, 22.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  73%|███████▎  | 10.3G/14.1G [08:34<02:56, 21.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  73%|███████▎  | 10.4G/14.1G [08:35<03:02, 20.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  73%|███████▎  | 10.4G/14.1G [08:35<02:50, 22.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  73%|███████▎  | 10.4G/14.1G [08:36<02:59, 20.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  73%|███████▎  | 10.4G/14.1G [08:36<03:02, 20.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  74%|███████▎  | 10.4G/14.1G [08:37<02:50, 21.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  74%|███████▎  | 10.4G/14.1G [08:37<02:56, 21.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  74%|███████▎  | 10.4G/14.1G [08:37<02:46, 22.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  74%|███████▍  | 10.4G/14.1G [08:38<02:55, 21.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  74%|███████▍  | 10.4G/14.1G [08:39<02:57, 20.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  74%|███████▍  | 10.5G/14.1G [08:39<02:47, 22.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  74%|███████▍  | 10.5G/14.1G [08:40<02:52, 21.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  74%|███████▍  | 10.5G/14.1G [08:40<02:43, 22.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  74%|███████▍  | 10.5G/14.1G [08:40<02:48, 21.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  74%|███████▍  | 10.5G/14.1G [08:41<02:56, 20.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  74%|███████▍  | 10.5G/14.1G [08:42<03:05, 19.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  74%|███████▍  | 10.5G/14.1G [08:42<03:07, 19.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  74%|███████▍  | 10.5G/14.1G [08:43<03:08, 19.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  75%|███████▍  | 10.5G/14.1G [08:43<03:08, 19.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  75%|███████▍  | 10.5G/14.1G [08:44<02:51, 20.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  75%|███████▍  | 10.6G/14.1G [08:44<02:56, 20.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  75%|███████▍  | 10.6G/14.1G [08:45<03:00, 19.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  75%|███████▍  | 10.6G/14.1G [08:45<02:48, 21.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  75%|███████▍  | 10.6G/14.1G [08:46<02:50, 20.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  75%|███████▍  | 10.6G/14.1G [08:46<02:55, 20.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  75%|███████▌  | 10.6G/14.1G [08:47<02:59, 19.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  75%|███████▌  | 10.6G/14.1G [08:47<02:43, 21.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  75%|███████▌  | 10.6G/14.1G [08:48<02:49, 20.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  75%|███████▌  | 10.6G/14.1G [08:48<02:54, 20.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  75%|███████▌  | 10.7G/14.1G [08:49<02:40, 21.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  75%|███████▌  | 10.7G/14.1G [08:49<02:46, 20.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  76%|███████▌  | 10.7G/14.1G [08:50<02:34, 22.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  76%|███████▌  | 10.7G/14.1G [08:50<02:42, 21.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  76%|███████▌  | 10.7G/14.1G [08:51<02:48, 20.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  76%|███████▌  | 10.7G/14.1G [08:51<02:35, 22.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  76%|███████▌  | 10.7G/14.1G [08:52<03:00, 18.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  76%|███████▌  | 10.7G/14.1G [08:52<03:00, 18.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  76%|███████▌  | 10.7G/14.1G [08:53<03:00, 18.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  76%|███████▌  | 10.7G/14.1G [08:54<03:00, 18.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  76%|███████▌  | 10.8G/14.1G [08:54<02:59, 18.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  76%|███████▌  | 10.8G/14.1G [08:55<02:58, 18.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  76%|███████▌  | 10.8G/14.1G [08:55<02:58, 18.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  76%|███████▋  | 10.8G/14.1G [08:56<02:57, 18.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  76%|███████▋  | 10.8G/14.1G [08:56<02:57, 18.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  76%|███████▋  | 10.8G/14.1G [08:57<02:52, 19.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  77%|███████▋  | 10.8G/14.1G [08:57<02:53, 19.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  77%|███████▋  | 10.8G/14.1G [08:58<02:40, 20.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  77%|███████▋  | 10.8G/14.1G [08:58<02:41, 20.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  77%|███████▋  | 10.9G/14.1G [08:59<02:44, 19.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  77%|███████▋  | 10.9G/14.1G [08:59<02:34, 21.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  77%|███████▋  | 10.9G/14.1G [09:00<02:36, 20.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  77%|███████▋  | 10.9G/14.1G [09:00<02:41, 20.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  77%|███████▋  | 10.9G/14.1G [09:01<02:30, 21.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  77%|███████▋  | 10.9G/14.1G [09:01<02:34, 21.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  77%|███████▋  | 10.9G/14.1G [09:02<02:38, 20.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  77%|███████▋  | 10.9G/14.1G [09:02<02:28, 21.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  77%|███████▋  | 10.9G/14.1G [09:03<02:32, 21.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  77%|███████▋  | 10.9G/14.1G [09:03<02:37, 20.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  78%|███████▊  | 11.0G/14.1G [09:04<02:26, 21.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  78%|███████▊  | 11.0G/14.1G [09:04<02:30, 21.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  78%|███████▊  | 11.0G/14.1G [09:05<02:35, 20.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  78%|███████▊  | 11.0G/14.1G [09:05<02:24, 21.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  78%|███████▊  | 11.0G/14.1G [09:06<02:28, 21.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  78%|███████▊  | 11.0G/14.1G [09:06<02:33, 20.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  78%|███████▊  | 11.0G/14.1G [09:07<02:23, 21.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  78%|███████▊  | 11.0G/14.1G [09:07<02:27, 21.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  78%|███████▊  | 11.0G/14.1G [09:08<02:18, 22.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  78%|███████▊  | 11.1G/14.1G [09:08<02:26, 21.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  78%|███████▊  | 11.1G/14.1G [09:09<02:28, 20.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  78%|███████▊  | 11.1G/14.1G [09:09<02:19, 22.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  78%|███████▊  | 11.1G/14.1G [09:10<02:23, 21.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  78%|███████▊  | 11.1G/14.1G [09:10<02:28, 20.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  79%|███████▊  | 11.1G/14.1G [09:11<02:18, 21.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  79%|███████▊  | 11.1G/14.1G [09:11<02:23, 21.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  79%|███████▊  | 11.1G/14.1G [09:12<02:27, 20.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  79%|███████▉  | 11.1G/14.1G [09:12<02:15, 22.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  79%|███████▉  | 11.1G/14.1G [09:13<02:22, 21.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  79%|███████▉  | 11.2G/14.1G [09:13<02:26, 20.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  79%|███████▉  | 11.2G/14.1G [09:14<02:15, 22.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  79%|███████▉  | 11.2G/14.1G [09:14<02:21, 20.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  79%|███████▉  | 11.2G/14.1G [09:15<02:10, 22.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  79%|███████▉  | 11.2G/14.1G [09:15<02:17, 21.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  79%|███████▉  | 11.2G/14.1G [09:16<02:23, 20.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  79%|███████▉  | 11.2G/14.1G [09:16<02:11, 22.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  79%|███████▉  | 11.2G/14.1G [09:17<02:18, 21.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  80%|███████▉  | 11.2G/14.1G [09:17<02:22, 20.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  80%|███████▉  | 11.3G/14.1G [09:18<02:10, 22.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  80%|███████▉  | 11.3G/14.1G [09:18<02:16, 21.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  80%|███████▉  | 11.3G/14.1G [09:19<02:21, 20.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  80%|███████▉  | 11.3G/14.1G [09:19<02:09, 22.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  80%|███████▉  | 11.3G/14.1G [09:20<02:15, 21.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  80%|███████▉  | 11.3G/14.1G [09:20<02:05, 22.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  80%|████████  | 11.3G/14.1G [09:21<02:12, 21.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  80%|████████  | 11.3G/14.1G [09:21<02:17, 20.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  80%|████████  | 11.3G/14.1G [09:22<02:06, 22.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  80%|████████  | 11.3G/14.1G [09:22<02:12, 21.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  80%|████████  | 11.4G/14.1G [09:23<02:16, 20.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  80%|████████  | 11.4G/14.1G [09:23<02:05, 22.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  80%|████████  | 11.4G/14.1G [09:24<02:11, 21.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  81%|████████  | 11.4G/14.1G [09:24<02:15, 20.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  81%|████████  | 11.4G/14.1G [09:25<02:05, 21.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  81%|████████  | 11.4G/14.1G [09:25<02:10, 20.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  81%|████████  | 11.4G/14.1G [09:26<02:01, 22.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  81%|████████  | 11.4G/14.1G [09:26<02:06, 21.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  81%|████████  | 11.4G/14.1G [09:27<02:11, 20.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  81%|████████  | 11.5G/14.1G [09:27<02:01, 22.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  81%|████████  | 11.5G/14.1G [09:28<02:07, 21.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  81%|████████  | 11.5G/14.1G [09:28<01:57, 22.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  81%|████████  | 11.5G/14.1G [09:28<02:04, 21.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  81%|████████▏ | 11.5G/14.1G [09:29<02:08, 20.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  81%|████████▏ | 11.5G/14.1G [09:29<01:58, 22.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  81%|████████▏ | 11.5G/14.1G [09:30<02:04, 21.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  82%|████████▏ | 11.5G/14.1G [09:31<02:08, 20.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  82%|████████▏ | 11.5G/14.1G [09:31<01:58, 22.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  82%|████████▏ | 11.5G/14.1G [09:31<02:03, 21.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  82%|████████▏ | 11.6G/14.1G [09:32<02:07, 20.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  82%|████████▏ | 11.6G/14.1G [09:32<01:56, 22.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  82%|████████▏ | 11.6G/14.1G [09:33<02:02, 21.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  82%|████████▏ | 11.6G/14.1G [09:34<02:06, 20.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  82%|████████▏ | 11.6G/14.1G [09:34<02:08, 19.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  82%|████████▏ | 11.6G/14.1G [09:34<01:57, 21.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  82%|████████▏ | 11.6G/14.1G [09:35<02:01, 20.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  82%|████████▏ | 11.6G/14.1G [09:36<02:04, 20.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  82%|████████▏ | 11.6G/14.1G [09:36<01:54, 21.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  82%|████████▏ | 11.6G/14.1G [09:37<01:59, 20.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  82%|████████▏ | 11.7G/14.1G [09:37<02:02, 20.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  83%|████████▎ | 11.7G/14.1G [09:37<01:52, 22.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  83%|████████▎ | 11.7G/14.1G [09:38<01:57, 20.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  83%|████████▎ | 11.7G/14.1G [09:39<02:00, 20.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  83%|████████▎ | 11.7G/14.1G [09:39<02:16, 17.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  83%|████████▎ | 11.7G/14.1G [09:40<02:13, 18.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  83%|████████▎ | 11.7G/14.1G [09:40<02:11, 18.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  83%|████████▎ | 11.7G/14.1G [09:41<02:34, 15.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  83%|████████▎ | 11.7G/14.1G [09:42<02:33, 15.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  83%|████████▎ | 11.8G/14.1G [09:43<02:37, 15.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  83%|████████▎ | 11.8G/14.1G [09:43<02:39, 14.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  83%|████████▎ | 11.8G/14.1G [09:44<02:40, 14.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  83%|████████▎ | 11.8G/14.1G [09:45<02:34, 15.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  83%|████████▎ | 11.8G/14.1G [09:46<02:36, 14.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  84%|████████▎ | 11.8G/14.1G [09:46<02:33, 15.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  84%|████████▎ | 11.8G/14.1G [09:47<02:28, 15.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  84%|████████▎ | 11.8G/14.1G [09:48<02:32, 15.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  84%|████████▎ | 11.8G/14.1G [09:48<02:22, 16.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  84%|████████▍ | 11.8G/14.1G [09:49<02:27, 15.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  84%|████████▍ | 11.9G/14.1G [09:50<02:25, 15.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  84%|████████▍ | 11.9G/14.1G [09:50<02:22, 15.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  84%|████████▍ | 11.9G/14.1G [09:51<02:21, 15.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  84%|████████▍ | 11.9G/14.1G [09:52<02:20, 16.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  84%|████████▍ | 11.9G/14.1G [09:52<02:24, 15.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  84%|████████▍ | 11.9G/14.1G [09:53<02:16, 16.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  84%|████████▍ | 11.9G/14.1G [09:54<02:21, 15.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  84%|████████▍ | 11.9G/14.1G [09:54<02:18, 15.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  84%|████████▍ | 11.9G/14.1G [09:55<02:18, 15.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  85%|████████▍ | 12.0G/14.1G [09:55<02:15, 16.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  85%|████████▍ | 12.0G/14.1G [09:56<02:15, 16.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  85%|████████▍ | 12.0G/14.1G [09:57<02:20, 15.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  85%|████████▍ | 12.0G/14.1G [09:58<02:33, 14.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  85%|████████▍ | 12.0G/14.1G [09:59<02:32, 14.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  85%|████████▍ | 12.0G/14.1G [09:59<02:38, 13.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  85%|████████▍ | 12.0G/14.1G [10:00<02:40, 13.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  85%|████████▌ | 12.0G/14.1G [10:01<02:58, 11.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  85%|████████▌ | 12.0G/14.1G [10:03<03:27, 10.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  85%|████████▌ | 12.0G/14.1G [10:04<03:36, 9.67MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  85%|████████▌ | 12.1G/14.1G [10:05<03:41, 9.38MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  85%|████████▌ | 12.1G/14.1G [10:06<03:44, 9.22MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  85%|████████▌ | 12.1G/14.1G [10:07<03:41, 9.28MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  86%|████████▌ | 12.1G/14.1G [10:08<03:39, 9.32MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  86%|████████▌ | 12.1G/14.1G [10:10<03:44, 9.08MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  86%|████████▌ | 12.1G/14.1G [10:11<03:43, 9.05MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  86%|████████▌ | 12.1G/14.1G [10:12<03:41, 9.10MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  86%|████████▌ | 12.1G/14.1G [10:13<03:37, 9.22MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  86%|████████▌ | 12.1G/14.1G [10:14<03:34, 9.30MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  86%|████████▌ | 12.2G/14.1G [10:15<03:32, 9.36MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  86%|████████▌ | 12.2G/14.1G [10:16<03:27, 9.50MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  86%|████████▌ | 12.2G/14.1G [10:17<03:18, 9.89MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  86%|████████▌ | 12.2G/14.1G [10:18<03:09, 10.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  86%|████████▋ | 12.2G/14.1G [10:19<03:03, 10.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  86%|████████▋ | 12.2G/14.1G [10:20<02:52, 11.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  86%|████████▋ | 12.2G/14.1G [10:21<02:44, 11.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  86%|████████▋ | 12.2G/14.1G [10:22<02:34, 12.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  87%|████████▋ | 12.2G/14.1G [10:22<02:24, 13.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  87%|████████▋ | 12.2G/14.1G [10:23<02:15, 14.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  87%|████████▋ | 12.3G/14.1G [10:23<02:06, 14.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  87%|████████▋ | 12.3G/14.1G [10:24<01:57, 15.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  87%|████████▋ | 12.3G/14.1G [10:25<01:51, 16.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  87%|████████▋ | 12.3G/14.1G [10:25<01:47, 17.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  87%|████████▋ | 12.3G/14.1G [10:26<01:40, 18.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  87%|████████▋ | 12.3G/14.1G [10:26<01:33, 19.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  87%|████████▋ | 12.3G/14.1G [10:27<01:30, 20.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  87%|████████▋ | 12.3G/14.1G [10:27<01:31, 19.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  87%|████████▋ | 12.3G/14.1G [10:28<01:26, 20.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  87%|████████▋ | 12.4G/14.1G [10:28<01:25, 20.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  87%|████████▋ | 12.4G/14.1G [10:29<01:22, 21.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  88%|████████▊ | 12.4G/14.1G [10:29<01:22, 21.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  88%|████████▊ | 12.4G/14.1G [10:30<01:25, 20.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  88%|████████▊ | 12.4G/14.1G [10:30<01:21, 21.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  88%|████████▊ | 12.4G/14.1G [10:31<01:21, 21.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  88%|████████▊ | 12.4G/14.1G [10:31<01:18, 21.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  88%|████████▊ | 12.4G/14.1G [10:32<01:22, 20.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  88%|████████▊ | 12.4G/14.1G [10:32<01:21, 20.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  88%|████████▊ | 12.4G/14.1G [10:32<01:18, 21.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  88%|████████▊ | 12.5G/14.1G [10:33<01:21, 20.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  88%|████████▊ | 12.5G/14.1G [10:34<01:20, 20.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  88%|████████▊ | 12.5G/14.1G [10:34<01:16, 21.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  88%|████████▊ | 12.5G/14.1G [10:34<01:17, 21.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  88%|████████▊ | 12.5G/14.1G [10:35<01:14, 22.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  88%|████████▊ | 12.5G/14.1G [10:35<01:17, 21.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  89%|████████▊ | 12.5G/14.1G [10:36<01:17, 20.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  89%|████████▊ | 12.5G/14.1G [10:36<01:13, 21.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  89%|████████▊ | 12.5G/14.1G [10:37<01:14, 21.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  89%|████████▉ | 12.6G/14.1G [10:37<01:17, 20.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  89%|████████▉ | 12.6G/14.1G [10:38<01:18, 20.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  89%|████████▉ | 12.6G/14.1G [10:38<01:11, 21.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  89%|████████▉ | 12.6G/14.1G [10:39<01:22, 18.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  89%|████████▉ | 12.6G/14.1G [10:40<01:17, 19.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  89%|████████▉ | 12.6G/14.1G [10:40<01:15, 20.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  89%|████████▉ | 12.6G/14.1G [10:41<01:16, 19.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  89%|████████▉ | 12.6G/14.1G [10:41<01:11, 21.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  89%|████████▉ | 12.6G/14.1G [10:42<01:11, 20.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  89%|████████▉ | 12.6G/14.1G [10:42<01:07, 22.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  90%|████████▉ | 12.7G/14.1G [10:43<01:09, 21.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  90%|████████▉ | 12.7G/14.1G [10:43<01:11, 20.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  90%|████████▉ | 12.7G/14.1G [10:43<01:07, 21.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  90%|████████▉ | 12.7G/14.1G [10:44<01:08, 21.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  90%|████████▉ | 12.7G/14.1G [10:45<01:10, 20.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  90%|████████▉ | 12.7G/14.1G [10:45<01:04, 22.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  90%|████████▉ | 12.7G/14.1G [10:45<01:07, 21.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  90%|█████████ | 12.7G/14.1G [10:46<01:09, 20.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  90%|█████████ | 12.7G/14.1G [10:46<01:03, 22.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  90%|█████████ | 12.8G/14.1G [10:47<01:05, 21.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  90%|█████████ | 12.8G/14.1G [10:47<01:00, 22.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  90%|█████████ | 12.8G/14.1G [10:48<01:03, 21.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  90%|█████████ | 12.8G/14.1G [10:48<01:05, 20.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  90%|█████████ | 12.8G/14.1G [10:49<01:00, 22.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  91%|█████████ | 12.8G/14.1G [10:49<01:03, 21.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  91%|█████████ | 12.8G/14.1G [10:50<00:58, 22.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  91%|█████████ | 12.8G/14.1G [10:50<01:01, 21.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  91%|█████████ | 12.8G/14.1G [10:51<01:03, 20.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  91%|█████████ | 12.8G/14.1G [10:51<00:58, 22.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  91%|█████████ | 12.9G/14.1G [10:52<01:00, 21.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  91%|█████████ | 12.9G/14.1G [10:52<00:55, 22.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  91%|█████████ | 12.9G/14.1G [10:53<00:58, 21.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  91%|█████████ | 12.9G/14.1G [10:53<01:00, 20.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  91%|█████████ | 12.9G/14.1G [10:54<01:01, 20.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  91%|█████████▏| 12.9G/14.1G [10:54<00:56, 21.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  91%|█████████▏| 12.9G/14.1G [10:55<00:58, 20.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  91%|█████████▏| 12.9G/14.1G [10:55<00:53, 22.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  92%|█████████▏| 12.9G/14.1G [10:56<00:56, 21.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  92%|█████████▏| 12.9G/14.1G [10:56<00:57, 20.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  92%|█████████▏| 13.0G/14.1G [10:57<00:53, 22.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  92%|█████████▏| 13.0G/14.1G [10:57<00:55, 21.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  92%|█████████▏| 13.0G/14.1G [10:58<00:51, 22.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  92%|█████████▏| 13.0G/14.1G [10:58<00:53, 21.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  92%|█████████▏| 13.0G/14.1G [10:59<00:55, 20.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  92%|█████████▏| 13.0G/14.1G [10:59<00:50, 22.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  92%|█████████▏| 13.0G/14.1G [11:00<00:52, 21.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  92%|█████████▏| 13.0G/14.1G [11:00<00:54, 20.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  92%|█████████▏| 13.0G/14.1G [11:01<00:55, 19.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  92%|█████████▏| 13.1G/14.1G [11:01<00:50, 21.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  92%|█████████▏| 13.1G/14.1G [11:02<00:51, 20.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  92%|█████████▏| 13.1G/14.1G [11:02<00:52, 20.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  93%|█████████▎| 13.1G/14.1G [11:03<00:48, 21.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  93%|█████████▎| 13.1G/14.1G [11:03<00:49, 20.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  93%|█████████▎| 13.1G/14.1G [11:04<00:45, 22.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  93%|█████████▎| 13.1G/14.1G [11:04<00:47, 21.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  93%|█████████▎| 13.1G/14.1G [11:05<00:44, 22.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  93%|█████████▎| 13.1G/14.1G [11:05<00:46, 21.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  93%|█████████▎| 13.1G/14.1G [11:06<00:47, 20.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  93%|█████████▎| 13.2G/14.1G [11:06<00:44, 22.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  93%|█████████▎| 13.2G/14.1G [11:07<00:45, 21.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  93%|█████████▎| 13.2G/14.1G [11:07<00:42, 22.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  93%|█████████▎| 13.2G/14.1G [11:08<00:44, 21.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  93%|█████████▎| 13.2G/14.1G [11:08<00:45, 20.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  93%|█████████▎| 13.2G/14.1G [11:08<00:42, 22.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  94%|█████████▎| 13.2G/14.1G [11:09<00:43, 21.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  94%|█████████▎| 13.2G/14.1G [11:09<00:40, 22.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  94%|█████████▎| 13.2G/14.1G [11:10<00:41, 21.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  94%|█████████▎| 13.3G/14.1G [11:11<00:43, 20.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  94%|█████████▍| 13.3G/14.1G [11:11<00:39, 22.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  94%|█████████▍| 13.3G/14.1G [11:11<00:40, 21.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  94%|█████████▍| 13.3G/14.1G [11:12<00:37, 22.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  94%|█████████▍| 13.3G/14.1G [11:12<00:39, 21.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  94%|█████████▍| 13.3G/14.1G [11:13<00:40, 20.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  94%|█████████▍| 13.3G/14.1G [11:14<00:41, 19.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  94%|█████████▍| 13.3G/14.1G [11:14<00:45, 17.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  94%|█████████▍| 13.3G/14.1G [11:15<00:52, 15.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  94%|█████████▍| 13.3G/14.1G [11:16<00:52, 14.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  94%|█████████▍| 13.4G/14.1G [11:17<00:52, 14.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  95%|█████████▍| 13.4G/14.1G [11:17<00:52, 14.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  95%|█████████▍| 13.4G/14.1G [11:18<00:49, 15.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  95%|█████████▍| 13.4G/14.1G [11:19<00:49, 15.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  95%|█████████▍| 13.4G/14.1G [11:19<00:49, 14.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  95%|█████████▍| 13.4G/14.1G [11:20<00:49, 14.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  95%|█████████▍| 13.4G/14.1G [11:21<00:46, 15.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  95%|█████████▌| 13.4G/14.1G [11:21<00:46, 15.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  95%|█████████▌| 13.4G/14.1G [11:22<00:46, 15.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  95%|█████████▌| 13.5G/14.1G [11:23<00:45, 14.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  95%|█████████▌| 13.5G/14.1G [11:23<00:43, 15.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  95%|█████████▌| 13.5G/14.1G [11:24<00:43, 15.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  95%|█████████▌| 13.5G/14.1G [11:25<00:43, 15.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  95%|█████████▌| 13.5G/14.1G [11:26<00:40, 15.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  96%|█████████▌| 13.5G/14.1G [11:26<00:41, 15.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  96%|█████████▌| 13.5G/14.1G [11:27<00:40, 15.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  96%|█████████▌| 13.5G/14.1G [11:28<00:41, 14.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  96%|█████████▌| 13.5G/14.1G [11:29<00:44, 13.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  96%|█████████▌| 13.5G/14.1G [11:29<00:43, 13.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  96%|█████████▌| 13.6G/14.1G [11:30<00:44, 13.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  96%|█████████▌| 13.6G/14.1G [11:31<00:42, 13.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  96%|█████████▌| 13.6G/14.1G [11:32<00:40, 13.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  96%|█████████▌| 13.6G/14.1G [11:32<00:39, 13.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  96%|█████████▌| 13.6G/14.1G [11:33<00:37, 14.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  96%|█████████▋| 13.6G/14.1G [11:34<00:35, 14.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  96%|█████████▋| 13.6G/14.1G [11:35<00:35, 14.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  96%|█████████▋| 13.6G/14.1G [11:35<00:34, 14.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  96%|█████████▋| 13.6G/14.1G [11:36<00:32, 15.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  97%|█████████▋| 13.7G/14.1G [11:37<00:32, 15.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  97%|█████████▋| 13.7G/14.1G [11:37<00:31, 15.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  97%|█████████▋| 13.7G/14.1G [11:38<00:29, 15.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  97%|█████████▋| 13.7G/14.1G [11:39<00:29, 15.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  97%|█████████▋| 13.7G/14.1G [11:39<00:29, 15.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  97%|█████████▋| 13.7G/14.1G [11:40<00:27, 15.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  97%|█████████▋| 13.7G/14.1G [11:41<00:27, 15.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  97%|█████████▋| 13.7G/14.1G [11:41<00:26, 15.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  97%|█████████▋| 13.7G/14.1G [11:42<00:25, 15.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  97%|█████████▋| 13.7G/14.1G [11:43<00:25, 15.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  97%|█████████▋| 13.8G/14.1G [11:43<00:23, 16.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  97%|█████████▋| 13.8G/14.1G [11:44<00:23, 15.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  97%|█████████▋| 13.8G/14.1G [11:45<00:23, 15.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  98%|█████████▊| 13.8G/14.1G [11:45<00:21, 15.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  98%|█████████▊| 13.8G/14.1G [11:46<00:20, 16.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  98%|█████████▊| 13.8G/14.1G [11:47<00:20, 15.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  98%|█████████▊| 13.8G/14.1G [11:47<00:19, 16.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  98%|█████████▊| 13.8G/14.1G [11:48<00:18, 16.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  98%|█████████▊| 13.8G/14.1G [11:48<00:18, 16.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  98%|█████████▊| 13.9G/14.1G [11:49<00:17, 16.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  98%|█████████▊| 13.9G/14.1G [11:50<00:15, 17.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  98%|█████████▊| 13.9G/14.1G [11:50<00:14, 17.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  98%|█████████▊| 13.9G/14.1G [11:51<00:14, 18.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  98%|█████████▊| 13.9G/14.1G [11:51<00:12, 20.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  98%|█████████▊| 13.9G/14.1G [11:52<00:11, 19.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  98%|█████████▊| 13.9G/14.1G [11:52<00:11, 19.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  98%|█████████▊| 13.9G/14.1G [11:53<00:10, 21.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  99%|█████████▊| 13.9G/14.1G [11:53<00:09, 20.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  99%|█████████▊| 13.9G/14.1G [11:54<00:09, 20.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  99%|█████████▊| 14.0G/14.1G [11:54<00:09, 19.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  99%|█████████▉| 14.0G/14.1G [11:55<00:07, 21.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  99%|█████████▉| 14.0G/14.1G [11:55<00:07, 20.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  99%|█████████▉| 14.0G/14.1G [11:56<00:06, 22.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  99%|█████████▉| 14.0G/14.1G [11:56<00:06, 21.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  99%|█████████▉| 14.0G/14.1G [11:57<00:05, 22.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  99%|█████████▉| 14.0G/14.1G [11:57<00:05, 21.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  99%|█████████▉| 14.0G/14.1G [11:58<00:05, 18.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  99%|█████████▉| 14.0G/14.1G [11:58<00:05, 18.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  99%|█████████▉| 14.1G/14.1G [11:59<00:04, 20.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";:  99%|█████████▉| 14.1G/14.1G [11:59<00:03, 20.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";: 100%|█████████▉| 14.1G/14.1G [12:00<00:03, 19.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";: 100%|█████████▉| 14.1G/14.1G [12:00<00:02, 21.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";: 100%|█████████▉| 14.1G/14.1G [12:01<00:02, 20.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";: 100%|█████████▉| 14.1G/14.1G [12:01<00:01, 20.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";: 100%|█████████▉| 14.1G/14.1G [12:02<00:01, 21.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";: 100%|█████████▉| 14.1G/14.1G [12:02<00:00, 20.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";: 100%|█████████▉| 14.1G/14.1G [12:03<00:00, 22.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";: 100%|██████████| 14.1G/14.1G [12:03<00:00, 21.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"pytorch_model.bin\";: 100%|██████████| 14.1G/14.1G [12:03<00:00, 19.5MB/s]\u001b[0m\n",
      "\u001b[34mtrainable params: 3932160 || all params: 7072948224 || trainable%: 0.055594355783029126\u001b[0m\n",
      "\u001b[34m0%|          | 0/1932 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[2023-08-09 02:43:46.594: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.27.1 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\u001b[0m\n",
      "\u001b[34mINFO:root:Using NamedTuple = typing._NamedTuple instead.\u001b[0m\n",
      "\u001b[34m[2023-08-09 02:43:46.650 algo-1:58 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2023-08-09 02:43:46.686 algo-1:58 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2023-08-09 02:43:46.686 algo-1:58 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2023-08-09 02:43:46.687 algo-1:58 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2023-08-09 02:43:46.687 algo-1:58 INFO hook.py:259] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2023-08-09 02:43:46.687 algo-1:58 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/bitsandbytes/autograd/_functions.py:298: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/bitsandbytes/autograd/_functions.py:298: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\u001b[0m\n",
      "\u001b[34m0%|          | 1/1932 [00:12<6:27:10, 12.03s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 2/1932 [00:21<5:36:21, 10.46s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 3/1932 [00:30<5:19:45,  9.95s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 4/1932 [00:40<5:12:00,  9.71s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 5/1932 [00:49<5:07:43,  9.58s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 6/1932 [00:58<5:05:05,  9.50s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 7/1932 [01:08<5:03:26,  9.46s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 8/1932 [01:17<5:02:23,  9.43s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 9/1932 [01:26<5:01:35,  9.41s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 10/1932 [01:36<5:01:00,  9.40s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.7307, 'learning_rate': 0.0001989648033126294, 'epoch': 0.02}\u001b[0m\n",
      "\u001b[34m1%|          | 10/1932 [01:36<5:01:00,  9.40s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 11/1932 [01:45<5:00:32,  9.39s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 12/1932 [01:54<5:00:09,  9.38s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 13/1932 [02:04<4:59:48,  9.37s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 14/1932 [02:13<4:59:34,  9.37s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 15/1932 [02:23<4:59:21,  9.37s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 16/1932 [02:32<4:59:11,  9.37s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 17/1932 [02:41<4:59:00,  9.37s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 18/1932 [02:51<4:58:56,  9.37s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 19/1932 [03:00<4:58:45,  9.37s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 20/1932 [03:09<4:58:36,  9.37s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.4118, 'learning_rate': 0.00019792960662525882, 'epoch': 0.03}\u001b[0m\n",
      "\u001b[34m1%|          | 20/1932 [03:09<4:58:36,  9.37s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 21/1932 [03:19<4:58:32,  9.37s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 22/1932 [03:28<4:58:20,  9.37s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 23/1932 [03:38<4:58:07,  9.37s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 24/1932 [03:47<4:58:02,  9.37s/it]\u001b[0m\n",
      "\u001b[34m1%|▏         | 25/1932 [03:56<4:57:56,  9.37s/it]\u001b[0m\n",
      "\u001b[34m1%|▏         | 26/1932 [04:06<4:57:46,  9.37s/it]\u001b[0m\n",
      "\u001b[34m1%|▏         | 27/1932 [04:15<4:57:38,  9.37s/it]\u001b[0m\n",
      "\u001b[34m1%|▏         | 28/1932 [04:24<4:57:30,  9.38s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 29/1932 [04:34<4:57:21,  9.38s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 30/1932 [04:43<4:57:14,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.3797, 'learning_rate': 0.00019689440993788822, 'epoch': 0.05}\u001b[0m\n",
      "\u001b[34m2%|▏         | 30/1932 [04:43<4:57:14,  9.38s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 31/1932 [04:53<4:57:04,  9.38s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 32/1932 [05:02<4:56:56,  9.38s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 33/1932 [05:11<4:56:47,  9.38s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 34/1932 [05:21<4:56:42,  9.38s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 35/1932 [05:30<4:56:33,  9.38s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 36/1932 [05:39<4:56:19,  9.38s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 37/1932 [05:49<4:56:07,  9.38s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 38/1932 [05:58<4:55:59,  9.38s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 39/1932 [06:08<4:55:45,  9.37s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 40/1932 [06:17<4:55:38,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.3869, 'learning_rate': 0.0001958592132505176, 'epoch': 0.06}\u001b[0m\n",
      "\u001b[34m2%|▏         | 40/1932 [06:17<4:55:38,  9.38s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 41/1932 [06:26<4:55:28,  9.38s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 42/1932 [06:36<4:55:15,  9.37s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 43/1932 [06:45<4:55:07,  9.37s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 44/1932 [06:54<4:54:56,  9.37s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 45/1932 [07:04<4:54:50,  9.37s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 46/1932 [07:13<4:54:40,  9.37s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 47/1932 [07:23<4:54:32,  9.38s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 48/1932 [07:32<4:54:25,  9.38s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 49/1932 [07:41<4:54:15,  9.38s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 50/1932 [07:51<4:54:09,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.363, 'learning_rate': 0.000194824016563147, 'epoch': 0.08}\u001b[0m\n",
      "\u001b[34m3%|▎         | 50/1932 [07:51<4:54:09,  9.38s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 51/1932 [08:00<4:54:00,  9.38s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 52/1932 [08:09<4:53:48,  9.38s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 53/1932 [08:19<4:53:39,  9.38s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 54/1932 [08:28<4:53:30,  9.38s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 55/1932 [08:38<4:53:19,  9.38s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 56/1932 [08:47<4:53:07,  9.37s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 57/1932 [08:56<4:53:01,  9.38s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 58/1932 [09:06<4:52:54,  9.38s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 59/1932 [09:15<4:52:45,  9.38s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 60/1932 [09:24<4:52:38,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.3193, 'learning_rate': 0.00019378881987577642, 'epoch': 0.09}\u001b[0m\n",
      "\u001b[34m3%|▎         | 60/1932 [09:24<4:52:38,  9.38s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 61/1932 [09:34<4:52:29,  9.38s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 62/1932 [09:43<4:52:20,  9.38s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 63/1932 [09:53<4:52:10,  9.38s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 64/1932 [10:02<4:52:00,  9.38s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 65/1932 [10:11<4:51:50,  9.38s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 66/1932 [10:21<4:51:38,  9.38s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 67/1932 [10:30<4:51:27,  9.38s/it]\u001b[0m\n",
      "\u001b[34m4%|▎         | 68/1932 [10:39<4:51:16,  9.38s/it]\u001b[0m\n",
      "\u001b[34m4%|▎         | 69/1932 [10:49<4:51:10,  9.38s/it]\u001b[0m\n",
      "\u001b[34m4%|▎         | 70/1932 [10:58<4:51:01,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2971, 'learning_rate': 0.0001927536231884058, 'epoch': 0.11}\u001b[0m\n",
      "\u001b[34m4%|▎         | 70/1932 [10:58<4:51:01,  9.38s/it]\u001b[0m\n",
      "\u001b[34m4%|▎         | 71/1932 [11:08<4:50:51,  9.38s/it]\u001b[0m\n",
      "\u001b[34m4%|▎         | 72/1932 [11:17<4:50:41,  9.38s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 73/1932 [11:26<4:50:34,  9.38s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 74/1932 [11:36<4:50:25,  9.38s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 75/1932 [11:45<4:50:13,  9.38s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 76/1932 [11:55<4:50:03,  9.38s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 77/1932 [12:04<4:49:53,  9.38s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 78/1932 [12:13<4:49:43,  9.38s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 79/1932 [12:23<4:49:38,  9.38s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 80/1932 [12:32<4:49:29,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2631, 'learning_rate': 0.0001917184265010352, 'epoch': 0.12}\u001b[0m\n",
      "\u001b[34m4%|▍         | 80/1932 [12:32<4:49:29,  9.38s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 81/1932 [12:41<4:49:19,  9.38s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 82/1932 [12:51<4:49:09,  9.38s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 83/1932 [13:00<4:48:56,  9.38s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 84/1932 [13:10<4:48:46,  9.38s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 85/1932 [13:19<4:48:37,  9.38s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 86/1932 [13:28<4:48:32,  9.38s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 87/1932 [13:38<4:48:21,  9.38s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 88/1932 [13:47<4:48:13,  9.38s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 89/1932 [13:56<4:48:02,  9.38s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 90/1932 [14:06<4:47:52,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2839, 'learning_rate': 0.0001906832298136646, 'epoch': 0.14}\u001b[0m\n",
      "\u001b[34m5%|▍         | 90/1932 [14:06<4:47:52,  9.38s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 91/1932 [14:15<4:47:44,  9.38s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 92/1932 [14:25<4:47:35,  9.38s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 93/1932 [14:34<4:47:25,  9.38s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 94/1932 [14:43<4:47:14,  9.38s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 95/1932 [14:53<4:47:03,  9.38s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 96/1932 [15:02<4:46:52,  9.38s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 97/1932 [15:11<4:46:44,  9.38s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 98/1932 [15:21<4:46:36,  9.38s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 99/1932 [15:30<4:46:26,  9.38s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 100/1932 [15:40<4:46:17,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2759, 'learning_rate': 0.000189648033126294, 'epoch': 0.16}\u001b[0m\n",
      "\u001b[34m5%|▌         | 100/1932 [15:40<4:46:17,  9.38s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 101/1932 [15:49<4:46:07,  9.38s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 102/1932 [15:58<4:45:59,  9.38s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 103/1932 [16:08<4:45:49,  9.38s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 104/1932 [16:17<4:45:44,  9.38s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 105/1932 [16:26<4:45:34,  9.38s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 106/1932 [16:36<4:45:23,  9.38s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 107/1932 [16:45<4:45:14,  9.38s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 108/1932 [16:55<4:45:02,  9.38s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 109/1932 [17:04<4:44:55,  9.38s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 110/1932 [17:13<4:44:43,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2996, 'learning_rate': 0.0001886128364389234, 'epoch': 0.17}\u001b[0m\n",
      "\u001b[34m6%|▌         | 110/1932 [17:13<4:44:43,  9.38s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 111/1932 [17:23<4:44:34,  9.38s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 112/1932 [17:32<4:44:24,  9.38s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 113/1932 [17:41<4:44:13,  9.38s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 114/1932 [17:51<4:44:07,  9.38s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 115/1932 [18:00<4:43:59,  9.38s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 116/1932 [18:10<4:43:48,  9.38s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 117/1932 [18:19<4:43:40,  9.38s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 118/1932 [18:28<4:43:30,  9.38s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 119/1932 [18:38<4:43:20,  9.38s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 120/1932 [18:47<4:43:10,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.3058, 'learning_rate': 0.0001875776397515528, 'epoch': 0.19}\u001b[0m\n",
      "\u001b[34m6%|▌         | 120/1932 [18:47<4:43:10,  9.38s/it]\u001b[0m\n",
      "\u001b[34m6%|▋         | 121/1932 [18:56<4:43:00,  9.38s/it]\u001b[0m\n",
      "\u001b[34m6%|▋         | 122/1932 [19:06<4:42:48,  9.38s/it]\u001b[0m\n",
      "\u001b[34m6%|▋         | 123/1932 [19:15<4:42:44,  9.38s/it]\u001b[0m\n",
      "\u001b[34m6%|▋         | 124/1932 [19:25<4:42:33,  9.38s/it]\u001b[0m\n",
      "\u001b[34m6%|▋         | 125/1932 [19:34<4:42:26,  9.38s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 126/1932 [19:43<4:42:19,  9.38s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 127/1932 [19:53<4:42:06,  9.38s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 128/1932 [20:02<4:41:56,  9.38s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 129/1932 [20:11<4:41:47,  9.38s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 130/1932 [20:21<4:41:37,  9.38s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 130/1932 [20:21<4:41:37,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2961, 'learning_rate': 0.0001865424430641822, 'epoch': 0.2}\u001b[0m\n",
      "\u001b[34m7%|▋         | 131/1932 [20:30<4:41:28,  9.38s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 132/1932 [20:40<4:41:21,  9.38s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 133/1932 [20:49<4:41:12,  9.38s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 134/1932 [20:58<4:41:03,  9.38s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 135/1932 [21:08<4:40:53,  9.38s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 136/1932 [21:17<4:40:43,  9.38s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 137/1932 [21:27<4:40:32,  9.38s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 138/1932 [21:36<4:40:21,  9.38s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 139/1932 [21:45<4:40:15,  9.38s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 140/1932 [21:55<4:40:05,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2612, 'learning_rate': 0.0001855072463768116, 'epoch': 0.22}\u001b[0m\n",
      "\u001b[34m7%|▋         | 140/1932 [21:55<4:40:05,  9.38s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 141/1932 [22:04<4:39:57,  9.38s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 142/1932 [22:13<4:39:48,  9.38s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 143/1932 [22:23<4:39:42,  9.38s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 144/1932 [22:32<4:39:33,  9.38s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 145/1932 [22:42<4:39:19,  9.38s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 146/1932 [22:51<4:39:09,  9.38s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 147/1932 [23:00<4:39:00,  9.38s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 148/1932 [23:10<4:38:50,  9.38s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 149/1932 [23:19<4:38:41,  9.38s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 150/1932 [23:28<4:38:33,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.3083, 'learning_rate': 0.00018447204968944102, 'epoch': 0.23}\u001b[0m\n",
      "\u001b[34m8%|▊         | 150/1932 [23:28<4:38:33,  9.38s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 151/1932 [23:38<4:38:26,  9.38s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 152/1932 [23:47<4:38:16,  9.38s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 153/1932 [23:57<4:38:06,  9.38s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 154/1932 [24:06<4:37:55,  9.38s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 155/1932 [24:15<4:37:46,  9.38s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 156/1932 [24:25<4:37:34,  9.38s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 157/1932 [24:34<4:37:25,  9.38s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 158/1932 [24:43<4:37:18,  9.38s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 159/1932 [24:53<4:37:09,  9.38s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 160/1932 [25:02<4:36:58,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2808, 'learning_rate': 0.0001834368530020704, 'epoch': 0.25}\u001b[0m\n",
      "\u001b[34m8%|▊         | 160/1932 [25:02<4:36:58,  9.38s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 161/1932 [25:12<4:36:49,  9.38s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 162/1932 [25:21<4:36:41,  9.38s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 163/1932 [25:30<4:36:29,  9.38s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 164/1932 [25:40<4:36:19,  9.38s/it]\u001b[0m\n",
      "\u001b[34m9%|▊         | 165/1932 [25:49<4:36:08,  9.38s/it]\u001b[0m\n",
      "\u001b[34m9%|▊         | 166/1932 [25:59<4:36:01,  9.38s/it]\u001b[0m\n",
      "\u001b[34m9%|▊         | 167/1932 [26:08<4:35:53,  9.38s/it]\u001b[0m\n",
      "\u001b[34m9%|▊         | 168/1932 [26:17<4:35:44,  9.38s/it]\u001b[0m\n",
      "\u001b[34m9%|▊         | 169/1932 [26:27<4:35:30,  9.38s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 170/1932 [26:36<4:35:22,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2315, 'learning_rate': 0.0001824016563146998, 'epoch': 0.26}\u001b[0m\n",
      "\u001b[34m9%|▉         | 170/1932 [26:36<4:35:22,  9.38s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 171/1932 [26:45<4:35:14,  9.38s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 172/1932 [26:55<4:35:07,  9.38s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 173/1932 [27:04<4:34:58,  9.38s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 174/1932 [27:14<4:34:49,  9.38s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 175/1932 [27:23<4:35:12,  9.40s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 176/1932 [27:32<4:35:06,  9.40s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 177/1932 [27:42<4:34:49,  9.40s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 178/1932 [27:51<4:34:34,  9.39s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 179/1932 [28:01<4:34:20,  9.39s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 180/1932 [28:10<4:34:04,  9.39s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2421, 'learning_rate': 0.00018136645962732922, 'epoch': 0.28}\u001b[0m\n",
      "\u001b[34m9%|▉         | 180/1932 [28:10<4:34:04,  9.39s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 181/1932 [28:19<4:33:51,  9.38s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 182/1932 [28:29<4:33:35,  9.38s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 183/1932 [28:38<4:33:28,  9.38s/it]\u001b[0m\n",
      "\u001b[34m10%|▉         | 184/1932 [28:47<4:33:17,  9.38s/it]\u001b[0m\n",
      "\u001b[34m10%|▉         | 185/1932 [28:57<4:33:04,  9.38s/it]\u001b[0m\n",
      "\u001b[34m10%|▉         | 186/1932 [29:06<4:32:52,  9.38s/it]\u001b[0m\n",
      "\u001b[34m10%|▉         | 187/1932 [29:16<4:32:45,  9.38s/it]\u001b[0m\n",
      "\u001b[34m10%|▉         | 188/1932 [29:25<4:32:36,  9.38s/it]\u001b[0m\n",
      "\u001b[34m10%|▉         | 189/1932 [29:34<4:32:29,  9.38s/it]\u001b[0m\n",
      "\u001b[34m10%|▉         | 190/1932 [29:44<4:32:21,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2987, 'learning_rate': 0.00018033126293995862, 'epoch': 0.29}\u001b[0m\n",
      "\u001b[34m10%|▉         | 190/1932 [29:44<4:32:21,  9.38s/it]\u001b[0m\n",
      "\u001b[34m10%|▉         | 191/1932 [29:53<4:32:10,  9.38s/it]\u001b[0m\n",
      "\u001b[34m10%|▉         | 192/1932 [30:02<4:31:58,  9.38s/it]\u001b[0m\n",
      "\u001b[34m10%|▉         | 193/1932 [30:12<4:31:49,  9.38s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 194/1932 [30:21<4:31:39,  9.38s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 195/1932 [30:31<4:31:28,  9.38s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 196/1932 [30:40<4:31:17,  9.38s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 197/1932 [30:49<4:31:08,  9.38s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 198/1932 [30:59<4:30:57,  9.38s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 199/1932 [31:08<4:30:46,  9.37s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 200/1932 [31:17<4:30:37,  9.37s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2671, 'learning_rate': 0.00017929606625258798, 'epoch': 0.31}\u001b[0m\n",
      "\u001b[34m10%|█         | 200/1932 [31:17<4:30:37,  9.37s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 201/1932 [31:27<4:30:28,  9.38s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 202/1932 [31:36<4:30:20,  9.38s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 203/1932 [31:46<4:30:09,  9.38s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 204/1932 [31:55<4:30:02,  9.38s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 205/1932 [32:04<4:29:52,  9.38s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 206/1932 [32:14<4:29:41,  9.38s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 207/1932 [32:23<4:29:35,  9.38s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 208/1932 [32:32<4:29:28,  9.38s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 209/1932 [32:42<4:29:19,  9.38s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 210/1932 [32:51<4:29:12,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2658, 'learning_rate': 0.0001782608695652174, 'epoch': 0.33}\u001b[0m\n",
      "\u001b[34m11%|█         | 210/1932 [32:51<4:29:12,  9.38s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 211/1932 [33:01<4:29:01,  9.38s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 212/1932 [33:10<4:28:52,  9.38s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 213/1932 [33:19<4:28:42,  9.38s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 214/1932 [33:29<4:28:31,  9.38s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 215/1932 [33:38<4:28:22,  9.38s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 216/1932 [33:48<4:28:14,  9.38s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 217/1932 [33:57<4:28:08,  9.38s/it]\u001b[0m\n",
      "\u001b[34m11%|█▏        | 218/1932 [34:06<4:27:55,  9.38s/it]\u001b[0m\n",
      "\u001b[34m11%|█▏        | 219/1932 [34:16<4:27:44,  9.38s/it]\u001b[0m\n",
      "\u001b[34m11%|█▏        | 220/1932 [34:25<4:27:38,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2729, 'learning_rate': 0.0001772256728778468, 'epoch': 0.34}\u001b[0m\n",
      "\u001b[34m11%|█▏        | 220/1932 [34:25<4:27:38,  9.38s/it]\u001b[0m\n",
      "\u001b[34m11%|█▏        | 221/1932 [34:34<4:27:30,  9.38s/it]\u001b[0m\n",
      "\u001b[34m11%|█▏        | 222/1932 [34:44<4:27:18,  9.38s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 223/1932 [34:53<4:27:09,  9.38s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 224/1932 [35:03<4:27:00,  9.38s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 225/1932 [35:12<4:26:50,  9.38s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 226/1932 [35:21<4:26:45,  9.38s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 227/1932 [35:31<4:26:39,  9.38s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 228/1932 [35:40<4:26:29,  9.38s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 229/1932 [35:49<4:26:14,  9.38s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 230/1932 [35:59<4:26:04,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.3248, 'learning_rate': 0.0001761904761904762, 'epoch': 0.36}\u001b[0m\n",
      "\u001b[34m12%|█▏        | 230/1932 [35:59<4:26:04,  9.38s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 231/1932 [36:08<4:25:54,  9.38s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 232/1932 [36:18<4:25:44,  9.38s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 233/1932 [36:27<4:25:37,  9.38s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 234/1932 [36:36<4:25:26,  9.38s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 235/1932 [36:46<4:25:16,  9.38s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 236/1932 [36:55<4:25:09,  9.38s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 237/1932 [37:05<4:25:03,  9.38s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 238/1932 [37:14<4:24:59,  9.39s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 239/1932 [37:23<4:24:47,  9.38s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 240/1932 [37:33<4:24:34,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2979, 'learning_rate': 0.00017515527950310558, 'epoch': 0.37}\u001b[0m\n",
      "\u001b[34m12%|█▏        | 240/1932 [37:33<4:24:34,  9.38s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 241/1932 [37:42<4:24:27,  9.38s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 242/1932 [37:51<4:24:14,  9.38s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 243/1932 [38:01<4:24:05,  9.38s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 244/1932 [38:10<4:23:56,  9.38s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 245/1932 [38:20<4:23:44,  9.38s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 246/1932 [38:29<4:23:35,  9.38s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 247/1932 [38:38<4:23:22,  9.38s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 248/1932 [38:48<4:23:14,  9.38s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 249/1932 [38:57<4:23:05,  9.38s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 250/1932 [39:06<4:22:57,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2395, 'learning_rate': 0.000174120082815735, 'epoch': 0.39}\u001b[0m\n",
      "\u001b[34m13%|█▎        | 250/1932 [39:06<4:22:57,  9.38s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 251/1932 [39:16<4:22:47,  9.38s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 252/1932 [39:25<4:22:34,  9.38s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 253/1932 [39:35<4:22:26,  9.38s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 254/1932 [39:44<4:22:14,  9.38s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 255/1932 [39:53<4:22:06,  9.38s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 256/1932 [40:03<4:22:00,  9.38s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 257/1932 [40:12<4:21:50,  9.38s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 258/1932 [40:21<4:21:44,  9.38s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 259/1932 [40:31<4:21:32,  9.38s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 260/1932 [40:40<4:21:19,  9.38s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 260/1932 [40:40<4:21:19,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2467, 'learning_rate': 0.0001730848861283644, 'epoch': 0.4}\u001b[0m\n",
      "\u001b[34m14%|█▎        | 261/1932 [40:50<4:21:09,  9.38s/it]\u001b[0m\n",
      "\u001b[34m14%|█▎        | 262/1932 [40:59<4:21:00,  9.38s/it]\u001b[0m\n",
      "\u001b[34m14%|█▎        | 263/1932 [41:08<4:20:52,  9.38s/it]\u001b[0m\n",
      "\u001b[34m14%|█▎        | 264/1932 [41:18<4:20:44,  9.38s/it]\u001b[0m\n",
      "\u001b[34m14%|█▎        | 265/1932 [41:27<4:20:35,  9.38s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 266/1932 [41:37<4:20:25,  9.38s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 267/1932 [41:46<4:20:13,  9.38s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 268/1932 [41:55<4:20:05,  9.38s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 269/1932 [42:05<4:19:54,  9.38s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 270/1932 [42:14<4:19:46,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2387, 'learning_rate': 0.0001720496894409938, 'epoch': 0.42}\u001b[0m\n",
      "\u001b[34m14%|█▍        | 270/1932 [42:14<4:19:46,  9.38s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 271/1932 [42:23<4:19:39,  9.38s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 272/1932 [42:33<4:19:30,  9.38s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 273/1932 [42:42<4:19:23,  9.38s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 274/1932 [42:52<4:19:11,  9.38s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 275/1932 [43:01<4:19:03,  9.38s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 276/1932 [43:10<4:18:53,  9.38s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 277/1932 [43:20<4:18:43,  9.38s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 278/1932 [43:29<4:18:33,  9.38s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 279/1932 [43:38<4:18:24,  9.38s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 280/1932 [43:48<4:18:15,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2473, 'learning_rate': 0.0001710144927536232, 'epoch': 0.43}\u001b[0m\n",
      "\u001b[34m14%|█▍        | 280/1932 [43:48<4:18:15,  9.38s/it]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 281/1932 [43:57<4:18:05,  9.38s/it]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 282/1932 [44:07<4:17:57,  9.38s/it]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 283/1932 [44:16<4:17:49,  9.38s/it]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 284/1932 [44:25<4:17:38,  9.38s/it]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 285/1932 [44:35<4:17:24,  9.38s/it]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 286/1932 [44:44<4:17:15,  9.38s/it]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 287/1932 [44:53<4:17:04,  9.38s/it]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 288/1932 [45:03<4:16:54,  9.38s/it]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 289/1932 [45:12<4:16:48,  9.38s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 290/1932 [45:22<4:16:44,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2232, 'learning_rate': 0.0001699792960662526, 'epoch': 0.45}\u001b[0m\n",
      "\u001b[34m15%|█▌        | 290/1932 [45:22<4:16:44,  9.38s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 291/1932 [45:31<4:16:38,  9.38s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 292/1932 [45:40<4:16:27,  9.38s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 293/1932 [45:50<4:16:15,  9.38s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 294/1932 [45:59<4:16:06,  9.38s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 295/1932 [46:09<4:15:54,  9.38s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 296/1932 [46:18<4:15:44,  9.38s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 297/1932 [46:27<4:15:35,  9.38s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 298/1932 [46:37<4:15:25,  9.38s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 299/1932 [46:46<4:15:15,  9.38s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 300/1932 [46:55<4:15:06,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2221, 'learning_rate': 0.000168944099378882, 'epoch': 0.47}\u001b[0m\n",
      "\u001b[34m16%|█▌        | 300/1932 [46:55<4:15:06,  9.38s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 301/1932 [47:05<4:14:55,  9.38s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 302/1932 [47:14<4:14:45,  9.38s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 303/1932 [47:24<4:14:38,  9.38s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 304/1932 [47:33<4:14:29,  9.38s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 305/1932 [47:42<4:14:19,  9.38s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 306/1932 [47:52<4:14:09,  9.38s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 307/1932 [48:01<4:14:01,  9.38s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 308/1932 [48:10<4:13:50,  9.38s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 309/1932 [48:20<4:13:42,  9.38s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 310/1932 [48:29<4:13:35,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2708, 'learning_rate': 0.00016790890269151142, 'epoch': 0.48}\u001b[0m\n",
      "\u001b[34m16%|█▌        | 310/1932 [48:29<4:13:35,  9.38s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 311/1932 [48:39<4:13:24,  9.38s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 312/1932 [48:48<4:13:17,  9.38s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 313/1932 [48:57<4:13:16,  9.39s/it]\u001b[0m\n",
      "\u001b[34m16%|█▋        | 314/1932 [49:07<4:13:04,  9.38s/it]\u001b[0m\n",
      "\u001b[34m16%|█▋        | 315/1932 [49:16<4:12:53,  9.38s/it]\u001b[0m\n",
      "\u001b[34m16%|█▋        | 316/1932 [49:26<4:12:41,  9.38s/it]\u001b[0m\n",
      "\u001b[34m16%|█▋        | 317/1932 [49:35<4:12:31,  9.38s/it]\u001b[0m\n",
      "\u001b[34m16%|█▋        | 318/1932 [49:44<4:12:23,  9.38s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 319/1932 [49:54<4:12:14,  9.38s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 320/1932 [50:03<4:12:07,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2254, 'learning_rate': 0.00016687370600414078, 'epoch': 0.5}\u001b[0m\n",
      "\u001b[34m17%|█▋        | 320/1932 [50:03<4:12:07,  9.38s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 321/1932 [50:12<4:11:58,  9.38s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 322/1932 [50:22<4:11:47,  9.38s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 323/1932 [50:31<4:11:35,  9.38s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 324/1932 [50:41<4:11:24,  9.38s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 325/1932 [50:50<4:11:11,  9.38s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 326/1932 [50:59<4:11:02,  9.38s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 327/1932 [51:09<4:10:55,  9.38s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 328/1932 [51:18<4:10:46,  9.38s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 329/1932 [51:27<4:10:36,  9.38s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 330/1932 [51:37<4:10:25,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2302, 'learning_rate': 0.00016583850931677018, 'epoch': 0.51}\u001b[0m\n",
      "\u001b[34m17%|█▋        | 330/1932 [51:37<4:10:25,  9.38s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 331/1932 [51:46<4:10:13,  9.38s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 332/1932 [51:56<4:10:03,  9.38s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 333/1932 [52:05<4:09:51,  9.38s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 334/1932 [52:14<4:09:40,  9.37s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 335/1932 [52:24<4:09:29,  9.37s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 336/1932 [52:33<4:09:21,  9.37s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 337/1932 [52:42<4:09:13,  9.38s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 338/1932 [52:52<4:09:05,  9.38s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 339/1932 [53:01<4:09:00,  9.38s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 340/1932 [53:11<4:08:51,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2451, 'learning_rate': 0.0001648033126293996, 'epoch': 0.53}\u001b[0m\n",
      "\u001b[34m18%|█▊        | 340/1932 [53:11<4:08:51,  9.38s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 341/1932 [53:20<4:08:41,  9.38s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 342/1932 [53:29<4:08:31,  9.38s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 343/1932 [53:39<4:08:21,  9.38s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 344/1932 [53:48<4:08:12,  9.38s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 345/1932 [53:58<4:08:04,  9.38s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 346/1932 [54:07<4:07:54,  9.38s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 347/1932 [54:16<4:07:43,  9.38s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 348/1932 [54:26<4:07:34,  9.38s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 349/1932 [54:35<4:07:24,  9.38s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 350/1932 [54:44<4:07:14,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2403, 'learning_rate': 0.000163768115942029, 'epoch': 0.54}\u001b[0m\n",
      "\u001b[34m18%|█▊        | 350/1932 [54:44<4:07:14,  9.38s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 351/1932 [54:54<4:07:07,  9.38s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 352/1932 [55:03<4:06:56,  9.38s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 353/1932 [55:13<4:06:49,  9.38s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 354/1932 [55:22<4:06:42,  9.38s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 355/1932 [55:31<4:06:32,  9.38s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 356/1932 [55:41<4:06:21,  9.38s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 357/1932 [55:50<4:06:13,  9.38s/it]\u001b[0m\n",
      "\u001b[34m19%|█▊        | 358/1932 [55:59<4:06:01,  9.38s/it]\u001b[0m\n",
      "\u001b[34m19%|█▊        | 359/1932 [56:09<4:05:53,  9.38s/it]\u001b[0m\n",
      "\u001b[34m19%|█▊        | 360/1932 [56:18<4:05:45,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2377, 'learning_rate': 0.00016273291925465838, 'epoch': 0.56}\u001b[0m\n",
      "\u001b[34m19%|█▊        | 360/1932 [56:18<4:05:45,  9.38s/it]\u001b[0m\n",
      "\u001b[34m19%|█▊        | 361/1932 [56:28<4:05:35,  9.38s/it]\u001b[0m\n",
      "\u001b[34m19%|█▊        | 362/1932 [56:37<4:05:26,  9.38s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 363/1932 [56:46<4:05:16,  9.38s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 364/1932 [56:56<4:05:07,  9.38s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 365/1932 [57:05<4:04:57,  9.38s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 366/1932 [57:14<4:04:51,  9.38s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 367/1932 [57:24<4:04:41,  9.38s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 368/1932 [57:33<4:04:31,  9.38s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 369/1932 [57:43<4:04:21,  9.38s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 370/1932 [57:52<4:04:10,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2863, 'learning_rate': 0.0001616977225672878, 'epoch': 0.57}\u001b[0m\n",
      "\u001b[34m19%|█▉        | 370/1932 [57:52<4:04:10,  9.38s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 371/1932 [58:01<4:03:58,  9.38s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 372/1932 [58:11<4:03:48,  9.38s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 373/1932 [58:20<4:03:43,  9.38s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 374/1932 [58:30<4:03:32,  9.38s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 375/1932 [58:39<4:03:21,  9.38s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 376/1932 [58:48<4:03:11,  9.38s/it]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 377/1932 [58:58<4:03:03,  9.38s/it]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 378/1932 [59:07<4:02:53,  9.38s/it]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 379/1932 [59:16<4:02:44,  9.38s/it]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 380/1932 [59:26<4:02:34,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2174, 'learning_rate': 0.0001606625258799172, 'epoch': 0.59}\u001b[0m\n",
      "\u001b[34m20%|█▉        | 380/1932 [59:26<4:02:34,  9.38s/it]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 381/1932 [59:35<4:02:25,  9.38s/it]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 382/1932 [59:45<4:02:14,  9.38s/it]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 383/1932 [59:54<4:02:06,  9.38s/it]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 384/1932 [1:00:03<4:01:55,  9.38s/it]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 385/1932 [1:00:13<4:01:46,  9.38s/it]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 386/1932 [1:00:22<4:01:37,  9.38s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 387/1932 [1:00:31<4:01:27,  9.38s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 388/1932 [1:00:41<4:01:19,  9.38s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 389/1932 [1:00:50<4:01:08,  9.38s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 390/1932 [1:01:00<4:01:01,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2612, 'learning_rate': 0.0001596273291925466, 'epoch': 0.61}\u001b[0m\n",
      "\u001b[34m20%|██        | 390/1932 [1:01:00<4:01:01,  9.38s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 391/1932 [1:01:09<4:00:51,  9.38s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 392/1932 [1:01:18<4:00:43,  9.38s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 393/1932 [1:01:28<4:00:33,  9.38s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 394/1932 [1:01:37<4:00:23,  9.38s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 395/1932 [1:01:46<4:00:12,  9.38s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 396/1932 [1:01:56<4:00:03,  9.38s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 397/1932 [1:02:05<3:59:57,  9.38s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 398/1932 [1:02:15<3:59:49,  9.38s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 399/1932 [1:02:24<3:59:40,  9.38s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 400/1932 [1:02:33<3:59:30,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2165, 'learning_rate': 0.00015859213250517598, 'epoch': 0.62}\u001b[0m\n",
      "\u001b[34m21%|██        | 400/1932 [1:02:33<3:59:30,  9.38s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 401/1932 [1:02:43<3:59:19,  9.38s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 402/1932 [1:02:52<3:59:09,  9.38s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 403/1932 [1:03:01<3:59:04,  9.38s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 404/1932 [1:03:11<3:58:51,  9.38s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 405/1932 [1:03:20<3:58:39,  9.38s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 406/1932 [1:03:30<3:58:31,  9.38s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 407/1932 [1:03:39<3:58:21,  9.38s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 408/1932 [1:03:48<3:58:14,  9.38s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 409/1932 [1:03:58<3:58:05,  9.38s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 410/1932 [1:04:07<3:57:55,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1913, 'learning_rate': 0.0001575569358178054, 'epoch': 0.64}\u001b[0m\n",
      "\u001b[34m21%|██        | 410/1932 [1:04:07<3:57:55,  9.38s/it]\u001b[0m\n",
      "\u001b[34m21%|██▏       | 411/1932 [1:04:17<3:57:45,  9.38s/it]\u001b[0m\n",
      "\u001b[34m21%|██▏       | 412/1932 [1:04:26<3:57:32,  9.38s/it]\u001b[0m\n",
      "\u001b[34m21%|██▏       | 413/1932 [1:04:35<3:57:26,  9.38s/it]\u001b[0m\n",
      "\u001b[34m21%|██▏       | 414/1932 [1:04:45<3:57:17,  9.38s/it]\u001b[0m\n",
      "\u001b[34m21%|██▏       | 415/1932 [1:04:54<3:57:08,  9.38s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 416/1932 [1:05:03<3:56:58,  9.38s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 417/1932 [1:05:13<3:56:47,  9.38s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 418/1932 [1:05:22<3:56:39,  9.38s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 419/1932 [1:05:32<3:56:30,  9.38s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 420/1932 [1:05:41<3:56:23,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2433, 'learning_rate': 0.0001565217391304348, 'epoch': 0.65}\u001b[0m\n",
      "\u001b[34m22%|██▏       | 420/1932 [1:05:41<3:56:23,  9.38s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 421/1932 [1:05:50<3:56:13,  9.38s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 422/1932 [1:06:00<3:56:02,  9.38s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 423/1932 [1:06:09<3:55:53,  9.38s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 424/1932 [1:06:18<3:55:46,  9.38s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 425/1932 [1:06:28<3:55:38,  9.38s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 426/1932 [1:06:37<3:55:28,  9.38s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 427/1932 [1:06:47<3:55:16,  9.38s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 428/1932 [1:06:56<3:55:05,  9.38s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 429/1932 [1:07:05<3:54:55,  9.38s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 430/1932 [1:07:15<3:54:48,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2225, 'learning_rate': 0.0001554865424430642, 'epoch': 0.67}\u001b[0m\n",
      "\u001b[34m22%|██▏       | 430/1932 [1:07:15<3:54:48,  9.38s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 431/1932 [1:07:24<3:54:39,  9.38s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 432/1932 [1:07:33<3:54:31,  9.38s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 433/1932 [1:07:43<3:54:20,  9.38s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 434/1932 [1:07:52<3:54:11,  9.38s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 435/1932 [1:08:02<3:54:02,  9.38s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 436/1932 [1:08:11<3:53:50,  9.38s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 437/1932 [1:08:20<3:53:41,  9.38s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 438/1932 [1:08:30<3:53:31,  9.38s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 439/1932 [1:08:39<3:53:25,  9.38s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 440/1932 [1:08:49<3:53:15,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.252, 'learning_rate': 0.0001544513457556936, 'epoch': 0.68}\u001b[0m\n",
      "\u001b[34m23%|██▎       | 440/1932 [1:08:49<3:53:15,  9.38s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 441/1932 [1:08:58<3:53:05,  9.38s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 442/1932 [1:09:07<3:52:56,  9.38s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 443/1932 [1:09:17<3:52:46,  9.38s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 444/1932 [1:09:26<3:52:36,  9.38s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 445/1932 [1:09:35<3:52:25,  9.38s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 446/1932 [1:09:45<3:52:16,  9.38s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 447/1932 [1:09:54<3:52:05,  9.38s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 448/1932 [1:10:04<3:52:00,  9.38s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 449/1932 [1:10:13<3:51:52,  9.38s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 450/1932 [1:10:22<3:51:42,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2376, 'learning_rate': 0.00015341614906832298, 'epoch': 0.7}\u001b[0m\n",
      "\u001b[34m23%|██▎       | 450/1932 [1:10:22<3:51:42,  9.38s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 451/1932 [1:10:32<3:51:34,  9.38s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 452/1932 [1:10:41<3:51:22,  9.38s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 453/1932 [1:10:50<3:51:15,  9.38s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 454/1932 [1:11:00<3:51:05,  9.38s/it]\u001b[0m\n",
      "\u001b[34m24%|██▎       | 455/1932 [1:11:09<3:50:54,  9.38s/it]\u001b[0m\n",
      "\u001b[34m24%|██▎       | 456/1932 [1:11:19<3:50:42,  9.38s/it]\u001b[0m\n",
      "\u001b[34m24%|██▎       | 457/1932 [1:11:28<3:50:33,  9.38s/it]\u001b[0m\n",
      "\u001b[34m24%|██▎       | 458/1932 [1:11:37<3:50:23,  9.38s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 459/1932 [1:11:47<3:50:11,  9.38s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 460/1932 [1:11:56<3:50:00,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2058, 'learning_rate': 0.00015238095238095237, 'epoch': 0.71}\u001b[0m\n",
      "\u001b[34m24%|██▍       | 460/1932 [1:11:56<3:50:00,  9.38s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 461/1932 [1:12:05<3:49:52,  9.38s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 462/1932 [1:12:15<3:49:42,  9.38s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 463/1932 [1:12:24<3:49:32,  9.38s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 464/1932 [1:12:34<3:49:26,  9.38s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 465/1932 [1:12:43<3:49:17,  9.38s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 466/1932 [1:12:52<3:49:08,  9.38s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 467/1932 [1:13:02<3:48:58,  9.38s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 468/1932 [1:13:11<3:48:48,  9.38s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 469/1932 [1:13:20<3:48:41,  9.38s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 470/1932 [1:13:30<3:48:32,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.252, 'learning_rate': 0.0001513457556935818, 'epoch': 0.73}\u001b[0m\n",
      "\u001b[34m24%|██▍       | 470/1932 [1:13:30<3:48:32,  9.38s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 471/1932 [1:13:39<3:48:22,  9.38s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 472/1932 [1:13:49<3:48:12,  9.38s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 473/1932 [1:13:58<3:48:00,  9.38s/it]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 474/1932 [1:14:07<3:47:51,  9.38s/it]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 475/1932 [1:14:17<3:47:44,  9.38s/it]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 476/1932 [1:14:26<3:47:37,  9.38s/it]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 477/1932 [1:14:36<3:47:27,  9.38s/it]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 478/1932 [1:14:45<3:47:16,  9.38s/it]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 479/1932 [1:14:54<3:47:10,  9.38s/it]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 480/1932 [1:15:04<3:47:01,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2661, 'learning_rate': 0.00015031055900621118, 'epoch': 0.74}\u001b[0m\n",
      "\u001b[34m25%|██▍       | 480/1932 [1:15:04<3:47:01,  9.38s/it]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 481/1932 [1:15:13<3:46:51,  9.38s/it]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 482/1932 [1:15:22<3:46:42,  9.38s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 483/1932 [1:15:32<3:46:32,  9.38s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 484/1932 [1:15:41<3:46:22,  9.38s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 485/1932 [1:15:51<3:46:11,  9.38s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 486/1932 [1:16:00<3:46:02,  9.38s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 487/1932 [1:16:09<3:45:54,  9.38s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 488/1932 [1:16:19<3:45:46,  9.38s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 489/1932 [1:16:28<3:45:34,  9.38s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 490/1932 [1:16:37<3:45:24,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2084, 'learning_rate': 0.00014927536231884058, 'epoch': 0.76}\u001b[0m\n",
      "\u001b[34m25%|██▌       | 490/1932 [1:16:37<3:45:24,  9.38s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 491/1932 [1:16:47<3:45:14,  9.38s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 492/1932 [1:16:56<3:45:04,  9.38s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 493/1932 [1:17:06<3:44:58,  9.38s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 494/1932 [1:17:15<3:44:50,  9.38s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 495/1932 [1:17:24<3:44:42,  9.38s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 496/1932 [1:17:34<3:44:31,  9.38s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 497/1932 [1:17:43<3:44:19,  9.38s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 498/1932 [1:17:53<3:44:08,  9.38s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 499/1932 [1:18:02<3:44:03,  9.38s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 500/1932 [1:18:11<3:43:52,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2518, 'learning_rate': 0.00014824016563147, 'epoch': 0.78}\u001b[0m\n",
      "\u001b[34m26%|██▌       | 500/1932 [1:18:11<3:43:52,  9.38s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 501/1932 [1:18:21<3:43:43,  9.38s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 502/1932 [1:18:30<3:43:32,  9.38s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 503/1932 [1:18:39<3:43:23,  9.38s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 504/1932 [1:18:49<3:43:12,  9.38s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 505/1932 [1:18:58<3:43:00,  9.38s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 506/1932 [1:19:08<3:42:51,  9.38s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 507/1932 [1:19:17<3:42:43,  9.38s/it]\u001b[0m\n",
      "\u001b[34m26%|██▋       | 508/1932 [1:19:26<3:42:35,  9.38s/it]\u001b[0m\n",
      "\u001b[34m26%|██▋       | 509/1932 [1:19:36<3:42:27,  9.38s/it]\u001b[0m\n",
      "\u001b[34m26%|██▋       | 510/1932 [1:19:45<3:42:20,  9.38s/it]\u001b[0m\n",
      "\u001b[34m26%|██▋       | 510/1932 [1:19:45<3:42:20,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2266, 'learning_rate': 0.0001472049689440994, 'epoch': 0.79}\u001b[0m\n",
      "\u001b[34m26%|██▋       | 511/1932 [1:19:54<3:42:09,  9.38s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 512/1932 [1:20:04<3:42:00,  9.38s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 513/1932 [1:20:13<3:41:48,  9.38s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 514/1932 [1:20:23<3:41:40,  9.38s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 515/1932 [1:20:32<3:41:33,  9.38s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 516/1932 [1:20:41<3:41:22,  9.38s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 517/1932 [1:20:51<3:41:09,  9.38s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 518/1932 [1:21:00<3:41:02,  9.38s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 519/1932 [1:21:09<3:40:52,  9.38s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 520/1932 [1:21:19<3:40:45,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2451, 'learning_rate': 0.00014616977225672878, 'epoch': 0.81}\u001b[0m\n",
      "\u001b[34m27%|██▋       | 520/1932 [1:21:19<3:40:45,  9.38s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 521/1932 [1:21:28<3:40:38,  9.38s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 522/1932 [1:21:38<3:40:24,  9.38s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 523/1932 [1:21:47<3:40:14,  9.38s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 524/1932 [1:21:56<3:40:04,  9.38s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 525/1932 [1:22:06<3:39:55,  9.38s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 526/1932 [1:22:15<3:39:45,  9.38s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 527/1932 [1:22:25<3:39:39,  9.38s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 528/1932 [1:22:34<3:39:28,  9.38s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 529/1932 [1:22:43<3:39:18,  9.38s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 530/1932 [1:22:53<3:39:08,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2399, 'learning_rate': 0.00014513457556935818, 'epoch': 0.82}\u001b[0m\n",
      "\u001b[34m27%|██▋       | 530/1932 [1:22:53<3:39:08,  9.38s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 531/1932 [1:23:02<3:39:00,  9.38s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 532/1932 [1:23:11<3:38:49,  9.38s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 533/1932 [1:23:21<3:38:41,  9.38s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 534/1932 [1:23:30<3:38:32,  9.38s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 535/1932 [1:23:40<3:38:22,  9.38s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 536/1932 [1:23:49<3:38:11,  9.38s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 537/1932 [1:23:58<3:38:01,  9.38s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 538/1932 [1:24:08<3:37:53,  9.38s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 539/1932 [1:24:17<3:37:43,  9.38s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 540/1932 [1:24:26<3:37:33,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1747, 'learning_rate': 0.0001440993788819876, 'epoch': 0.84}\u001b[0m\n",
      "\u001b[34m28%|██▊       | 540/1932 [1:24:26<3:37:33,  9.38s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 541/1932 [1:24:36<3:37:25,  9.38s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 542/1932 [1:24:45<3:37:15,  9.38s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 543/1932 [1:24:55<3:37:04,  9.38s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 544/1932 [1:25:04<3:36:57,  9.38s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 545/1932 [1:25:13<3:36:46,  9.38s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 546/1932 [1:25:23<3:36:36,  9.38s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 547/1932 [1:25:32<3:36:29,  9.38s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 548/1932 [1:25:41<3:36:22,  9.38s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 549/1932 [1:25:51<3:36:11,  9.38s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 550/1932 [1:26:00<3:36:01,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2699, 'learning_rate': 0.000143064182194617, 'epoch': 0.85}\u001b[0m\n",
      "\u001b[34m28%|██▊       | 550/1932 [1:26:00<3:36:01,  9.38s/it]\u001b[0m\n",
      "\u001b[34m29%|██▊       | 551/1932 [1:26:10<3:35:53,  9.38s/it]\u001b[0m\n",
      "\u001b[34m29%|██▊       | 552/1932 [1:26:19<3:35:46,  9.38s/it]\u001b[0m\n",
      "\u001b[34m29%|██▊       | 553/1932 [1:26:28<3:35:36,  9.38s/it]\u001b[0m\n",
      "\u001b[34m29%|██▊       | 554/1932 [1:26:38<3:35:25,  9.38s/it]\u001b[0m\n",
      "\u001b[34m29%|██▊       | 555/1932 [1:26:47<3:35:16,  9.38s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 556/1932 [1:26:57<3:35:09,  9.38s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 557/1932 [1:27:06<3:35:00,  9.38s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 558/1932 [1:27:15<3:34:50,  9.38s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 559/1932 [1:27:25<3:34:39,  9.38s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 560/1932 [1:27:34<3:34:29,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2681, 'learning_rate': 0.00014202898550724638, 'epoch': 0.87}\u001b[0m\n",
      "\u001b[34m29%|██▉       | 560/1932 [1:27:34<3:34:29,  9.38s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 561/1932 [1:27:43<3:34:21,  9.38s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 562/1932 [1:27:53<3:34:11,  9.38s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 563/1932 [1:28:02<3:34:01,  9.38s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 564/1932 [1:28:12<3:33:52,  9.38s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 565/1932 [1:28:21<3:33:45,  9.38s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 566/1932 [1:28:30<3:33:33,  9.38s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 567/1932 [1:28:40<3:33:23,  9.38s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 568/1932 [1:28:49<3:33:14,  9.38s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 569/1932 [1:28:58<3:33:07,  9.38s/it]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 570/1932 [1:29:08<3:32:59,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.187, 'learning_rate': 0.0001409937888198758, 'epoch': 0.88}\u001b[0m\n",
      "\u001b[34m30%|██▉       | 570/1932 [1:29:08<3:32:59,  9.38s/it]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 571/1932 [1:29:17<3:32:50,  9.38s/it]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 572/1932 [1:29:27<3:32:38,  9.38s/it]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 573/1932 [1:29:36<3:32:27,  9.38s/it]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 574/1932 [1:29:45<3:32:18,  9.38s/it]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 575/1932 [1:29:55<3:32:10,  9.38s/it]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 576/1932 [1:30:04<3:32:01,  9.38s/it]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 577/1932 [1:30:14<3:31:53,  9.38s/it]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 578/1932 [1:30:23<3:31:44,  9.38s/it]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 579/1932 [1:30:32<3:31:32,  9.38s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 580/1932 [1:30:42<3:31:22,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2203, 'learning_rate': 0.00013995859213250517, 'epoch': 0.9}\u001b[0m\n",
      "\u001b[34m30%|███       | 580/1932 [1:30:42<3:31:22,  9.38s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 581/1932 [1:30:51<3:31:10,  9.38s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 582/1932 [1:31:00<3:31:00,  9.38s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 583/1932 [1:31:10<3:30:51,  9.38s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 584/1932 [1:31:19<3:30:44,  9.38s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 585/1932 [1:31:29<3:30:34,  9.38s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 586/1932 [1:31:38<3:30:26,  9.38s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 587/1932 [1:31:47<3:30:17,  9.38s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 588/1932 [1:31:57<3:30:09,  9.38s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 589/1932 [1:32:06<3:30:01,  9.38s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 590/1932 [1:32:15<3:29:52,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.219, 'learning_rate': 0.00013892339544513456, 'epoch': 0.92}\u001b[0m\n",
      "\u001b[34m31%|███       | 590/1932 [1:32:15<3:29:52,  9.38s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 591/1932 [1:32:25<3:29:40,  9.38s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 592/1932 [1:32:34<3:29:28,  9.38s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 593/1932 [1:32:44<3:29:20,  9.38s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 594/1932 [1:32:53<3:29:13,  9.38s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 595/1932 [1:33:02<3:29:05,  9.38s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 596/1932 [1:33:12<3:28:55,  9.38s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 597/1932 [1:33:21<3:28:47,  9.38s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 598/1932 [1:33:31<3:28:33,  9.38s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 599/1932 [1:33:40<3:28:22,  9.38s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 600/1932 [1:33:49<3:28:13,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2691, 'learning_rate': 0.00013788819875776398, 'epoch': 0.93}\u001b[0m\n",
      "\u001b[34m31%|███       | 600/1932 [1:33:49<3:28:13,  9.38s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 601/1932 [1:33:59<3:28:02,  9.38s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 602/1932 [1:34:08<3:27:54,  9.38s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 603/1932 [1:34:17<3:27:45,  9.38s/it]\u001b[0m\n",
      "\u001b[34m31%|███▏      | 604/1932 [1:34:27<3:27:32,  9.38s/it]\u001b[0m\n",
      "\u001b[34m31%|███▏      | 605/1932 [1:34:36<3:27:24,  9.38s/it]\u001b[0m\n",
      "\u001b[34m31%|███▏      | 606/1932 [1:34:46<3:27:15,  9.38s/it]\u001b[0m\n",
      "\u001b[34m31%|███▏      | 607/1932 [1:34:55<3:27:04,  9.38s/it]\u001b[0m\n",
      "\u001b[34m31%|███▏      | 608/1932 [1:35:04<3:26:55,  9.38s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 609/1932 [1:35:14<3:26:46,  9.38s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 610/1932 [1:35:23<3:26:43,  9.38s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 610/1932 [1:35:23<3:26:43,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2697, 'learning_rate': 0.00013685300207039338, 'epoch': 0.95}\u001b[0m\n",
      "\u001b[34m32%|███▏      | 611/1932 [1:35:32<3:26:34,  9.38s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 612/1932 [1:35:42<3:26:26,  9.38s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 613/1932 [1:35:51<3:26:13,  9.38s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 614/1932 [1:36:01<3:26:00,  9.38s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 615/1932 [1:36:10<3:25:54,  9.38s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 616/1932 [1:36:19<3:25:46,  9.38s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 617/1932 [1:36:29<3:25:43,  9.39s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 618/1932 [1:36:38<3:25:32,  9.39s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 619/1932 [1:36:48<3:25:19,  9.38s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 620/1932 [1:36:57<3:25:08,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2315, 'learning_rate': 0.00013581780538302277, 'epoch': 0.96}\u001b[0m\n",
      "\u001b[34m32%|███▏      | 620/1932 [1:36:57<3:25:08,  9.38s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 621/1932 [1:37:06<3:24:58,  9.38s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 622/1932 [1:37:16<3:24:48,  9.38s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 623/1932 [1:37:25<3:24:36,  9.38s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 624/1932 [1:37:34<3:24:28,  9.38s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 625/1932 [1:37:44<3:24:17,  9.38s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 626/1932 [1:37:53<3:24:08,  9.38s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 627/1932 [1:38:03<3:24:00,  9.38s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 628/1932 [1:38:12<3:23:50,  9.38s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 629/1932 [1:38:21<3:23:43,  9.38s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 630/1932 [1:38:31<3:23:34,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2943, 'learning_rate': 0.0001347826086956522, 'epoch': 0.98}\u001b[0m\n",
      "\u001b[34m33%|███▎      | 630/1932 [1:38:31<3:23:34,  9.38s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 631/1932 [1:38:40<3:23:25,  9.38s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 632/1932 [1:38:49<3:23:16,  9.38s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 633/1932 [1:38:59<3:23:05,  9.38s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 634/1932 [1:39:08<3:22:54,  9.38s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 635/1932 [1:39:18<3:22:45,  9.38s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 636/1932 [1:39:27<3:22:35,  9.38s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 637/1932 [1:39:36<3:22:27,  9.38s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 638/1932 [1:39:46<3:22:17,  9.38s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 639/1932 [1:39:55<3:22:10,  9.38s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 640/1932 [1:40:04<3:22:02,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2136, 'learning_rate': 0.00013374741200828158, 'epoch': 0.99}\u001b[0m\n",
      "\u001b[34m33%|███▎      | 640/1932 [1:40:04<3:22:02,  9.38s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 641/1932 [1:40:14<3:21:50,  9.38s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 642/1932 [1:40:23<3:21:38,  9.38s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 643/1932 [1:40:33<3:21:31,  9.38s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 644/1932 [1:40:42<3:21:20,  9.38s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 645/1932 [1:40:51<3:21:12,  9.38s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 646/1932 [1:41:01<3:21:02,  9.38s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 647/1932 [1:41:10<3:20:54,  9.38s/it]\u001b[0m\n",
      "\u001b[34m34%|███▎      | 648/1932 [1:41:20<3:20:49,  9.38s/it]\u001b[0m\n",
      "\u001b[34m34%|███▎      | 649/1932 [1:41:29<3:20:38,  9.38s/it]\u001b[0m\n",
      "\u001b[34m34%|███▎      | 650/1932 [1:41:38<3:20:26,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2345, 'learning_rate': 0.00013271221532091098, 'epoch': 1.01}\u001b[0m\n",
      "\u001b[34m34%|███▎      | 650/1932 [1:41:38<3:20:26,  9.38s/it]\u001b[0m\n",
      "\u001b[34m34%|███▎      | 651/1932 [1:41:48<3:20:20,  9.38s/it]\u001b[0m\n",
      "\u001b[34m34%|███▎      | 652/1932 [1:41:57<3:20:11,  9.38s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 653/1932 [1:42:06<3:20:00,  9.38s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 654/1932 [1:42:16<3:19:53,  9.38s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 655/1932 [1:42:25<3:19:43,  9.38s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 656/1932 [1:42:35<3:19:31,  9.38s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 657/1932 [1:42:44<3:19:21,  9.38s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 658/1932 [1:42:53<3:19:13,  9.38s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 659/1932 [1:43:03<3:19:05,  9.38s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 660/1932 [1:43:12<3:18:55,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2288, 'learning_rate': 0.0001316770186335404, 'epoch': 1.02}\u001b[0m\n",
      "\u001b[34m34%|███▍      | 660/1932 [1:43:12<3:18:55,  9.38s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 661/1932 [1:43:22<3:18:45,  9.38s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 662/1932 [1:43:31<3:18:36,  9.38s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 663/1932 [1:43:40<3:18:26,  9.38s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 664/1932 [1:43:50<3:18:17,  9.38s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 665/1932 [1:43:59<3:18:08,  9.38s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 666/1932 [1:44:08<3:18:02,  9.39s/it]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 667/1932 [1:44:18<3:17:51,  9.38s/it]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 668/1932 [1:44:27<3:17:41,  9.38s/it]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 669/1932 [1:44:37<3:17:31,  9.38s/it]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 670/1932 [1:44:46<3:17:21,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1861, 'learning_rate': 0.0001306418219461698, 'epoch': 1.04}\u001b[0m\n",
      "\u001b[34m35%|███▍      | 670/1932 [1:44:46<3:17:21,  9.38s/it]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 671/1932 [1:44:55<3:17:15,  9.39s/it]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 672/1932 [1:45:05<3:17:06,  9.39s/it]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 673/1932 [1:45:14<3:16:55,  9.38s/it]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 674/1932 [1:45:24<3:16:46,  9.39s/it]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 675/1932 [1:45:33<3:16:35,  9.38s/it]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 676/1932 [1:45:42<3:16:23,  9.38s/it]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 677/1932 [1:45:52<3:16:13,  9.38s/it]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 678/1932 [1:46:01<3:16:06,  9.38s/it]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 679/1932 [1:46:10<3:15:55,  9.38s/it]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 680/1932 [1:46:20<3:15:46,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1759, 'learning_rate': 0.00012960662525879918, 'epoch': 1.06}\u001b[0m\n",
      "\u001b[34m35%|███▌      | 680/1932 [1:46:20<3:15:46,  9.38s/it]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 681/1932 [1:46:29<3:15:37,  9.38s/it]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 682/1932 [1:46:39<3:15:28,  9.38s/it]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 683/1932 [1:46:48<3:15:20,  9.38s/it]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 684/1932 [1:46:57<3:15:11,  9.38s/it]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 685/1932 [1:47:07<3:15:00,  9.38s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 686/1932 [1:47:16<3:14:50,  9.38s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 687/1932 [1:47:25<3:14:40,  9.38s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 688/1932 [1:47:35<3:14:30,  9.38s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 689/1932 [1:47:44<3:14:22,  9.38s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 690/1932 [1:47:54<3:14:12,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2085, 'learning_rate': 0.00012857142857142858, 'epoch': 1.07}\u001b[0m\n",
      "\u001b[34m36%|███▌      | 690/1932 [1:47:54<3:14:12,  9.38s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 691/1932 [1:48:03<3:14:05,  9.38s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 692/1932 [1:48:12<3:13:54,  9.38s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 693/1932 [1:48:22<3:13:45,  9.38s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 694/1932 [1:48:31<3:13:36,  9.38s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 695/1932 [1:48:41<3:13:27,  9.38s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 696/1932 [1:48:50<3:13:17,  9.38s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 697/1932 [1:48:59<3:13:11,  9.39s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 698/1932 [1:49:09<3:13:01,  9.39s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 699/1932 [1:49:18<3:12:51,  9.39s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 700/1932 [1:49:27<3:12:39,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2353, 'learning_rate': 0.00012753623188405797, 'epoch': 1.09}\u001b[0m\n",
      "\u001b[34m36%|███▌      | 700/1932 [1:49:27<3:12:39,  9.38s/it]\u001b[0m\n",
      "\u001b[34m36%|███▋      | 701/1932 [1:49:37<3:12:29,  9.38s/it]\u001b[0m\n",
      "\u001b[34m36%|███▋      | 702/1932 [1:49:46<3:12:19,  9.38s/it]\u001b[0m\n",
      "\u001b[34m36%|███▋      | 703/1932 [1:49:56<3:12:12,  9.38s/it]\u001b[0m\n",
      "\u001b[34m36%|███▋      | 704/1932 [1:50:05<3:12:03,  9.38s/it]\u001b[0m\n",
      "\u001b[34m36%|███▋      | 705/1932 [1:50:14<3:11:54,  9.38s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 706/1932 [1:50:24<3:11:43,  9.38s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 707/1932 [1:50:33<3:11:33,  9.38s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 708/1932 [1:50:43<3:11:25,  9.38s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 709/1932 [1:50:52<3:11:15,  9.38s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 710/1932 [1:51:01<3:11:07,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2496, 'learning_rate': 0.00012650103519668736, 'epoch': 1.1}\u001b[0m\n",
      "\u001b[34m37%|███▋      | 710/1932 [1:51:01<3:11:07,  9.38s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 711/1932 [1:51:11<3:10:56,  9.38s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 712/1932 [1:51:20<3:10:49,  9.39s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 713/1932 [1:51:29<3:10:41,  9.39s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 714/1932 [1:51:39<3:10:28,  9.38s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 715/1932 [1:51:48<3:10:18,  9.38s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 716/1932 [1:51:58<3:10:08,  9.38s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 717/1932 [1:52:07<3:09:59,  9.38s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 718/1932 [1:52:16<3:09:48,  9.38s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 719/1932 [1:52:26<3:09:40,  9.38s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 720/1932 [1:52:35<3:09:34,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2055, 'learning_rate': 0.00012546583850931676, 'epoch': 1.12}\u001b[0m\n",
      "\u001b[34m37%|███▋      | 720/1932 [1:52:35<3:09:34,  9.38s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 721/1932 [1:52:45<3:09:24,  9.38s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 722/1932 [1:52:54<3:09:14,  9.38s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 723/1932 [1:53:03<3:09:09,  9.39s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 724/1932 [1:53:13<3:08:58,  9.39s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 725/1932 [1:53:22<3:08:48,  9.39s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 726/1932 [1:53:31<3:08:37,  9.38s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 727/1932 [1:53:41<3:08:27,  9.38s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 728/1932 [1:53:50<3:08:14,  9.38s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 729/1932 [1:54:00<3:08:05,  9.38s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 730/1932 [1:54:09<3:07:58,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1905, 'learning_rate': 0.00012443064182194618, 'epoch': 1.13}\u001b[0m\n",
      "\u001b[34m38%|███▊      | 730/1932 [1:54:09<3:07:58,  9.38s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 731/1932 [1:54:18<3:07:47,  9.38s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 732/1932 [1:54:28<3:07:36,  9.38s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 733/1932 [1:54:37<3:07:26,  9.38s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 734/1932 [1:54:47<3:07:19,  9.38s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 735/1932 [1:54:56<3:07:11,  9.38s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 736/1932 [1:55:05<3:07:02,  9.38s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 737/1932 [1:55:15<3:06:53,  9.38s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 738/1932 [1:55:24<3:06:46,  9.39s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 739/1932 [1:55:33<3:06:35,  9.38s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 740/1932 [1:55:43<3:06:27,  9.39s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1464, 'learning_rate': 0.00012339544513457557, 'epoch': 1.15}\u001b[0m\n",
      "\u001b[34m38%|███▊      | 740/1932 [1:55:43<3:06:27,  9.39s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 741/1932 [1:55:52<3:06:17,  9.39s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 742/1932 [1:56:02<3:06:11,  9.39s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 743/1932 [1:56:11<3:06:02,  9.39s/it]\u001b[0m\n",
      "\u001b[34m39%|███▊      | 744/1932 [1:56:20<3:05:50,  9.39s/it]\u001b[0m\n",
      "\u001b[34m39%|███▊      | 745/1932 [1:56:30<3:05:41,  9.39s/it]\u001b[0m\n",
      "\u001b[34m39%|███▊      | 746/1932 [1:56:39<3:05:30,  9.38s/it]\u001b[0m\n",
      "\u001b[34m39%|███▊      | 747/1932 [1:56:49<3:05:21,  9.39s/it]\u001b[0m\n",
      "\u001b[34m39%|███▊      | 748/1932 [1:56:58<3:05:12,  9.39s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 749/1932 [1:57:07<3:05:03,  9.39s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 750/1932 [1:57:17<3:04:53,  9.39s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2002, 'learning_rate': 0.00012236024844720496, 'epoch': 1.16}\u001b[0m\n",
      "\u001b[34m39%|███▉      | 750/1932 [1:57:17<3:04:53,  9.39s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 751/1932 [1:57:26<3:04:43,  9.39s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 752/1932 [1:57:35<3:04:33,  9.38s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 753/1932 [1:57:45<3:04:25,  9.39s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 754/1932 [1:57:54<3:04:14,  9.38s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 755/1932 [1:58:04<3:04:04,  9.38s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 756/1932 [1:58:13<3:03:53,  9.38s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 757/1932 [1:58:22<3:03:45,  9.38s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 758/1932 [1:58:32<3:03:34,  9.38s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 759/1932 [1:58:41<3:03:26,  9.38s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 760/1932 [1:58:51<3:03:18,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.171, 'learning_rate': 0.00012132505175983437, 'epoch': 1.18}\u001b[0m\n",
      "\u001b[34m39%|███▉      | 760/1932 [1:58:51<3:03:18,  9.38s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 761/1932 [1:59:00<3:03:09,  9.38s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 762/1932 [1:59:09<3:03:03,  9.39s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 763/1932 [1:59:19<3:02:54,  9.39s/it]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 764/1932 [1:59:28<3:02:43,  9.39s/it]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 765/1932 [1:59:37<3:02:31,  9.38s/it]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 766/1932 [1:59:47<3:02:19,  9.38s/it]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 767/1932 [1:59:56<3:02:12,  9.38s/it]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 768/1932 [2:00:06<3:02:05,  9.39s/it]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 769/1932 [2:00:15<3:01:55,  9.39s/it]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 770/1932 [2:00:24<3:01:47,  9.39s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1623, 'learning_rate': 0.00012028985507246378, 'epoch': 1.19}\u001b[0m\n",
      "\u001b[34m40%|███▉      | 770/1932 [2:00:24<3:01:47,  9.39s/it]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 771/1932 [2:00:34<3:01:36,  9.39s/it]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 772/1932 [2:00:43<3:01:27,  9.39s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 773/1932 [2:00:53<3:01:19,  9.39s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 774/1932 [2:01:02<3:01:07,  9.38s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 775/1932 [2:01:11<3:00:57,  9.38s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 776/1932 [2:01:21<3:00:51,  9.39s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 777/1932 [2:01:30<3:00:39,  9.39s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 778/1932 [2:01:39<3:00:31,  9.39s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 779/1932 [2:01:49<3:00:20,  9.38s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 780/1932 [2:01:58<3:00:09,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1787, 'learning_rate': 0.00011925465838509318, 'epoch': 1.21}\u001b[0m\n",
      "\u001b[34m40%|████      | 780/1932 [2:01:58<3:00:09,  9.38s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 781/1932 [2:02:08<3:00:01,  9.38s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 782/1932 [2:02:17<2:59:50,  9.38s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 783/1932 [2:02:26<2:59:41,  9.38s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 784/1932 [2:02:36<2:59:32,  9.38s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 785/1932 [2:02:45<2:59:24,  9.39s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 786/1932 [2:02:55<2:59:12,  9.38s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 787/1932 [2:03:04<2:59:03,  9.38s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 788/1932 [2:03:13<2:58:53,  9.38s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 789/1932 [2:03:23<2:58:44,  9.38s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 790/1932 [2:03:32<2:58:34,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1841, 'learning_rate': 0.00011821946169772258, 'epoch': 1.23}\u001b[0m\n",
      "\u001b[34m41%|████      | 790/1932 [2:03:32<2:58:34,  9.38s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 791/1932 [2:03:41<2:58:27,  9.38s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 792/1932 [2:03:51<2:58:20,  9.39s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 793/1932 [2:04:00<2:58:12,  9.39s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 794/1932 [2:04:10<2:58:06,  9.39s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 795/1932 [2:04:19<2:57:57,  9.39s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 796/1932 [2:04:28<2:57:44,  9.39s/it]\u001b[0m\n",
      "\u001b[34m41%|████▏     | 797/1932 [2:04:38<2:57:34,  9.39s/it]\u001b[0m\n",
      "\u001b[34m41%|████▏     | 798/1932 [2:04:47<2:57:22,  9.39s/it]\u001b[0m\n",
      "\u001b[34m41%|████▏     | 799/1932 [2:04:57<2:57:11,  9.38s/it]\u001b[0m\n",
      "\u001b[34m41%|████▏     | 800/1932 [2:05:06<2:57:01,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2537, 'learning_rate': 0.00011718426501035198, 'epoch': 1.24}\u001b[0m\n",
      "\u001b[34m41%|████▏     | 800/1932 [2:05:06<2:57:01,  9.38s/it]\u001b[0m\n",
      "\u001b[34m41%|████▏     | 801/1932 [2:05:15<2:56:51,  9.38s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 802/1932 [2:05:25<2:56:41,  9.38s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 803/1932 [2:05:34<2:56:32,  9.38s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 804/1932 [2:05:43<2:56:22,  9.38s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 805/1932 [2:05:53<2:56:12,  9.38s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 806/1932 [2:06:02<2:56:05,  9.38s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 807/1932 [2:06:12<2:55:55,  9.38s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 808/1932 [2:06:21<2:55:46,  9.38s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 809/1932 [2:06:30<2:55:38,  9.38s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 810/1932 [2:06:40<2:55:28,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2242, 'learning_rate': 0.00011614906832298138, 'epoch': 1.26}\u001b[0m\n",
      "\u001b[34m42%|████▏     | 810/1932 [2:06:40<2:55:28,  9.38s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 811/1932 [2:06:49<2:55:17,  9.38s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 812/1932 [2:06:59<2:55:08,  9.38s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 813/1932 [2:07:08<2:55:00,  9.38s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 814/1932 [2:07:17<2:54:50,  9.38s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 815/1932 [2:07:27<2:54:41,  9.38s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 816/1932 [2:07:36<2:54:31,  9.38s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 817/1932 [2:07:45<2:54:20,  9.38s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 818/1932 [2:07:55<2:54:12,  9.38s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 819/1932 [2:08:04<2:54:03,  9.38s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 820/1932 [2:08:14<2:53:55,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1953, 'learning_rate': 0.00011511387163561078, 'epoch': 1.27}\u001b[0m\n",
      "\u001b[34m42%|████▏     | 820/1932 [2:08:14<2:53:55,  9.38s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 821/1932 [2:08:23<2:53:47,  9.39s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 822/1932 [2:08:32<2:53:36,  9.38s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 823/1932 [2:08:42<2:53:23,  9.38s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 824/1932 [2:08:51<2:53:14,  9.38s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 825/1932 [2:09:00<2:53:09,  9.39s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 826/1932 [2:09:10<2:52:59,  9.38s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 827/1932 [2:09:19<2:52:50,  9.38s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 828/1932 [2:09:29<2:52:40,  9.38s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 829/1932 [2:09:38<2:52:30,  9.38s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 830/1932 [2:09:47<2:52:19,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1646, 'learning_rate': 0.00011407867494824016, 'epoch': 1.29}\u001b[0m\n",
      "\u001b[34m43%|████▎     | 830/1932 [2:09:47<2:52:19,  9.38s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 831/1932 [2:09:57<2:52:11,  9.38s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 832/1932 [2:10:06<2:52:01,  9.38s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 833/1932 [2:10:16<2:51:51,  9.38s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 834/1932 [2:10:25<2:51:42,  9.38s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 835/1932 [2:10:34<2:51:33,  9.38s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 836/1932 [2:10:44<2:51:23,  9.38s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 837/1932 [2:10:53<2:51:14,  9.38s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 838/1932 [2:11:02<2:51:05,  9.38s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 839/1932 [2:11:12<2:50:55,  9.38s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 840/1932 [2:11:21<2:50:46,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1814, 'learning_rate': 0.00011304347826086956, 'epoch': 1.3}\u001b[0m\n",
      "\u001b[34m43%|████▎     | 840/1932 [2:11:21<2:50:46,  9.38s/it]\u001b[0m\n",
      "\u001b[34m44%|████▎     | 841/1932 [2:11:31<2:50:36,  9.38s/it]\u001b[0m\n",
      "\u001b[34m44%|████▎     | 842/1932 [2:11:40<2:50:27,  9.38s/it]\u001b[0m\n",
      "\u001b[34m44%|████▎     | 843/1932 [2:11:49<2:50:18,  9.38s/it]\u001b[0m\n",
      "\u001b[34m44%|████▎     | 844/1932 [2:11:59<2:50:10,  9.38s/it]\u001b[0m\n",
      "\u001b[34m44%|████▎     | 845/1932 [2:12:08<2:50:02,  9.39s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 846/1932 [2:12:18<2:49:53,  9.39s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 847/1932 [2:12:27<2:49:40,  9.38s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 848/1932 [2:12:36<2:49:30,  9.38s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 849/1932 [2:12:46<2:49:23,  9.38s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 850/1932 [2:12:55<2:49:13,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2122, 'learning_rate': 0.00011200828157349896, 'epoch': 1.32}\u001b[0m\n",
      "\u001b[34m44%|████▍     | 850/1932 [2:12:55<2:49:13,  9.38s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 851/1932 [2:13:04<2:49:04,  9.38s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 852/1932 [2:13:14<2:48:54,  9.38s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 853/1932 [2:13:23<2:48:43,  9.38s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 854/1932 [2:13:33<2:48:34,  9.38s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 855/1932 [2:13:42<2:48:26,  9.38s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 856/1932 [2:13:51<2:48:15,  9.38s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 857/1932 [2:14:01<2:48:06,  9.38s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 858/1932 [2:14:10<2:47:58,  9.38s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 859/1932 [2:14:20<2:47:49,  9.38s/it]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 860/1932 [2:14:29<2:47:38,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2214, 'learning_rate': 0.00011097308488612837, 'epoch': 1.33}\u001b[0m\n",
      "\u001b[34m45%|████▍     | 860/1932 [2:14:29<2:47:38,  9.38s/it]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 861/1932 [2:14:38<2:47:31,  9.39s/it]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 862/1932 [2:14:48<2:47:21,  9.38s/it]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 863/1932 [2:14:57<2:47:12,  9.38s/it]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 864/1932 [2:15:06<2:47:02,  9.38s/it]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 865/1932 [2:15:16<2:46:52,  9.38s/it]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 866/1932 [2:15:25<2:46:44,  9.38s/it]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 867/1932 [2:15:35<2:46:29,  9.38s/it]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 868/1932 [2:15:44<2:46:21,  9.38s/it]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 869/1932 [2:15:53<2:46:11,  9.38s/it]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 870/1932 [2:16:03<2:46:01,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.165, 'learning_rate': 0.00010993788819875776, 'epoch': 1.35}\u001b[0m\n",
      "\u001b[34m45%|████▌     | 870/1932 [2:16:03<2:46:01,  9.38s/it]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 871/1932 [2:16:12<2:45:52,  9.38s/it]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 872/1932 [2:16:21<2:45:43,  9.38s/it]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 873/1932 [2:16:31<2:45:38,  9.38s/it]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 874/1932 [2:16:40<2:45:27,  9.38s/it]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 875/1932 [2:16:50<2:45:21,  9.39s/it]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 876/1932 [2:16:59<2:45:14,  9.39s/it]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 877/1932 [2:17:08<2:45:03,  9.39s/it]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 878/1932 [2:17:18<2:44:53,  9.39s/it]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 879/1932 [2:17:27<2:44:43,  9.39s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 880/1932 [2:17:37<2:44:33,  9.39s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1758, 'learning_rate': 0.00010890269151138717, 'epoch': 1.37}\u001b[0m\n",
      "\u001b[34m46%|████▌     | 880/1932 [2:17:37<2:44:33,  9.39s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 881/1932 [2:17:46<2:44:25,  9.39s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 882/1932 [2:17:55<2:44:16,  9.39s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 883/1932 [2:18:05<2:44:07,  9.39s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 884/1932 [2:18:14<2:44:00,  9.39s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 885/1932 [2:18:24<2:43:50,  9.39s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 886/1932 [2:18:33<2:43:39,  9.39s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 887/1932 [2:18:42<2:43:28,  9.39s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 888/1932 [2:18:52<2:43:17,  9.38s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 889/1932 [2:19:01<2:43:09,  9.39s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 890/1932 [2:19:10<2:42:58,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1839, 'learning_rate': 0.00010786749482401656, 'epoch': 1.38}\u001b[0m\n",
      "\u001b[34m46%|████▌     | 890/1932 [2:19:10<2:42:58,  9.38s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 891/1932 [2:19:20<2:42:50,  9.39s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 892/1932 [2:19:29<2:42:42,  9.39s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 893/1932 [2:19:39<2:42:30,  9.38s/it]\u001b[0m\n",
      "\u001b[34m46%|████▋     | 894/1932 [2:19:48<2:42:20,  9.38s/it]\u001b[0m\n",
      "\u001b[34m46%|████▋     | 895/1932 [2:19:57<2:42:08,  9.38s/it]\u001b[0m\n",
      "\u001b[34m46%|████▋     | 896/1932 [2:20:07<2:42:00,  9.38s/it]\u001b[0m\n",
      "\u001b[34m46%|████▋     | 897/1932 [2:20:16<2:41:52,  9.38s/it]\u001b[0m\n",
      "\u001b[34m46%|████▋     | 898/1932 [2:20:26<2:41:45,  9.39s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 899/1932 [2:20:35<2:41:35,  9.39s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 900/1932 [2:20:44<2:41:26,  9.39s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1655, 'learning_rate': 0.00010683229813664597, 'epoch': 1.4}\u001b[0m\n",
      "\u001b[34m47%|████▋     | 900/1932 [2:20:44<2:41:26,  9.39s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 901/1932 [2:20:54<2:41:17,  9.39s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 902/1932 [2:21:03<2:41:08,  9.39s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 903/1932 [2:21:12<2:40:56,  9.38s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 904/1932 [2:21:22<2:40:49,  9.39s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 905/1932 [2:21:31<2:40:42,  9.39s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 906/1932 [2:21:41<2:40:30,  9.39s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 907/1932 [2:21:50<2:40:19,  9.39s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 908/1932 [2:21:59<2:40:10,  9.38s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 909/1932 [2:22:09<2:40:01,  9.39s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 910/1932 [2:22:18<2:39:53,  9.39s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.21, 'learning_rate': 0.00010579710144927538, 'epoch': 1.41}\u001b[0m\n",
      "\u001b[34m47%|████▋     | 910/1932 [2:22:18<2:39:53,  9.39s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 911/1932 [2:22:28<2:39:42,  9.39s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 912/1932 [2:22:37<2:39:33,  9.39s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 913/1932 [2:22:46<2:39:24,  9.39s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 914/1932 [2:22:56<2:39:13,  9.38s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 915/1932 [2:23:05<2:39:06,  9.39s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 916/1932 [2:23:14<2:38:56,  9.39s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 917/1932 [2:23:24<2:38:46,  9.39s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 918/1932 [2:23:33<2:38:36,  9.38s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 919/1932 [2:23:43<2:38:26,  9.38s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 920/1932 [2:23:52<2:38:14,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1681, 'learning_rate': 0.00010476190476190477, 'epoch': 1.43}\u001b[0m\n",
      "\u001b[34m48%|████▊     | 920/1932 [2:23:52<2:38:14,  9.38s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 921/1932 [2:24:01<2:38:05,  9.38s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 922/1932 [2:24:11<2:37:56,  9.38s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 923/1932 [2:24:20<2:37:47,  9.38s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 924/1932 [2:24:30<2:37:37,  9.38s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 925/1932 [2:24:39<2:37:28,  9.38s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 926/1932 [2:24:48<2:37:17,  9.38s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 927/1932 [2:24:58<2:37:08,  9.38s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 928/1932 [2:25:07<2:37:02,  9.38s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 929/1932 [2:25:16<2:36:53,  9.39s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 930/1932 [2:25:26<2:36:43,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1633, 'learning_rate': 0.00010372670807453418, 'epoch': 1.44}\u001b[0m\n",
      "\u001b[34m48%|████▊     | 930/1932 [2:25:26<2:36:43,  9.38s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 931/1932 [2:25:35<2:36:33,  9.38s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 932/1932 [2:25:45<2:36:25,  9.39s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 933/1932 [2:25:54<2:36:17,  9.39s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 934/1932 [2:26:03<2:36:06,  9.38s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 935/1932 [2:26:13<2:35:57,  9.39s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 936/1932 [2:26:22<2:35:48,  9.39s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 937/1932 [2:26:32<2:35:37,  9.38s/it]\u001b[0m\n",
      "\u001b[34m49%|████▊     | 938/1932 [2:26:41<2:35:28,  9.39s/it]\u001b[0m\n",
      "\u001b[34m49%|████▊     | 939/1932 [2:26:50<2:35:20,  9.39s/it]\u001b[0m\n",
      "\u001b[34m49%|████▊     | 940/1932 [2:27:00<2:35:11,  9.39s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2446, 'learning_rate': 0.00010269151138716357, 'epoch': 1.46}\u001b[0m\n",
      "\u001b[34m49%|████▊     | 940/1932 [2:27:00<2:35:11,  9.39s/it]\u001b[0m\n",
      "\u001b[34m49%|████▊     | 941/1932 [2:27:09<2:35:02,  9.39s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 942/1932 [2:27:18<2:34:50,  9.38s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 943/1932 [2:27:28<2:34:41,  9.38s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 944/1932 [2:27:37<2:34:33,  9.39s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 945/1932 [2:27:47<2:34:21,  9.38s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 946/1932 [2:27:56<2:34:13,  9.39s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 947/1932 [2:28:05<2:34:04,  9.39s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 948/1932 [2:28:15<2:33:55,  9.39s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 949/1932 [2:28:24<2:33:45,  9.38s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 950/1932 [2:28:34<2:33:36,  9.39s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2277, 'learning_rate': 0.00010165631469979298, 'epoch': 1.47}\u001b[0m\n",
      "\u001b[34m49%|████▉     | 950/1932 [2:28:34<2:33:36,  9.39s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 951/1932 [2:28:43<2:33:26,  9.38s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 952/1932 [2:28:52<2:33:15,  9.38s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 953/1932 [2:29:02<2:33:05,  9.38s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 954/1932 [2:29:11<2:32:56,  9.38s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 955/1932 [2:29:20<2:32:47,  9.38s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 956/1932 [2:29:30<2:32:36,  9.38s/it]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 957/1932 [2:29:39<2:32:29,  9.38s/it]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 958/1932 [2:29:49<2:32:20,  9.38s/it]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 959/1932 [2:29:58<2:32:11,  9.38s/it]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 960/1932 [2:30:07<2:32:03,  9.39s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1889, 'learning_rate': 0.00010062111801242236, 'epoch': 1.49}\u001b[0m\n",
      "\u001b[34m50%|████▉     | 960/1932 [2:30:07<2:32:03,  9.39s/it]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 961/1932 [2:30:17<2:31:54,  9.39s/it]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 962/1932 [2:30:26<2:31:44,  9.39s/it]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 963/1932 [2:30:36<2:31:34,  9.39s/it]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 964/1932 [2:30:45<2:31:24,  9.38s/it]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 965/1932 [2:30:54<2:31:14,  9.38s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 966/1932 [2:31:04<2:31:03,  9.38s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 967/1932 [2:31:13<2:30:53,  9.38s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 968/1932 [2:31:22<2:30:43,  9.38s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 969/1932 [2:31:32<2:30:35,  9.38s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 970/1932 [2:31:41<2:30:26,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1995, 'learning_rate': 9.958592132505176e-05, 'epoch': 1.51}\u001b[0m\n",
      "\u001b[34m50%|█████     | 970/1932 [2:31:41<2:30:26,  9.38s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 971/1932 [2:31:51<2:30:19,  9.39s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 972/1932 [2:32:00<2:30:09,  9.38s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 973/1932 [2:32:09<2:29:58,  9.38s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 974/1932 [2:32:19<2:29:51,  9.39s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 975/1932 [2:32:28<2:29:40,  9.38s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 976/1932 [2:32:38<2:29:31,  9.38s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 977/1932 [2:32:47<2:29:22,  9.38s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 978/1932 [2:32:56<2:29:13,  9.39s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 979/1932 [2:33:06<2:29:03,  9.38s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 980/1932 [2:33:15<2:28:52,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1622, 'learning_rate': 9.855072463768117e-05, 'epoch': 1.52}\u001b[0m\n",
      "\u001b[34m51%|█████     | 980/1932 [2:33:15<2:28:52,  9.38s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 981/1932 [2:33:24<2:28:43,  9.38s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 982/1932 [2:33:34<2:28:32,  9.38s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 983/1932 [2:33:43<2:28:24,  9.38s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 984/1932 [2:33:53<2:28:13,  9.38s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 985/1932 [2:34:02<2:28:04,  9.38s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 986/1932 [2:34:11<2:27:56,  9.38s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 987/1932 [2:34:21<2:27:48,  9.38s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 988/1932 [2:34:30<2:27:36,  9.38s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 989/1932 [2:34:40<2:27:27,  9.38s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 990/1932 [2:34:49<2:27:17,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1849, 'learning_rate': 9.751552795031056e-05, 'epoch': 1.54}\u001b[0m\n",
      "\u001b[34m51%|█████     | 990/1932 [2:34:49<2:27:17,  9.38s/it]\u001b[0m\n",
      "\u001b[34m51%|█████▏    | 991/1932 [2:34:58<2:27:08,  9.38s/it]\u001b[0m\n",
      "\u001b[34m51%|█████▏    | 992/1932 [2:35:08<2:27:01,  9.38s/it]\u001b[0m\n",
      "\u001b[34m51%|█████▏    | 993/1932 [2:35:17<2:26:52,  9.38s/it]\u001b[0m\n",
      "\u001b[34m51%|█████▏    | 994/1932 [2:35:26<2:26:42,  9.38s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 995/1932 [2:35:36<2:26:32,  9.38s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 996/1932 [2:35:45<2:26:23,  9.38s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 997/1932 [2:35:55<2:26:13,  9.38s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 998/1932 [2:36:04<2:26:05,  9.38s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 999/1932 [2:36:13<2:25:58,  9.39s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 1000/1932 [2:36:23<2:25:50,  9.39s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1832, 'learning_rate': 9.648033126293996e-05, 'epoch': 1.55}\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 1000/1932 [2:36:23<2:25:50,  9.39s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 1001/1932 [2:36:32<2:25:40,  9.39s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 1002/1932 [2:36:42<2:25:30,  9.39s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 1003/1932 [2:36:51<2:25:20,  9.39s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 1004/1932 [2:37:00<2:25:10,  9.39s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 1005/1932 [2:37:10<2:24:59,  9.39s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 1006/1932 [2:37:19<2:24:51,  9.39s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 1007/1932 [2:37:28<2:24:41,  9.39s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 1008/1932 [2:37:38<2:24:30,  9.38s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 1009/1932 [2:37:47<2:24:21,  9.38s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 1010/1932 [2:37:57<2:24:11,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2024, 'learning_rate': 9.544513457556936e-05, 'epoch': 1.57}\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 1010/1932 [2:37:57<2:24:11,  9.38s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 1011/1932 [2:38:06<2:24:02,  9.38s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 1012/1932 [2:38:15<2:23:52,  9.38s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 1013/1932 [2:38:25<2:23:43,  9.38s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 1014/1932 [2:38:34<2:23:33,  9.38s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 1015/1932 [2:38:44<2:23:24,  9.38s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 1016/1932 [2:38:53<2:23:14,  9.38s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 1017/1932 [2:39:02<2:23:05,  9.38s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 1018/1932 [2:39:12<2:22:56,  9.38s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 1019/1932 [2:39:21<2:22:48,  9.39s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 1020/1932 [2:39:30<2:22:38,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2416, 'learning_rate': 9.440993788819877e-05, 'epoch': 1.58}\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 1020/1932 [2:39:30<2:22:38,  9.38s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 1021/1932 [2:39:40<2:22:30,  9.39s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 1022/1932 [2:39:49<2:22:20,  9.39s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 1023/1932 [2:39:59<2:22:08,  9.38s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 1024/1932 [2:40:08<2:21:59,  9.38s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 1025/1932 [2:40:17<2:21:50,  9.38s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 1026/1932 [2:40:27<2:21:40,  9.38s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 1027/1932 [2:40:36<2:21:31,  9.38s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 1028/1932 [2:40:46<2:21:23,  9.38s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 1029/1932 [2:40:55<2:21:14,  9.38s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 1030/1932 [2:41:04<2:21:06,  9.39s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1768, 'learning_rate': 9.337474120082816e-05, 'epoch': 1.6}\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 1030/1932 [2:41:04<2:21:06,  9.39s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 1031/1932 [2:41:14<2:20:55,  9.38s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 1032/1932 [2:41:23<2:20:47,  9.39s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 1033/1932 [2:41:32<2:20:36,  9.38s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▎    | 1034/1932 [2:41:42<2:20:25,  9.38s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▎    | 1035/1932 [2:41:51<2:20:15,  9.38s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▎    | 1036/1932 [2:42:01<2:20:05,  9.38s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▎    | 1037/1932 [2:42:10<2:19:54,  9.38s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▎    | 1038/1932 [2:42:19<2:19:47,  9.38s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 1039/1932 [2:42:29<2:19:39,  9.38s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 1040/1932 [2:42:38<2:19:32,  9.39s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1861, 'learning_rate': 9.233954451345757e-05, 'epoch': 1.61}\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 1040/1932 [2:42:38<2:19:32,  9.39s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 1041/1932 [2:42:48<2:19:21,  9.38s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 1042/1932 [2:42:57<2:19:11,  9.38s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 1043/1932 [2:43:06<2:19:01,  9.38s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 1044/1932 [2:43:16<2:18:54,  9.39s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 1045/1932 [2:43:25<2:18:44,  9.39s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 1046/1932 [2:43:34<2:18:35,  9.39s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 1047/1932 [2:43:44<2:18:23,  9.38s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 1048/1932 [2:43:53<2:18:14,  9.38s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 1049/1932 [2:44:03<2:18:03,  9.38s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 1050/1932 [2:44:12<2:17:55,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1741, 'learning_rate': 9.130434782608696e-05, 'epoch': 1.63}\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 1050/1932 [2:44:12<2:17:55,  9.38s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 1051/1932 [2:44:21<2:17:46,  9.38s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 1052/1932 [2:44:31<2:17:36,  9.38s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 1053/1932 [2:44:40<2:17:27,  9.38s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 1054/1932 [2:44:49<2:17:19,  9.38s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 1055/1932 [2:44:59<2:17:10,  9.39s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 1056/1932 [2:45:08<2:17:02,  9.39s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 1057/1932 [2:45:18<2:16:53,  9.39s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 1058/1932 [2:45:27<2:16:42,  9.38s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 1059/1932 [2:45:36<2:16:32,  9.38s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 1060/1932 [2:45:46<2:16:23,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1526, 'learning_rate': 9.026915113871636e-05, 'epoch': 1.64}\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 1060/1932 [2:45:46<2:16:23,  9.38s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 1061/1932 [2:45:55<2:16:15,  9.39s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 1062/1932 [2:46:05<2:16:07,  9.39s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 1063/1932 [2:46:14<2:15:58,  9.39s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 1064/1932 [2:46:23<2:15:48,  9.39s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 1065/1932 [2:46:33<2:15:36,  9.39s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 1066/1932 [2:46:42<2:15:27,  9.38s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 1067/1932 [2:46:52<2:15:17,  9.38s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 1068/1932 [2:47:01<2:15:07,  9.38s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 1069/1932 [2:47:10<2:14:57,  9.38s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 1070/1932 [2:47:20<2:14:50,  9.39s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2037, 'learning_rate': 8.923395445134576e-05, 'epoch': 1.66}\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 1070/1932 [2:47:20<2:14:50,  9.39s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 1071/1932 [2:47:29<2:14:40,  9.39s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 1072/1932 [2:47:38<2:14:30,  9.38s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 1073/1932 [2:47:48<2:14:20,  9.38s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 1074/1932 [2:47:57<2:14:11,  9.38s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 1075/1932 [2:48:07<2:14:01,  9.38s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 1076/1932 [2:48:16<2:13:53,  9.39s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 1077/1932 [2:48:25<2:13:42,  9.38s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 1078/1932 [2:48:35<2:13:33,  9.38s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 1079/1932 [2:48:44<2:13:21,  9.38s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 1080/1932 [2:48:53<2:13:13,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1733, 'learning_rate': 8.819875776397516e-05, 'epoch': 1.68}\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 1080/1932 [2:48:53<2:13:13,  9.38s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 1081/1932 [2:49:03<2:13:04,  9.38s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 1082/1932 [2:49:12<2:12:55,  9.38s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 1083/1932 [2:49:22<2:12:45,  9.38s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 1084/1932 [2:49:31<2:12:35,  9.38s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 1085/1932 [2:49:40<2:12:24,  9.38s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 1086/1932 [2:49:50<2:12:14,  9.38s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▋    | 1087/1932 [2:49:59<2:12:04,  9.38s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▋    | 1088/1932 [2:50:09<2:11:54,  9.38s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▋    | 1089/1932 [2:50:18<2:11:46,  9.38s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▋    | 1090/1932 [2:50:27<2:11:36,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2082, 'learning_rate': 8.716356107660456e-05, 'epoch': 1.69}\u001b[0m\n",
      "\u001b[34m56%|█████▋    | 1090/1932 [2:50:27<2:11:36,  9.38s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▋    | 1091/1932 [2:50:37<2:11:28,  9.38s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 1092/1932 [2:50:46<2:11:18,  9.38s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 1093/1932 [2:50:55<2:11:11,  9.38s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 1094/1932 [2:51:05<2:11:02,  9.38s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 1095/1932 [2:51:14<2:10:54,  9.38s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 1096/1932 [2:51:24<2:10:44,  9.38s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 1097/1932 [2:51:33<2:10:33,  9.38s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 1098/1932 [2:51:42<2:10:24,  9.38s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 1099/1932 [2:51:52<2:10:15,  9.38s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 1100/1932 [2:52:01<2:10:03,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2609, 'learning_rate': 8.612836438923396e-05, 'epoch': 1.71}\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 1100/1932 [2:52:01<2:10:03,  9.38s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 1101/1932 [2:52:10<2:09:56,  9.38s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 1102/1932 [2:52:20<2:09:48,  9.38s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 1103/1932 [2:52:29<2:09:39,  9.38s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 1104/1932 [2:52:39<2:09:30,  9.38s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 1105/1932 [2:52:48<2:09:20,  9.38s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 1106/1932 [2:52:57<2:09:11,  9.38s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 1107/1932 [2:53:07<2:09:03,  9.39s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 1108/1932 [2:53:16<2:08:53,  9.39s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 1109/1932 [2:53:26<2:08:42,  9.38s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 1110/1932 [2:53:35<2:08:34,  9.39s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1687, 'learning_rate': 8.509316770186336e-05, 'epoch': 1.72}\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 1110/1932 [2:53:35<2:08:34,  9.39s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 1111/1932 [2:53:44<2:08:26,  9.39s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 1112/1932 [2:53:54<2:08:16,  9.39s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 1113/1932 [2:54:03<2:08:04,  9.38s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 1114/1932 [2:54:12<2:07:56,  9.38s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 1115/1932 [2:54:22<2:07:48,  9.39s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 1116/1932 [2:54:31<2:07:37,  9.38s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 1117/1932 [2:54:41<2:07:27,  9.38s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 1118/1932 [2:54:50<2:07:18,  9.38s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 1119/1932 [2:54:59<2:07:09,  9.38s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 1120/1932 [2:55:09<2:06:59,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1854, 'learning_rate': 8.405797101449276e-05, 'epoch': 1.74}\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 1120/1932 [2:55:09<2:06:59,  9.38s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 1121/1932 [2:55:18<2:06:51,  9.39s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 1122/1932 [2:55:28<2:06:43,  9.39s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 1123/1932 [2:55:37<2:06:34,  9.39s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 1124/1932 [2:55:46<2:06:25,  9.39s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 1125/1932 [2:55:56<2:06:16,  9.39s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 1126/1932 [2:56:05<2:06:05,  9.39s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 1127/1932 [2:56:15<2:05:55,  9.39s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 1128/1932 [2:56:24<2:05:45,  9.39s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 1129/1932 [2:56:33<2:05:35,  9.38s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 1130/1932 [2:56:43<2:05:27,  9.39s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1399, 'learning_rate': 8.302277432712215e-05, 'epoch': 1.75}\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 1130/1932 [2:56:43<2:05:27,  9.39s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▊    | 1131/1932 [2:56:52<2:05:17,  9.39s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▊    | 1132/1932 [2:57:01<2:05:08,  9.39s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▊    | 1133/1932 [2:57:11<2:04:57,  9.38s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▊    | 1134/1932 [2:57:20<2:04:48,  9.38s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▊    | 1135/1932 [2:57:30<2:04:37,  9.38s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 1136/1932 [2:57:39<2:04:27,  9.38s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 1137/1932 [2:57:48<2:04:18,  9.38s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 1138/1932 [2:57:58<2:04:08,  9.38s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 1139/1932 [2:58:07<2:03:59,  9.38s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 1140/1932 [2:58:16<2:03:49,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1885, 'learning_rate': 8.198757763975156e-05, 'epoch': 1.77}\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 1140/1932 [2:58:16<2:03:49,  9.38s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 1141/1932 [2:58:26<2:03:39,  9.38s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 1142/1932 [2:58:35<2:03:31,  9.38s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 1143/1932 [2:58:45<2:03:23,  9.38s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 1144/1932 [2:58:54<2:03:12,  9.38s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 1145/1932 [2:59:03<2:03:02,  9.38s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 1146/1932 [2:59:13<2:02:52,  9.38s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 1147/1932 [2:59:22<2:02:42,  9.38s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 1148/1932 [2:59:32<2:02:32,  9.38s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 1149/1932 [2:59:41<2:02:22,  9.38s/it]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 1150/1932 [2:59:50<2:02:14,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1667, 'learning_rate': 8.095238095238096e-05, 'epoch': 1.78}\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 1150/1932 [2:59:50<2:02:14,  9.38s/it]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 1151/1932 [3:00:00<2:02:05,  9.38s/it]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 1152/1932 [3:00:09<2:01:57,  9.38s/it]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 1153/1932 [3:00:18<2:01:49,  9.38s/it]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 1154/1932 [3:00:28<2:01:41,  9.38s/it]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 1155/1932 [3:00:37<2:01:30,  9.38s/it]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 1156/1932 [3:00:47<2:01:22,  9.38s/it]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 1157/1932 [3:00:56<2:01:12,  9.38s/it]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 1158/1932 [3:01:05<2:01:03,  9.38s/it]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 1159/1932 [3:01:15<2:00:54,  9.38s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 1160/1932 [3:01:24<2:00:44,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1784, 'learning_rate': 7.991718426501036e-05, 'epoch': 1.8}\u001b[0m\n",
      "\u001b[34m60%|██████    | 1160/1932 [3:01:24<2:00:44,  9.38s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 1161/1932 [3:01:34<2:00:34,  9.38s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 1162/1932 [3:01:43<2:00:25,  9.38s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 1163/1932 [3:01:52<2:00:14,  9.38s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 1164/1932 [3:02:02<2:00:04,  9.38s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 1165/1932 [3:02:11<1:59:55,  9.38s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 1166/1932 [3:02:20<1:59:47,  9.38s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 1167/1932 [3:02:30<1:59:39,  9.38s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 1168/1932 [3:02:39<1:59:30,  9.39s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 1169/1932 [3:02:49<1:59:19,  9.38s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 1170/1932 [3:02:58<1:59:10,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1901, 'learning_rate': 7.888198757763976e-05, 'epoch': 1.82}\u001b[0m\n",
      "\u001b[34m61%|██████    | 1170/1932 [3:02:58<1:59:10,  9.38s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 1171/1932 [3:03:07<1:59:01,  9.38s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 1172/1932 [3:03:17<1:58:51,  9.38s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 1173/1932 [3:03:26<1:58:43,  9.38s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 1174/1932 [3:03:35<1:58:33,  9.38s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 1175/1932 [3:03:45<1:58:22,  9.38s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 1176/1932 [3:03:54<1:58:12,  9.38s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 1177/1932 [3:04:04<1:58:02,  9.38s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 1178/1932 [3:04:13<1:57:55,  9.38s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 1179/1932 [3:04:22<1:57:47,  9.39s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 1180/1932 [3:04:32<1:57:38,  9.39s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1803, 'learning_rate': 7.784679089026916e-05, 'epoch': 1.83}\u001b[0m\n",
      "\u001b[34m61%|██████    | 1180/1932 [3:04:32<1:57:38,  9.39s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 1181/1932 [3:04:41<1:57:27,  9.38s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 1182/1932 [3:04:51<1:57:18,  9.39s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 1183/1932 [3:05:00<1:57:08,  9.38s/it]\u001b[0m\n",
      "\u001b[34m61%|██████▏   | 1184/1932 [3:05:09<1:57:01,  9.39s/it]\u001b[0m\n",
      "\u001b[34m61%|██████▏   | 1185/1932 [3:05:19<1:56:52,  9.39s/it]\u001b[0m\n",
      "\u001b[34m61%|██████▏   | 1186/1932 [3:05:28<1:56:41,  9.39s/it]\u001b[0m\n",
      "\u001b[34m61%|██████▏   | 1187/1932 [3:05:37<1:56:32,  9.39s/it]\u001b[0m\n",
      "\u001b[34m61%|██████▏   | 1188/1932 [3:05:47<1:56:22,  9.38s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 1189/1932 [3:05:56<1:56:13,  9.39s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 1190/1932 [3:06:06<1:56:04,  9.39s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1603, 'learning_rate': 7.681159420289855e-05, 'epoch': 1.85}\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 1190/1932 [3:06:06<1:56:04,  9.39s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 1191/1932 [3:06:15<1:55:54,  9.39s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 1192/1932 [3:06:24<1:55:44,  9.38s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 1193/1932 [3:06:34<1:55:34,  9.38s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 1194/1932 [3:06:43<1:55:25,  9.38s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 1195/1932 [3:06:53<1:55:15,  9.38s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 1196/1932 [3:07:02<1:55:06,  9.38s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 1197/1932 [3:07:11<1:54:56,  9.38s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 1198/1932 [3:07:21<1:54:47,  9.38s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 1199/1932 [3:07:30<1:54:36,  9.38s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 1200/1932 [3:07:39<1:54:26,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1445, 'learning_rate': 7.577639751552796e-05, 'epoch': 1.86}\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 1200/1932 [3:07:39<1:54:26,  9.38s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 1201/1932 [3:07:49<1:54:20,  9.38s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 1202/1932 [3:07:58<1:54:11,  9.39s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 1203/1932 [3:08:08<1:54:02,  9.39s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 1204/1932 [3:08:17<1:53:52,  9.39s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 1205/1932 [3:08:26<1:53:43,  9.39s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 1206/1932 [3:08:36<1:53:33,  9.38s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 1207/1932 [3:08:45<1:53:23,  9.38s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 1208/1932 [3:08:55<1:53:13,  9.38s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 1209/1932 [3:09:04<1:53:03,  9.38s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 1210/1932 [3:09:13<1:52:54,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2304, 'learning_rate': 7.474120082815735e-05, 'epoch': 1.88}\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 1210/1932 [3:09:13<1:52:54,  9.38s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 1211/1932 [3:09:23<1:52:45,  9.38s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 1212/1932 [3:09:32<1:52:36,  9.38s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 1213/1932 [3:09:41<1:52:26,  9.38s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 1214/1932 [3:09:51<1:52:17,  9.38s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 1215/1932 [3:10:00<1:52:08,  9.38s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 1216/1932 [3:10:10<1:51:59,  9.38s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 1217/1932 [3:10:19<1:51:52,  9.39s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 1218/1932 [3:10:28<1:51:42,  9.39s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 1219/1932 [3:10:38<1:51:32,  9.39s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 1220/1932 [3:10:47<1:51:23,  9.39s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1828, 'learning_rate': 7.370600414078676e-05, 'epoch': 1.89}\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 1220/1932 [3:10:47<1:51:23,  9.39s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 1221/1932 [3:10:57<1:51:12,  9.38s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 1222/1932 [3:11:06<1:51:04,  9.39s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 1223/1932 [3:11:15<1:50:54,  9.39s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 1224/1932 [3:11:25<1:50:43,  9.38s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 1225/1932 [3:11:34<1:50:35,  9.38s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 1226/1932 [3:11:43<1:50:26,  9.39s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▎   | 1227/1932 [3:11:53<1:50:19,  9.39s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▎   | 1228/1932 [3:12:02<1:50:11,  9.39s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▎   | 1229/1932 [3:12:12<1:50:01,  9.39s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▎   | 1230/1932 [3:12:21<1:49:51,  9.39s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1261, 'learning_rate': 7.267080745341616e-05, 'epoch': 1.91}\u001b[0m\n",
      "\u001b[34m64%|██████▎   | 1230/1932 [3:12:21<1:49:51,  9.39s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▎   | 1231/1932 [3:12:30<1:49:41,  9.39s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 1232/1932 [3:12:40<1:49:31,  9.39s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 1233/1932 [3:12:49<1:49:22,  9.39s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 1234/1932 [3:12:59<1:49:13,  9.39s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 1235/1932 [3:13:08<1:49:03,  9.39s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 1236/1932 [3:13:17<1:48:54,  9.39s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 1237/1932 [3:13:27<1:48:43,  9.39s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 1238/1932 [3:13:36<1:48:33,  9.39s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 1239/1932 [3:13:46<1:48:24,  9.39s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 1240/1932 [3:13:55<1:48:14,  9.39s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1812, 'learning_rate': 7.163561076604554e-05, 'epoch': 1.92}\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 1240/1932 [3:13:55<1:48:14,  9.39s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 1241/1932 [3:14:04<1:48:04,  9.38s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 1242/1932 [3:14:14<1:47:56,  9.39s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 1243/1932 [3:14:23<1:47:47,  9.39s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 1244/1932 [3:14:32<1:47:37,  9.39s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 1245/1932 [3:14:42<1:47:26,  9.38s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 1246/1932 [3:14:51<1:47:17,  9.38s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 1247/1932 [3:15:01<1:47:06,  9.38s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 1248/1932 [3:15:10<1:46:57,  9.38s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 1249/1932 [3:15:19<1:46:48,  9.38s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 1250/1932 [3:15:29<1:46:38,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1603, 'learning_rate': 7.060041407867495e-05, 'epoch': 1.94}\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 1250/1932 [3:15:29<1:46:38,  9.38s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 1251/1932 [3:15:38<1:46:30,  9.38s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 1252/1932 [3:15:48<1:46:20,  9.38s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 1253/1932 [3:15:57<1:46:11,  9.38s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 1254/1932 [3:16:06<1:46:02,  9.38s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 1255/1932 [3:16:16<1:45:52,  9.38s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 1256/1932 [3:16:25<1:45:43,  9.38s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 1257/1932 [3:16:34<1:45:33,  9.38s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 1258/1932 [3:16:44<1:45:22,  9.38s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 1259/1932 [3:16:53<1:45:13,  9.38s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 1260/1932 [3:17:03<1:45:06,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1952, 'learning_rate': 6.956521739130436e-05, 'epoch': 1.96}\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 1260/1932 [3:17:03<1:45:06,  9.38s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 1261/1932 [3:17:12<1:44:57,  9.39s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 1262/1932 [3:17:21<1:44:47,  9.38s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 1263/1932 [3:17:31<1:44:38,  9.38s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 1264/1932 [3:17:40<1:44:28,  9.38s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 1265/1932 [3:17:50<1:44:20,  9.39s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 1266/1932 [3:17:59<1:44:11,  9.39s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 1267/1932 [3:18:08<1:44:02,  9.39s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 1268/1932 [3:18:18<1:43:52,  9.39s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 1269/1932 [3:18:27<1:43:42,  9.38s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 1270/1932 [3:18:36<1:43:32,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1572, 'learning_rate': 6.853002070393375e-05, 'epoch': 1.97}\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 1270/1932 [3:18:36<1:43:32,  9.38s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 1271/1932 [3:18:46<1:43:22,  9.38s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 1272/1932 [3:18:55<1:43:13,  9.38s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 1273/1932 [3:19:05<1:43:04,  9.38s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 1274/1932 [3:19:14<1:42:54,  9.38s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 1275/1932 [3:19:23<1:42:47,  9.39s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 1276/1932 [3:19:33<1:42:36,  9.39s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 1277/1932 [3:19:42<1:42:27,  9.39s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 1278/1932 [3:19:52<1:42:18,  9.39s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 1279/1932 [3:20:01<1:42:08,  9.38s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▋   | 1280/1932 [3:20:10<1:41:58,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1677, 'learning_rate': 6.749482401656316e-05, 'epoch': 1.99}\u001b[0m\n",
      "\u001b[34m66%|██████▋   | 1280/1932 [3:20:10<1:41:58,  9.38s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▋   | 1281/1932 [3:20:20<1:41:49,  9.38s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▋   | 1282/1932 [3:20:29<1:41:40,  9.39s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▋   | 1283/1932 [3:20:38<1:41:30,  9.38s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▋   | 1284/1932 [3:20:48<1:41:21,  9.38s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 1285/1932 [3:20:57<1:41:12,  9.39s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 1286/1932 [3:21:07<1:41:01,  9.38s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 1287/1932 [3:21:16<1:40:53,  9.38s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 1288/1932 [3:21:25<1:40:41,  9.38s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 1289/1932 [3:21:35<1:40:30,  9.38s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 1290/1932 [3:21:44<1:40:21,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1292, 'learning_rate': 6.645962732919255e-05, 'epoch': 2.0}\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 1290/1932 [3:21:44<1:40:21,  9.38s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 1291/1932 [3:21:53<1:40:11,  9.38s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 1292/1932 [3:22:03<1:40:01,  9.38s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 1293/1932 [3:22:12<1:39:53,  9.38s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 1294/1932 [3:22:22<1:39:43,  9.38s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 1295/1932 [3:22:31<1:39:35,  9.38s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 1296/1932 [3:22:40<1:39:24,  9.38s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 1297/1932 [3:22:50<1:39:13,  9.38s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 1298/1932 [3:22:59<1:39:05,  9.38s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 1299/1932 [3:23:09<1:38:55,  9.38s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 1300/1932 [3:23:18<1:38:46,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1396, 'learning_rate': 6.542443064182196e-05, 'epoch': 2.02}\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 1300/1932 [3:23:18<1:38:46,  9.38s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 1301/1932 [3:23:27<1:38:37,  9.38s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 1302/1932 [3:23:37<1:38:28,  9.38s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 1303/1932 [3:23:46<1:38:19,  9.38s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 1304/1932 [3:23:55<1:38:10,  9.38s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 1305/1932 [3:24:05<1:38:01,  9.38s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 1306/1932 [3:24:14<1:37:53,  9.38s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 1307/1932 [3:24:24<1:37:44,  9.38s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 1308/1932 [3:24:33<1:37:35,  9.38s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 1309/1932 [3:24:42<1:37:25,  9.38s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 1310/1932 [3:24:52<1:37:16,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1711, 'learning_rate': 6.438923395445135e-05, 'epoch': 2.03}\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 1310/1932 [3:24:52<1:37:16,  9.38s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 1311/1932 [3:25:01<1:37:06,  9.38s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 1312/1932 [3:25:10<1:36:56,  9.38s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 1313/1932 [3:25:20<1:36:44,  9.38s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 1314/1932 [3:25:29<1:36:33,  9.37s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 1315/1932 [3:25:39<1:36:22,  9.37s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 1316/1932 [3:25:48<1:36:11,  9.37s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 1317/1932 [3:25:57<1:36:01,  9.37s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 1318/1932 [3:26:07<1:35:52,  9.37s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 1319/1932 [3:26:16<1:35:42,  9.37s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 1320/1932 [3:26:25<1:35:33,  9.37s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1509, 'learning_rate': 6.335403726708074e-05, 'epoch': 2.05}\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 1320/1932 [3:26:25<1:35:33,  9.37s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 1321/1932 [3:26:35<1:35:22,  9.37s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 1322/1932 [3:26:44<1:35:12,  9.36s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 1323/1932 [3:26:54<1:35:03,  9.37s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▊   | 1324/1932 [3:27:03<1:34:54,  9.37s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▊   | 1325/1932 [3:27:12<1:34:44,  9.37s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▊   | 1326/1932 [3:27:22<1:34:36,  9.37s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▊   | 1327/1932 [3:27:31<1:34:27,  9.37s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▊   | 1328/1932 [3:27:40<1:34:18,  9.37s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 1329/1932 [3:27:50<1:34:10,  9.37s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 1330/1932 [3:27:59<1:34:02,  9.37s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.14, 'learning_rate': 6.231884057971015e-05, 'epoch': 2.06}\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 1330/1932 [3:27:59<1:34:02,  9.37s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 1331/1932 [3:28:08<1:33:54,  9.37s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 1332/1932 [3:28:18<1:33:44,  9.37s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 1333/1932 [3:28:27<1:33:35,  9.38s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 1334/1932 [3:28:37<1:33:26,  9.38s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 1335/1932 [3:28:46<1:33:17,  9.38s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 1336/1932 [3:28:55<1:33:08,  9.38s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 1337/1932 [3:29:05<1:32:59,  9.38s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 1338/1932 [3:29:14<1:32:49,  9.38s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 1339/1932 [3:29:23<1:32:40,  9.38s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 1340/1932 [3:29:33<1:32:31,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1772, 'learning_rate': 6.128364389233954e-05, 'epoch': 2.08}\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 1340/1932 [3:29:33<1:32:31,  9.38s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 1341/1932 [3:29:42<1:32:22,  9.38s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 1342/1932 [3:29:52<1:32:13,  9.38s/it]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 1343/1932 [3:30:01<1:32:05,  9.38s/it]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 1344/1932 [3:30:10<1:31:57,  9.38s/it]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 1345/1932 [3:30:20<1:31:49,  9.39s/it]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 1346/1932 [3:30:29<1:31:40,  9.39s/it]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 1347/1932 [3:30:39<1:31:30,  9.39s/it]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 1348/1932 [3:30:48<1:31:20,  9.39s/it]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 1349/1932 [3:30:57<1:31:10,  9.38s/it]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 1350/1932 [3:31:07<1:31:02,  9.39s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1242, 'learning_rate': 6.024844720496895e-05, 'epoch': 2.09}\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 1350/1932 [3:31:07<1:31:02,  9.39s/it]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 1351/1932 [3:31:16<1:30:52,  9.39s/it]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 1352/1932 [3:31:25<1:30:43,  9.38s/it]\u001b[0m\n",
      "\u001b[34m70%|███████   | 1353/1932 [3:31:35<1:30:34,  9.39s/it]\u001b[0m\n",
      "\u001b[34m70%|███████   | 1354/1932 [3:31:44<1:30:24,  9.39s/it]\u001b[0m\n",
      "\u001b[34m70%|███████   | 1355/1932 [3:31:54<1:30:15,  9.39s/it]\u001b[0m\n",
      "\u001b[34m70%|███████   | 1356/1932 [3:32:03<1:30:06,  9.39s/it]\u001b[0m\n",
      "\u001b[34m70%|███████   | 1357/1932 [3:32:12<1:29:58,  9.39s/it]\u001b[0m\n",
      "\u001b[34m70%|███████   | 1358/1932 [3:32:22<1:29:49,  9.39s/it]\u001b[0m\n",
      "\u001b[34m70%|███████   | 1359/1932 [3:32:31<1:29:39,  9.39s/it]\u001b[0m\n",
      "\u001b[34m70%|███████   | 1360/1932 [3:32:41<1:29:31,  9.39s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1622, 'learning_rate': 5.921325051759835e-05, 'epoch': 2.11}\u001b[0m\n",
      "\u001b[34m70%|███████   | 1360/1932 [3:32:41<1:29:31,  9.39s/it]\u001b[0m\n",
      "\u001b[34m70%|███████   | 1361/1932 [3:32:50<1:29:21,  9.39s/it]\u001b[0m\n",
      "\u001b[34m70%|███████   | 1362/1932 [3:32:59<1:29:11,  9.39s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 1363/1932 [3:33:09<1:29:03,  9.39s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 1364/1932 [3:33:18<1:28:54,  9.39s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 1365/1932 [3:33:28<1:28:45,  9.39s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 1366/1932 [3:33:37<1:28:35,  9.39s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 1367/1932 [3:33:46<1:28:25,  9.39s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 1368/1932 [3:33:56<1:28:14,  9.39s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 1369/1932 [3:34:05<1:28:05,  9.39s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 1370/1932 [3:34:14<1:27:55,  9.39s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1585, 'learning_rate': 5.817805383022774e-05, 'epoch': 2.13}\u001b[0m\n",
      "\u001b[34m71%|███████   | 1370/1932 [3:34:14<1:27:55,  9.39s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 1371/1932 [3:34:24<1:27:45,  9.39s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 1372/1932 [3:34:33<1:27:36,  9.39s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 1373/1932 [3:34:43<1:27:26,  9.39s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 1374/1932 [3:34:52<1:27:17,  9.39s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 1375/1932 [3:35:01<1:27:08,  9.39s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 1376/1932 [3:35:11<1:26:58,  9.39s/it]\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 1377/1932 [3:35:20<1:26:49,  9.39s/it]\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 1378/1932 [3:35:30<1:26:41,  9.39s/it]\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 1379/1932 [3:35:39<1:26:31,  9.39s/it]\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 1380/1932 [3:35:48<1:26:22,  9.39s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1623, 'learning_rate': 5.714285714285714e-05, 'epoch': 2.14}\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 1380/1932 [3:35:48<1:26:22,  9.39s/it]\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 1381/1932 [3:35:58<1:26:13,  9.39s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 1382/1932 [3:36:07<1:26:03,  9.39s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 1383/1932 [3:36:17<1:25:53,  9.39s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 1384/1932 [3:36:26<1:25:43,  9.39s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 1385/1932 [3:36:35<1:25:35,  9.39s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 1386/1932 [3:36:45<1:25:26,  9.39s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 1387/1932 [3:36:54<1:25:16,  9.39s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 1388/1932 [3:37:03<1:25:06,  9.39s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 1389/1932 [3:37:13<1:24:56,  9.39s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 1390/1932 [3:37:22<1:24:46,  9.39s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1872, 'learning_rate': 5.610766045548654e-05, 'epoch': 2.16}\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 1390/1932 [3:37:22<1:24:46,  9.39s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 1391/1932 [3:37:32<1:24:36,  9.38s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 1392/1932 [3:37:41<1:24:26,  9.38s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 1393/1932 [3:37:50<1:24:19,  9.39s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 1394/1932 [3:38:00<1:24:10,  9.39s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 1395/1932 [3:38:09<1:24:00,  9.39s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 1396/1932 [3:38:19<1:23:50,  9.39s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 1397/1932 [3:38:28<1:23:39,  9.38s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 1398/1932 [3:38:37<1:23:28,  9.38s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 1399/1932 [3:38:47<1:23:16,  9.38s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 1400/1932 [3:38:56<1:23:05,  9.37s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1579, 'learning_rate': 5.507246376811594e-05, 'epoch': 2.17}\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 1400/1932 [3:38:56<1:23:05,  9.37s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 1401/1932 [3:39:05<1:22:55,  9.37s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 1402/1932 [3:39:15<1:22:46,  9.37s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 1403/1932 [3:39:24<1:22:36,  9.37s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 1404/1932 [3:39:34<1:22:26,  9.37s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 1405/1932 [3:39:43<1:22:17,  9.37s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 1406/1932 [3:39:52<1:22:08,  9.37s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 1407/1932 [3:40:02<1:21:59,  9.37s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 1408/1932 [3:40:11<1:21:50,  9.37s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 1409/1932 [3:40:20<1:21:41,  9.37s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 1410/1932 [3:40:30<1:21:31,  9.37s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.0968, 'learning_rate': 5.403726708074535e-05, 'epoch': 2.19}\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 1410/1932 [3:40:30<1:21:31,  9.37s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 1411/1932 [3:40:39<1:21:22,  9.37s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 1412/1932 [3:40:48<1:21:13,  9.37s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 1413/1932 [3:40:58<1:21:03,  9.37s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 1414/1932 [3:41:07<1:20:54,  9.37s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 1415/1932 [3:41:17<1:20:45,  9.37s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 1416/1932 [3:41:26<1:20:36,  9.37s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 1417/1932 [3:41:35<1:20:28,  9.38s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 1418/1932 [3:41:45<1:20:17,  9.37s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 1419/1932 [3:41:54<1:20:08,  9.37s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 1420/1932 [3:42:03<1:19:58,  9.37s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1192, 'learning_rate': 5.300207039337475e-05, 'epoch': 2.2}\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 1420/1932 [3:42:03<1:19:58,  9.37s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▎  | 1421/1932 [3:42:13<1:19:48,  9.37s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▎  | 1422/1932 [3:42:22<1:19:39,  9.37s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▎  | 1423/1932 [3:42:32<1:19:29,  9.37s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▎  | 1424/1932 [3:42:41<1:19:19,  9.37s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 1425/1932 [3:42:50<1:19:11,  9.37s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 1426/1932 [3:43:00<1:19:02,  9.37s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 1427/1932 [3:43:09<1:18:53,  9.37s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 1428/1932 [3:43:18<1:18:45,  9.38s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 1429/1932 [3:43:28<1:18:35,  9.38s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 1430/1932 [3:43:37<1:18:26,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1395, 'learning_rate': 5.1966873706004135e-05, 'epoch': 2.22}\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 1430/1932 [3:43:37<1:18:26,  9.38s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 1431/1932 [3:43:47<1:18:17,  9.38s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 1432/1932 [3:43:56<1:18:08,  9.38s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 1433/1932 [3:44:05<1:17:58,  9.38s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 1434/1932 [3:44:15<1:17:50,  9.38s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 1435/1932 [3:44:24<1:17:41,  9.38s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 1436/1932 [3:44:33<1:17:32,  9.38s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 1437/1932 [3:44:43<1:17:23,  9.38s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 1438/1932 [3:44:52<1:17:13,  9.38s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 1439/1932 [3:45:02<1:17:04,  9.38s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 1440/1932 [3:45:11<1:16:55,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1249, 'learning_rate': 5.093167701863354e-05, 'epoch': 2.23}\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 1440/1932 [3:45:11<1:16:55,  9.38s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 1441/1932 [3:45:20<1:16:47,  9.38s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 1442/1932 [3:45:30<1:16:37,  9.38s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 1443/1932 [3:45:39<1:16:27,  9.38s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 1444/1932 [3:45:49<1:16:18,  9.38s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 1445/1932 [3:45:58<1:16:09,  9.38s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 1446/1932 [3:46:07<1:15:59,  9.38s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 1447/1932 [3:46:17<1:15:50,  9.38s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 1448/1932 [3:46:26<1:15:40,  9.38s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 1449/1932 [3:46:35<1:15:29,  9.38s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 1450/1932 [3:46:45<1:15:18,  9.37s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1506, 'learning_rate': 4.989648033126294e-05, 'epoch': 2.25}\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 1450/1932 [3:46:45<1:15:18,  9.37s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 1451/1932 [3:46:54<1:15:07,  9.37s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 1452/1932 [3:47:04<1:14:57,  9.37s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 1453/1932 [3:47:13<1:14:48,  9.37s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 1454/1932 [3:47:22<1:14:38,  9.37s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 1455/1932 [3:47:32<1:14:29,  9.37s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 1456/1932 [3:47:41<1:14:20,  9.37s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 1457/1932 [3:47:50<1:14:11,  9.37s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 1458/1932 [3:48:00<1:14:01,  9.37s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 1459/1932 [3:48:09<1:13:52,  9.37s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 1460/1932 [3:48:18<1:13:42,  9.37s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1391, 'learning_rate': 4.886128364389234e-05, 'epoch': 2.27}\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 1460/1932 [3:48:18<1:13:42,  9.37s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 1461/1932 [3:48:28<1:13:32,  9.37s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 1462/1932 [3:48:37<1:13:23,  9.37s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 1463/1932 [3:48:47<1:13:14,  9.37s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 1464/1932 [3:48:56<1:13:05,  9.37s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 1465/1932 [3:49:05<1:12:55,  9.37s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 1466/1932 [3:49:15<1:12:45,  9.37s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 1467/1932 [3:49:24<1:12:36,  9.37s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 1468/1932 [3:49:33<1:12:25,  9.37s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 1469/1932 [3:49:43<1:12:17,  9.37s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 1470/1932 [3:49:52<1:12:08,  9.37s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.107, 'learning_rate': 4.782608695652174e-05, 'epoch': 2.28}\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 1470/1932 [3:49:52<1:12:08,  9.37s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 1471/1932 [3:50:02<1:11:58,  9.37s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 1472/1932 [3:50:11<1:11:48,  9.37s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 1473/1932 [3:50:20<1:11:40,  9.37s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▋  | 1474/1932 [3:50:30<1:11:29,  9.37s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▋  | 1475/1932 [3:50:39<1:11:19,  9.36s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▋  | 1476/1932 [3:50:48<1:11:10,  9.37s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▋  | 1477/1932 [3:50:58<1:11:00,  9.36s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 1478/1932 [3:51:07<1:10:50,  9.36s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 1479/1932 [3:51:16<1:10:41,  9.36s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 1480/1932 [3:51:26<1:10:32,  9.36s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1214, 'learning_rate': 4.679089026915114e-05, 'epoch': 2.3}\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 1480/1932 [3:51:26<1:10:32,  9.36s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 1481/1932 [3:51:35<1:10:22,  9.36s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 1482/1932 [3:51:45<1:10:12,  9.36s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 1483/1932 [3:51:54<1:10:03,  9.36s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 1484/1932 [3:52:03<1:09:53,  9.36s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 1485/1932 [3:52:13<1:09:45,  9.36s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 1486/1932 [3:52:22<1:09:37,  9.37s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 1487/1932 [3:52:31<1:09:28,  9.37s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 1488/1932 [3:52:41<1:09:19,  9.37s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 1489/1932 [3:52:50<1:09:09,  9.37s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 1490/1932 [3:52:59<1:09:00,  9.37s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 1490/1932 [3:52:59<1:09:00,  9.37s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1993, 'learning_rate': 4.575569358178054e-05, 'epoch': 2.31}\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 1491/1932 [3:53:09<1:08:52,  9.37s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 1492/1932 [3:53:18<1:08:44,  9.37s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 1493/1932 [3:53:28<1:08:35,  9.37s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 1494/1932 [3:53:37<1:08:26,  9.37s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 1495/1932 [3:53:46<1:08:16,  9.37s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 1496/1932 [3:53:56<1:08:06,  9.37s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 1497/1932 [3:54:05<1:07:57,  9.37s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 1498/1932 [3:54:14<1:07:48,  9.38s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 1499/1932 [3:54:24<1:07:40,  9.38s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 1500/1932 [3:54:33<1:07:32,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.2015, 'learning_rate': 4.472049689440994e-05, 'epoch': 2.33}\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 1500/1932 [3:54:33<1:07:32,  9.38s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 1501/1932 [3:54:43<1:07:23,  9.38s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 1502/1932 [3:54:52<1:07:13,  9.38s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 1503/1932 [3:55:01<1:07:04,  9.38s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 1504/1932 [3:55:11<1:06:54,  9.38s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 1505/1932 [3:55:20<1:06:45,  9.38s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 1506/1932 [3:55:30<1:06:35,  9.38s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 1507/1932 [3:55:39<1:06:27,  9.38s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 1508/1932 [3:55:48<1:06:17,  9.38s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 1509/1932 [3:55:58<1:06:07,  9.38s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 1510/1932 [3:56:07<1:05:59,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1614, 'learning_rate': 4.3685300207039335e-05, 'epoch': 2.34}\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 1510/1932 [3:56:07<1:05:59,  9.38s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 1511/1932 [3:56:16<1:05:50,  9.38s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 1512/1932 [3:56:26<1:05:40,  9.38s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 1513/1932 [3:56:35<1:05:31,  9.38s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 1514/1932 [3:56:45<1:05:21,  9.38s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 1515/1932 [3:56:54<1:05:10,  9.38s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 1516/1932 [3:57:03<1:04:59,  9.37s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 1517/1932 [3:57:13<1:04:49,  9.37s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 1518/1932 [3:57:22<1:04:39,  9.37s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 1519/1932 [3:57:31<1:04:29,  9.37s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 1520/1932 [3:57:41<1:04:19,  9.37s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.0737, 'learning_rate': 4.2650103519668735e-05, 'epoch': 2.36}\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 1520/1932 [3:57:41<1:04:19,  9.37s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 1521/1932 [3:57:50<1:04:10,  9.37s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 1522/1932 [3:58:00<1:04:01,  9.37s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 1523/1932 [3:58:09<1:03:51,  9.37s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 1524/1932 [3:58:18<1:03:41,  9.37s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 1525/1932 [3:58:28<1:03:32,  9.37s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 1526/1932 [3:58:37<1:03:22,  9.37s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 1527/1932 [3:58:46<1:03:14,  9.37s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 1528/1932 [3:58:56<1:03:05,  9.37s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 1529/1932 [3:59:05<1:02:55,  9.37s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 1530/1932 [3:59:14<1:02:46,  9.37s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1449, 'learning_rate': 4.161490683229814e-05, 'epoch': 2.37}\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 1530/1932 [3:59:14<1:02:46,  9.37s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 1531/1932 [3:59:24<1:02:36,  9.37s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 1532/1932 [3:59:33<1:02:27,  9.37s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 1533/1932 [3:59:43<1:02:17,  9.37s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 1534/1932 [3:59:52<1:02:07,  9.37s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 1535/1932 [4:00:01<1:01:57,  9.37s/it]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 1536/1932 [4:00:11<1:01:48,  9.37s/it]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 1537/1932 [4:00:20<1:01:39,  9.37s/it]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 1538/1932 [4:00:29<1:01:29,  9.37s/it]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 1539/1932 [4:00:39<1:01:20,  9.37s/it]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 1540/1932 [4:00:48<1:01:11,  9.37s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1459, 'learning_rate': 4.057971014492754e-05, 'epoch': 2.39}\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 1540/1932 [4:00:48<1:01:11,  9.37s/it]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 1541/1932 [4:00:58<1:01:02,  9.37s/it]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 1542/1932 [4:01:07<1:00:54,  9.37s/it]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 1543/1932 [4:01:16<1:00:45,  9.37s/it]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 1544/1932 [4:01:26<1:00:36,  9.37s/it]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 1545/1932 [4:01:35<1:00:27,  9.37s/it]\u001b[0m\n",
      "\u001b[34m80%|████████  | 1546/1932 [4:01:44<1:00:19,  9.38s/it]\u001b[0m\n",
      "\u001b[34m80%|████████  | 1547/1932 [4:01:54<1:00:09,  9.38s/it]\u001b[0m\n",
      "\u001b[34m80%|████████  | 1548/1932 [4:02:03<1:00:00,  9.38s/it]\u001b[0m\n",
      "\u001b[34m80%|████████  | 1549/1932 [4:02:13<59:51,  9.38s/it]\u001b[0m\n",
      "\u001b[34m80%|████████  | 1550/1932 [4:02:22<59:42,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1593, 'learning_rate': 3.9544513457556935e-05, 'epoch': 2.4}\u001b[0m\n",
      "\u001b[34m80%|████████  | 1550/1932 [4:02:22<59:42,  9.38s/it]\u001b[0m\n",
      "\u001b[34m80%|████████  | 1551/1932 [4:02:31<59:34,  9.38s/it]\u001b[0m\n",
      "\u001b[34m80%|████████  | 1552/1932 [4:02:41<59:24,  9.38s/it]\u001b[0m\n",
      "\u001b[34m80%|████████  | 1553/1932 [4:02:50<59:16,  9.38s/it]\u001b[0m\n",
      "\u001b[34m80%|████████  | 1554/1932 [4:02:59<59:06,  9.38s/it]\u001b[0m\n",
      "\u001b[34m80%|████████  | 1555/1932 [4:03:09<58:57,  9.38s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 1556/1932 [4:03:18<58:47,  9.38s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 1557/1932 [4:03:28<58:38,  9.38s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 1558/1932 [4:03:37<58:29,  9.38s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 1559/1932 [4:03:46<58:20,  9.38s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 1560/1932 [4:03:56<58:10,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.142, 'learning_rate': 3.8509316770186335e-05, 'epoch': 2.42}\u001b[0m\n",
      "\u001b[34m81%|████████  | 1560/1932 [4:03:56<58:10,  9.38s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 1561/1932 [4:04:05<58:01,  9.38s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 1562/1932 [4:04:15<57:51,  9.38s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 1563/1932 [4:04:24<57:42,  9.38s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 1564/1932 [4:04:33<57:33,  9.38s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 1565/1932 [4:04:43<57:23,  9.38s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 1566/1932 [4:04:52<57:15,  9.39s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 1567/1932 [4:05:01<57:06,  9.39s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 1568/1932 [4:05:11<56:57,  9.39s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 1569/1932 [4:05:20<56:48,  9.39s/it]\u001b[0m\n",
      "\u001b[34m81%|████████▏ | 1570/1932 [4:05:30<56:38,  9.39s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.0887, 'learning_rate': 3.747412008281574e-05, 'epoch': 2.44}\u001b[0m\n",
      "\u001b[34m81%|████████▏ | 1570/1932 [4:05:30<56:38,  9.39s/it]\u001b[0m\n",
      "\u001b[34m81%|████████▏ | 1571/1932 [4:05:39<56:28,  9.39s/it]\u001b[0m\n",
      "\u001b[34m81%|████████▏ | 1572/1932 [4:05:48<56:19,  9.39s/it]\u001b[0m\n",
      "\u001b[34m81%|████████▏ | 1573/1932 [4:05:58<56:09,  9.39s/it]\u001b[0m\n",
      "\u001b[34m81%|████████▏ | 1574/1932 [4:06:07<55:59,  9.39s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 1575/1932 [4:06:17<55:51,  9.39s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 1576/1932 [4:06:26<55:42,  9.39s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 1577/1932 [4:06:35<55:32,  9.39s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 1578/1932 [4:06:45<55:23,  9.39s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 1579/1932 [4:06:54<55:14,  9.39s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 1580/1932 [4:07:03<55:04,  9.39s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.173, 'learning_rate': 3.6438923395445135e-05, 'epoch': 2.45}\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 1580/1932 [4:07:03<55:04,  9.39s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 1581/1932 [4:07:13<54:54,  9.39s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 1582/1932 [4:07:22<54:44,  9.38s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 1583/1932 [4:07:32<54:34,  9.38s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 1584/1932 [4:07:41<54:25,  9.38s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 1585/1932 [4:07:50<54:16,  9.38s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 1586/1932 [4:08:00<54:06,  9.38s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 1587/1932 [4:08:09<53:57,  9.38s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 1588/1932 [4:08:19<53:49,  9.39s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 1589/1932 [4:08:28<53:39,  9.39s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 1590/1932 [4:08:37<53:30,  9.39s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1632, 'learning_rate': 3.5403726708074535e-05, 'epoch': 2.47}\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 1590/1932 [4:08:37<53:30,  9.39s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 1591/1932 [4:08:47<53:20,  9.39s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 1592/1932 [4:08:56<53:11,  9.39s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 1593/1932 [4:09:05<53:01,  9.39s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 1594/1932 [4:09:15<52:52,  9.39s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 1595/1932 [4:09:24<52:42,  9.38s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 1596/1932 [4:09:34<52:33,  9.39s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 1597/1932 [4:09:43<52:23,  9.38s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 1598/1932 [4:09:52<52:14,  9.38s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 1599/1932 [4:10:02<52:05,  9.38s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 1600/1932 [4:10:11<51:55,  9.39s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.166, 'learning_rate': 3.4368530020703935e-05, 'epoch': 2.48}\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 1600/1932 [4:10:11<51:55,  9.39s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 1601/1932 [4:10:21<51:46,  9.38s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 1602/1932 [4:10:30<51:36,  9.38s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 1603/1932 [4:10:39<51:26,  9.38s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 1604/1932 [4:10:49<51:15,  9.38s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 1605/1932 [4:10:58<51:05,  9.38s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 1606/1932 [4:11:07<50:55,  9.37s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 1607/1932 [4:11:17<50:46,  9.37s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 1608/1932 [4:11:26<50:36,  9.37s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 1609/1932 [4:11:36<50:27,  9.37s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 1610/1932 [4:11:45<50:17,  9.37s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1535, 'learning_rate': 3.3333333333333335e-05, 'epoch': 2.5}\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 1610/1932 [4:11:45<50:17,  9.37s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 1611/1932 [4:11:54<50:08,  9.37s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 1612/1932 [4:12:04<49:58,  9.37s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 1613/1932 [4:12:13<49:48,  9.37s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▎ | 1614/1932 [4:12:22<49:38,  9.37s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▎ | 1615/1932 [4:12:32<49:29,  9.37s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▎ | 1616/1932 [4:12:41<49:19,  9.36s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▎ | 1617/1932 [4:12:50<49:10,  9.37s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▎ | 1618/1932 [4:13:00<49:00,  9.37s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 1619/1932 [4:13:09<48:51,  9.37s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 1620/1932 [4:13:19<48:42,  9.37s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1318, 'learning_rate': 3.2298136645962735e-05, 'epoch': 2.51}\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 1620/1932 [4:13:19<48:42,  9.37s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 1621/1932 [4:13:28<48:33,  9.37s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 1622/1932 [4:13:37<48:24,  9.37s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 1623/1932 [4:13:47<48:15,  9.37s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 1624/1932 [4:13:56<48:05,  9.37s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 1625/1932 [4:14:05<47:56,  9.37s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 1626/1932 [4:14:15<47:46,  9.37s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 1627/1932 [4:14:24<47:37,  9.37s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 1628/1932 [4:14:34<47:27,  9.37s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 1629/1932 [4:14:43<47:17,  9.37s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 1630/1932 [4:14:52<47:08,  9.36s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1241, 'learning_rate': 3.1262939958592135e-05, 'epoch': 2.53}\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 1630/1932 [4:14:52<47:08,  9.36s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 1631/1932 [4:15:02<46:58,  9.36s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 1632/1932 [4:15:11<46:49,  9.36s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 1633/1932 [4:15:20<46:39,  9.36s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 1634/1932 [4:15:30<46:30,  9.36s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 1635/1932 [4:15:39<46:21,  9.36s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 1636/1932 [4:15:48<46:11,  9.36s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 1637/1932 [4:15:58<46:02,  9.36s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 1638/1932 [4:16:07<45:52,  9.36s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 1639/1932 [4:16:17<45:44,  9.37s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 1640/1932 [4:16:26<45:34,  9.36s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1653, 'learning_rate': 3.022774327122153e-05, 'epoch': 2.54}\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 1640/1932 [4:16:26<45:34,  9.36s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 1641/1932 [4:16:35<45:25,  9.37s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 1642/1932 [4:16:45<45:16,  9.37s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 1643/1932 [4:16:54<45:07,  9.37s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 1644/1932 [4:17:03<44:58,  9.37s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 1645/1932 [4:17:13<44:50,  9.37s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 1646/1932 [4:17:22<44:41,  9.37s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 1647/1932 [4:17:31<44:30,  9.37s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 1648/1932 [4:17:41<44:20,  9.37s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 1649/1932 [4:17:50<44:10,  9.37s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 1650/1932 [4:18:00<44:00,  9.36s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1825, 'learning_rate': 2.919254658385093e-05, 'epoch': 2.56}\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 1650/1932 [4:18:00<44:00,  9.36s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 1651/1932 [4:18:09<43:50,  9.36s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 1652/1932 [4:18:18<43:41,  9.36s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 1653/1932 [4:18:28<43:31,  9.36s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 1654/1932 [4:18:37<43:22,  9.36s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 1655/1932 [4:18:46<43:13,  9.36s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 1656/1932 [4:18:56<43:03,  9.36s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 1657/1932 [4:19:05<42:54,  9.36s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 1658/1932 [4:19:14<42:45,  9.36s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 1659/1932 [4:19:24<42:35,  9.36s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 1660/1932 [4:19:33<42:26,  9.36s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1529, 'learning_rate': 2.8157349896480335e-05, 'epoch': 2.58}\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 1660/1932 [4:19:33<42:26,  9.36s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 1661/1932 [4:19:43<42:16,  9.36s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 1662/1932 [4:19:52<42:07,  9.36s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 1663/1932 [4:20:01<41:57,  9.36s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 1664/1932 [4:20:11<41:48,  9.36s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 1665/1932 [4:20:20<41:39,  9.36s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 1666/1932 [4:20:29<41:30,  9.36s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▋ | 1667/1932 [4:20:39<41:21,  9.36s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▋ | 1668/1932 [4:20:48<41:12,  9.36s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▋ | 1669/1932 [4:20:57<41:02,  9.36s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▋ | 1670/1932 [4:21:07<40:52,  9.36s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1387, 'learning_rate': 2.7122153209109728e-05, 'epoch': 2.59}\u001b[0m\n",
      "\u001b[34m86%|████████▋ | 1670/1932 [4:21:07<40:52,  9.36s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▋ | 1671/1932 [4:21:16<40:43,  9.36s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 1672/1932 [4:21:26<40:33,  9.36s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 1673/1932 [4:21:35<40:24,  9.36s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 1674/1932 [4:21:44<40:14,  9.36s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 1675/1932 [4:21:54<40:04,  9.36s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 1676/1932 [4:22:03<39:54,  9.36s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 1677/1932 [4:22:12<39:45,  9.36s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 1678/1932 [4:22:22<39:36,  9.36s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 1679/1932 [4:22:31<39:27,  9.36s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 1680/1932 [4:22:40<39:17,  9.36s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.0997, 'learning_rate': 2.608695652173913e-05, 'epoch': 2.61}\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 1680/1932 [4:22:40<39:17,  9.36s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 1681/1932 [4:22:50<39:09,  9.36s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 1682/1932 [4:22:59<38:59,  9.36s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 1683/1932 [4:23:08<38:49,  9.36s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 1684/1932 [4:23:18<38:40,  9.36s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 1685/1932 [4:23:27<38:31,  9.36s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 1686/1932 [4:23:37<38:22,  9.36s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 1687/1932 [4:23:46<38:13,  9.36s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 1688/1932 [4:23:55<38:03,  9.36s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 1689/1932 [4:24:05<37:54,  9.36s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 1690/1932 [4:24:14<37:45,  9.36s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1061, 'learning_rate': 2.505175983436853e-05, 'epoch': 2.62}\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 1690/1932 [4:24:14<37:45,  9.36s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 1691/1932 [4:24:23<37:36,  9.36s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 1692/1932 [4:24:33<37:26,  9.36s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 1693/1932 [4:24:42<37:17,  9.36s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 1694/1932 [4:24:51<37:08,  9.36s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 1695/1932 [4:25:01<36:58,  9.36s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 1696/1932 [4:25:10<36:49,  9.36s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 1697/1932 [4:25:20<36:40,  9.36s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 1698/1932 [4:25:29<36:31,  9.36s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 1699/1932 [4:25:38<36:22,  9.37s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 1700/1932 [4:25:48<36:13,  9.37s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.142, 'learning_rate': 2.401656314699793e-05, 'epoch': 2.64}\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 1700/1932 [4:25:48<36:13,  9.37s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 1701/1932 [4:25:57<36:03,  9.37s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 1702/1932 [4:26:06<35:53,  9.36s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 1703/1932 [4:26:16<35:44,  9.36s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 1704/1932 [4:26:25<35:35,  9.36s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 1705/1932 [4:26:34<35:25,  9.36s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 1706/1932 [4:26:44<35:16,  9.36s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 1707/1932 [4:26:53<35:07,  9.36s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 1708/1932 [4:27:03<34:57,  9.36s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 1709/1932 [4:27:12<34:48,  9.36s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▊ | 1710/1932 [4:27:21<34:39,  9.36s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1413, 'learning_rate': 2.2981366459627328e-05, 'epoch': 2.65}\u001b[0m\n",
      "\u001b[34m89%|████████▊ | 1710/1932 [4:27:21<34:39,  9.36s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▊ | 1711/1932 [4:27:31<34:29,  9.36s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▊ | 1712/1932 [4:27:40<34:19,  9.36s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▊ | 1713/1932 [4:27:49<34:09,  9.36s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▊ | 1714/1932 [4:27:59<34:00,  9.36s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 1715/1932 [4:28:08<33:50,  9.36s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 1716/1932 [4:28:17<33:41,  9.36s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 1717/1932 [4:28:27<33:32,  9.36s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 1718/1932 [4:28:36<33:23,  9.36s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 1719/1932 [4:28:46<33:13,  9.36s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 1720/1932 [4:28:55<33:04,  9.36s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1509, 'learning_rate': 2.194616977225673e-05, 'epoch': 2.67}\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 1720/1932 [4:28:55<33:04,  9.36s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 1721/1932 [4:29:04<32:55,  9.36s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 1722/1932 [4:29:14<32:46,  9.36s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 1723/1932 [4:29:23<32:37,  9.36s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 1724/1932 [4:29:32<32:27,  9.36s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 1725/1932 [4:29:42<32:18,  9.37s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 1726/1932 [4:29:51<32:09,  9.37s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 1727/1932 [4:30:00<31:59,  9.37s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 1728/1932 [4:30:10<31:50,  9.37s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 1729/1932 [4:30:19<31:41,  9.37s/it]\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 1730/1932 [4:30:29<31:32,  9.37s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1338, 'learning_rate': 2.0910973084886128e-05, 'epoch': 2.68}\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 1730/1932 [4:30:29<31:32,  9.37s/it]\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 1731/1932 [4:30:38<31:23,  9.37s/it]\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 1732/1932 [4:30:47<31:13,  9.37s/it]\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 1733/1932 [4:30:57<31:04,  9.37s/it]\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 1734/1932 [4:31:06<30:56,  9.37s/it]\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 1735/1932 [4:31:15<30:47,  9.38s/it]\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 1736/1932 [4:31:25<30:37,  9.38s/it]\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 1737/1932 [4:31:34<30:28,  9.38s/it]\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 1738/1932 [4:31:44<30:18,  9.37s/it]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 1739/1932 [4:31:53<30:08,  9.37s/it]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 1740/1932 [4:32:02<29:58,  9.37s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.133, 'learning_rate': 1.9875776397515528e-05, 'epoch': 2.7}\u001b[0m\n",
      "\u001b[34m90%|█████████ | 1740/1932 [4:32:02<29:58,  9.37s/it]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 1741/1932 [4:32:12<29:48,  9.37s/it]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 1742/1932 [4:32:21<29:39,  9.37s/it]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 1743/1932 [4:32:30<29:29,  9.36s/it]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 1744/1932 [4:32:40<29:20,  9.36s/it]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 1745/1932 [4:32:49<29:10,  9.36s/it]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 1746/1932 [4:32:58<29:01,  9.36s/it]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 1747/1932 [4:33:08<28:52,  9.36s/it]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 1748/1932 [4:33:17<28:42,  9.36s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 1749/1932 [4:33:27<28:33,  9.36s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 1750/1932 [4:33:36<28:24,  9.36s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1365, 'learning_rate': 1.8840579710144928e-05, 'epoch': 2.72}\u001b[0m\n",
      "\u001b[34m91%|█████████ | 1750/1932 [4:33:36<28:24,  9.36s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 1751/1932 [4:33:45<28:14,  9.36s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 1752/1932 [4:33:55<28:05,  9.37s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 1753/1932 [4:34:04<27:56,  9.36s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 1754/1932 [4:34:13<27:46,  9.36s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 1755/1932 [4:34:23<27:37,  9.37s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 1756/1932 [4:34:32<27:28,  9.37s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 1757/1932 [4:34:41<27:18,  9.37s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 1758/1932 [4:34:51<27:09,  9.37s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 1759/1932 [4:35:00<27:00,  9.37s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 1760/1932 [4:35:10<26:50,  9.37s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1381, 'learning_rate': 1.7805383022774328e-05, 'epoch': 2.73}\u001b[0m\n",
      "\u001b[34m91%|█████████ | 1760/1932 [4:35:10<26:50,  9.37s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 1761/1932 [4:35:19<26:41,  9.37s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 1762/1932 [4:35:28<26:32,  9.37s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████▏| 1763/1932 [4:35:38<26:22,  9.36s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████▏| 1764/1932 [4:35:47<26:12,  9.36s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████▏| 1765/1932 [4:35:56<26:03,  9.36s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████▏| 1766/1932 [4:36:06<25:54,  9.36s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████▏| 1767/1932 [4:36:15<25:45,  9.37s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 1768/1932 [4:36:24<25:35,  9.36s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 1769/1932 [4:36:34<25:26,  9.36s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 1770/1932 [4:36:43<25:16,  9.36s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1366, 'learning_rate': 1.6770186335403728e-05, 'epoch': 2.75}\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 1770/1932 [4:36:43<25:16,  9.36s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 1771/1932 [4:36:53<25:07,  9.36s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 1772/1932 [4:37:02<24:58,  9.36s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 1773/1932 [4:37:11<24:48,  9.36s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 1774/1932 [4:37:21<24:39,  9.36s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 1775/1932 [4:37:30<24:30,  9.36s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 1776/1932 [4:37:39<24:20,  9.36s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 1777/1932 [4:37:49<24:11,  9.37s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 1778/1932 [4:37:58<24:02,  9.37s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 1779/1932 [4:38:07<23:52,  9.37s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 1780/1932 [4:38:17<23:43,  9.36s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1529, 'learning_rate': 1.5734989648033128e-05, 'epoch': 2.76}\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 1780/1932 [4:38:17<23:43,  9.36s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 1781/1932 [4:38:26<23:33,  9.36s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 1782/1932 [4:38:36<23:23,  9.36s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 1783/1932 [4:38:45<23:14,  9.36s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 1784/1932 [4:38:54<23:04,  9.36s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 1785/1932 [4:39:04<22:55,  9.36s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 1786/1932 [4:39:13<22:46,  9.36s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 1787/1932 [4:39:22<22:37,  9.36s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1788/1932 [4:39:32<22:27,  9.36s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1789/1932 [4:39:41<22:18,  9.36s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1790/1932 [4:39:50<22:09,  9.36s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.0931, 'learning_rate': 1.4699792960662526e-05, 'epoch': 2.78}\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1790/1932 [4:39:50<22:09,  9.36s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1791/1932 [4:40:00<21:59,  9.36s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1792/1932 [4:40:09<21:50,  9.36s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1793/1932 [4:40:18<21:41,  9.36s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1794/1932 [4:40:28<21:32,  9.37s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1795/1932 [4:40:37<21:23,  9.37s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1796/1932 [4:40:47<21:14,  9.37s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1797/1932 [4:40:56<21:05,  9.37s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1798/1932 [4:41:05<20:56,  9.37s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1799/1932 [4:41:15<20:46,  9.37s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1800/1932 [4:41:24<20:37,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1223, 'learning_rate': 1.3664596273291926e-05, 'epoch': 2.79}\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1800/1932 [4:41:24<20:37,  9.38s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1801/1932 [4:41:34<20:28,  9.38s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1802/1932 [4:41:43<20:19,  9.38s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1803/1932 [4:41:52<20:09,  9.38s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1804/1932 [4:42:02<20:00,  9.38s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1805/1932 [4:42:11<19:51,  9.38s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1806/1932 [4:42:20<19:41,  9.38s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▎| 1807/1932 [4:42:30<19:31,  9.38s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▎| 1808/1932 [4:42:39<19:22,  9.37s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▎| 1809/1932 [4:42:49<19:13,  9.38s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▎| 1810/1932 [4:42:58<19:03,  9.37s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1791, 'learning_rate': 1.2629399585921325e-05, 'epoch': 2.81}\u001b[0m\n",
      "\u001b[34m94%|█████████▎| 1810/1932 [4:42:58<19:03,  9.37s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▎| 1811/1932 [4:43:07<18:54,  9.37s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 1812/1932 [4:43:17<18:44,  9.37s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 1813/1932 [4:43:26<18:35,  9.37s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 1814/1932 [4:43:35<18:26,  9.37s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 1815/1932 [4:43:45<18:16,  9.38s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 1816/1932 [4:43:54<18:07,  9.37s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 1817/1932 [4:44:04<17:58,  9.38s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 1818/1932 [4:44:13<17:48,  9.38s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 1819/1932 [4:44:22<17:39,  9.38s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 1820/1932 [4:44:32<17:30,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1115, 'learning_rate': 1.1594202898550725e-05, 'epoch': 2.82}\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 1820/1932 [4:44:32<17:30,  9.38s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 1821/1932 [4:44:41<17:21,  9.38s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 1822/1932 [4:44:50<17:11,  9.38s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 1823/1932 [4:45:00<17:02,  9.38s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 1824/1932 [4:45:09<16:52,  9.38s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 1825/1932 [4:45:19<16:42,  9.37s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 1826/1932 [4:45:28<16:33,  9.37s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 1827/1932 [4:45:37<16:23,  9.37s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 1828/1932 [4:45:47<16:14,  9.37s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 1829/1932 [4:45:56<16:04,  9.37s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 1830/1932 [4:46:05<15:55,  9.36s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1464, 'learning_rate': 1.0559006211180125e-05, 'epoch': 2.84}\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 1830/1932 [4:46:05<15:55,  9.36s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 1831/1932 [4:46:15<15:45,  9.37s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 1832/1932 [4:46:24<15:36,  9.36s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 1833/1932 [4:46:33<15:27,  9.37s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 1834/1932 [4:46:43<15:17,  9.36s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 1835/1932 [4:46:52<15:08,  9.36s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 1836/1932 [4:47:02<14:58,  9.36s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 1837/1932 [4:47:11<14:49,  9.36s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 1838/1932 [4:47:20<14:40,  9.37s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 1839/1932 [4:47:30<14:30,  9.37s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 1840/1932 [4:47:39<14:21,  9.37s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1668, 'learning_rate': 9.523809523809523e-06, 'epoch': 2.85}\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 1840/1932 [4:47:39<14:21,  9.37s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 1841/1932 [4:47:48<14:12,  9.37s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 1842/1932 [4:47:58<14:03,  9.37s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 1843/1932 [4:48:07<13:53,  9.37s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 1844/1932 [4:48:16<13:44,  9.37s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 1845/1932 [4:48:26<13:35,  9.37s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 1846/1932 [4:48:35<13:26,  9.37s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 1847/1932 [4:48:45<13:16,  9.38s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 1848/1932 [4:48:54<13:07,  9.38s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 1849/1932 [4:49:03<12:58,  9.38s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 1850/1932 [4:49:13<12:49,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1773, 'learning_rate': 8.488612836438923e-06, 'epoch': 2.87}\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 1850/1932 [4:49:13<12:49,  9.38s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 1851/1932 [4:49:22<12:39,  9.38s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 1852/1932 [4:49:32<12:30,  9.38s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 1853/1932 [4:49:41<12:21,  9.38s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 1854/1932 [4:49:50<12:11,  9.38s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 1855/1932 [4:50:00<12:02,  9.38s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 1856/1932 [4:50:09<11:53,  9.38s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 1857/1932 [4:50:18<11:43,  9.38s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 1858/1932 [4:50:28<11:34,  9.38s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 1859/1932 [4:50:37<11:24,  9.38s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▋| 1860/1932 [4:50:47<11:15,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1265, 'learning_rate': 7.453416149068324e-06, 'epoch': 2.89}\u001b[0m\n",
      "\u001b[34m96%|█████████▋| 1860/1932 [4:50:47<11:15,  9.38s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▋| 1861/1932 [4:50:56<11:06,  9.38s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▋| 1862/1932 [4:51:05<10:56,  9.38s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▋| 1863/1932 [4:51:15<10:47,  9.39s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▋| 1864/1932 [4:51:24<10:38,  9.39s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1865/1932 [4:51:34<10:28,  9.38s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1866/1932 [4:51:43<10:19,  9.38s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1867/1932 [4:51:52<10:10,  9.39s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1868/1932 [4:52:02<10:00,  9.39s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1869/1932 [4:52:11<09:51,  9.39s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1870/1932 [4:52:20<09:41,  9.39s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1246, 'learning_rate': 6.418219461697723e-06, 'epoch': 2.9}\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1870/1932 [4:52:20<09:41,  9.39s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1871/1932 [4:52:30<09:32,  9.38s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1872/1932 [4:52:39<09:23,  9.38s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1873/1932 [4:52:49<09:13,  9.39s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1874/1932 [4:52:58<09:04,  9.39s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1875/1932 [4:53:07<08:55,  9.39s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1876/1932 [4:53:17<08:45,  9.39s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1877/1932 [4:53:26<08:36,  9.39s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1878/1932 [4:53:36<08:26,  9.38s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1879/1932 [4:53:45<08:17,  9.38s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1880/1932 [4:53:54<08:08,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.0937, 'learning_rate': 5.383022774327122e-06, 'epoch': 2.92}\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1880/1932 [4:53:54<08:08,  9.38s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1881/1932 [4:54:04<07:58,  9.38s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1882/1932 [4:54:13<07:49,  9.38s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1883/1932 [4:54:22<07:39,  9.39s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1884/1932 [4:54:32<07:30,  9.39s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1885/1932 [4:54:41<07:21,  9.39s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1886/1932 [4:54:51<07:11,  9.39s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1887/1932 [4:55:00<07:02,  9.39s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1888/1932 [4:55:09<06:53,  9.39s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1889/1932 [4:55:19<06:43,  9.39s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1890/1932 [4:55:28<06:34,  9.39s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1373, 'learning_rate': 4.347826086956522e-06, 'epoch': 2.93}\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1890/1932 [4:55:28<06:34,  9.39s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1891/1932 [4:55:38<06:24,  9.39s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1892/1932 [4:55:47<06:15,  9.39s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1893/1932 [4:55:56<06:06,  9.39s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1894/1932 [4:56:06<05:56,  9.39s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1895/1932 [4:56:15<05:47,  9.39s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1896/1932 [4:56:25<05:37,  9.39s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1897/1932 [4:56:34<05:28,  9.39s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1898/1932 [4:56:43<05:19,  9.39s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1899/1932 [4:56:53<05:09,  9.39s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1900/1932 [4:57:02<05:00,  9.39s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1159, 'learning_rate': 3.3126293995859218e-06, 'epoch': 2.95}\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1900/1932 [4:57:02<05:00,  9.39s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1901/1932 [4:57:11<04:51,  9.39s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1902/1932 [4:57:21<04:41,  9.39s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1903/1932 [4:57:30<04:32,  9.39s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▊| 1904/1932 [4:57:40<04:22,  9.39s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▊| 1905/1932 [4:57:49<04:13,  9.39s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▊| 1906/1932 [4:57:58<04:04,  9.39s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▊| 1907/1932 [4:58:08<03:54,  9.39s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 1908/1932 [4:58:17<03:45,  9.39s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 1909/1932 [4:58:27<03:35,  9.39s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 1910/1932 [4:58:36<03:26,  9.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1283, 'learning_rate': 2.277432712215321e-06, 'epoch': 2.96}\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 1910/1932 [4:58:36<03:26,  9.38s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 1911/1932 [4:58:45<03:17,  9.38s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 1912/1932 [4:58:55<03:07,  9.39s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 1913/1932 [4:59:04<02:58,  9.39s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 1914/1932 [4:59:13<02:48,  9.39s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 1915/1932 [4:59:23<02:39,  9.39s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 1916/1932 [4:59:32<02:30,  9.39s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 1917/1932 [4:59:42<02:20,  9.39s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 1918/1932 [4:59:51<02:11,  9.39s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 1919/1932 [5:00:00<02:02,  9.39s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 1920/1932 [5:00:10<01:52,  9.39s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1308, 'learning_rate': 1.2422360248447205e-06, 'epoch': 2.98}\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 1920/1932 [5:00:10<01:52,  9.39s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 1921/1932 [5:00:19<01:43,  9.39s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 1922/1932 [5:00:29<01:33,  9.39s/it]\u001b[0m\n",
      "\u001b[34m100%|█████████▉| 1923/1932 [5:00:38<01:24,  9.39s/it]\u001b[0m\n",
      "\u001b[34m100%|█████████▉| 1924/1932 [5:00:47<01:15,  9.39s/it]\u001b[0m\n",
      "\u001b[34m100%|█████████▉| 1925/1932 [5:00:57<01:05,  9.39s/it]\u001b[0m\n",
      "\u001b[34m100%|█████████▉| 1926/1932 [5:01:06<00:56,  9.39s/it]\u001b[0m\n",
      "\u001b[34m100%|█████████▉| 1927/1932 [5:01:16<00:46,  9.39s/it]\u001b[0m\n",
      "\u001b[34m100%|█████████▉| 1928/1932 [5:01:25<00:37,  9.39s/it]\u001b[0m\n",
      "\u001b[34m100%|█████████▉| 1929/1932 [5:01:34<00:28,  9.39s/it]\u001b[0m\n",
      "\u001b[34m100%|█████████▉| 1930/1932 [5:01:44<00:18,  9.39s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.1539, 'learning_rate': 2.070393374741201e-07, 'epoch': 2.99}\u001b[0m\n",
      "\u001b[34m100%|█████████▉| 1930/1932 [5:01:44<00:18,  9.39s/it]\u001b[0m\n",
      "\u001b[34m100%|█████████▉| 1931/1932 [5:01:53<00:09,  9.39s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 1932/1932 [5:02:02<00:00,  9.39s/it]\u001b[0m\n",
      "\u001b[34m{'train_runtime': 18122.9584, 'train_samples_per_second': 0.213, 'train_steps_per_second': 0.107, 'train_loss': 2.1994019188989515, 'epoch': 3.0}\u001b[0m\n",
      "\u001b[34m100%|██████████| 1932/1932 [5:02:02<00:00,  9.39s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 1932/1932 [5:02:02<00:00,  9.38s/it]\u001b[0m\n",
      "\u001b[34mDownloading (…)okenizer_config.json:   0%|          | 0.00/223 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)okenizer_config.json: 100%|██████████| 223/223 [00:00<00:00, 38.6kB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"tokenizer.json\";:   0%|          | 0.00/14.5M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)\"tokenizer.json\";: 100%|██████████| 14.5M/14.5M [00:00<00:00, 217MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)cial_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)cial_tokens_map.json: 100%|██████████| 85.0/85.0 [00:00<00:00, 51.6kB/s]\u001b[0m\n",
      "\u001b[34m2023-08-09 07:48:32,944 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-08-09 07:48:32,944 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-08-09 07:48:32,944 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2023-08-09 07:48:38 Uploading - Uploading generated training model\n",
      "2023-08-09 08:03:05 Completed - Training job completed\n",
      "Training seconds: 20327\n",
      "Billable seconds: 20327\n"
     ]
    }
   ],
   "source": [
    "# define a data input dictionary with our uploaded s3 uris\n",
    "training_input_path = \"s3://sagemaker-ap-south-1-179750807597/processed/samsum-sagemaker/train\"\n",
    "data = {'training': training_input_path}\n",
    "\n",
    "# starting the train job with our uploaded datasets as inputs\n",
    "huggingface_estimator.fit(data, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3ed1b8ea-640d-4b05-a7d9-9687e86d082d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "# 1. create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "   model_data=huggingface_estimator.model_data,\n",
    "   #model_data=\"s3://hf-sagemaker-inference/model.tar.gz\",  # Change to your model path\n",
    "   role=role, \n",
    "   transformers_version=\"4.26\", \n",
    "   pytorch_version=\"1.13\", \n",
    "   py_version=\"py39\",\n",
    "   model_server_workers=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5348d55-558e-492f-9bf6-b335c2c33dfd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'huggingface_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m predictor \u001b[38;5;241m=\u001b[39m \u001b[43mhuggingface_model\u001b[49m\u001b[38;5;241m.\u001b[39mdeploy(\n\u001b[1;32m      2\u001b[0m    initial_instance_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m      3\u001b[0m    instance_type\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mml.g5.4xlarge\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'huggingface_model' is not defined"
     ]
    }
   ],
   "source": [
    "predictor = huggingface_model.deploy(\n",
    "   initial_instance_count=1,\n",
    "   instance_type= \"ml.g5.4xlarge\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7655932f-12d9-4c73-b969-fabc0092d614",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Don: Hi Cindy. Have you made all arrangements?\n",
      "Cindy: It's about today's meeting or your trip next week?\n",
      "Don: Both, I suppose:)\n",
      "Cindy: You have meeting with management board today at 2 pm.\n",
      "Don: Where did you set it up?\n",
      "Cindy: In our conference room.\n",
      "Cindy: Catering will bring some tea, coffee and snacks.\n",
      "Don: That's good.\n",
      "Don: Did everybody got the agenda?\n",
      "Cindy: Yep.\n",
      "Don: How did Andy react when he saw it?\n",
      "Cindy: Can't say, really. Not sure if he even read it.\n",
      "Don: That's Andy all right.\n",
      "Don: And how about the trip.\n",
      "Cindy: I've got your plane tickets and booked the hotel.\n",
      "Don: Which one?\n",
      "Cindy: Hilton, as usual.\n",
      "Don: Perfect:=)\n",
      "Cindy: But nobody is gonna pick you up at the airport. You'll have to get a cab.\n",
      "Don: I think, I can manage that;=)\n",
      "Don: Good job, Cindy. No idea, where I'd be without you.\n",
      "\n",
      "Andy didn't read the agenda, so Cindy hasn't been able to tell him that a meeting with management board is scheduled for 2 pm. Andy will have a meeting with management board today. He will meet Cindy at Hilton hotel next week. Don will have to get a cab to pick him up from the airport. \n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "from datasets import load_dataset\n",
    "\n",
    "# 1. Load dataset from the hub\n",
    "test_dataset = load_dataset(\"samsum\", split=\"test\")\n",
    "\n",
    "# 2. select a random test sample\n",
    "sample = test_dataset[randint(0,len(test_dataset))]\n",
    "print(sample[\"dialogue\"])\n",
    "# 3. format the sample\n",
    "prompt_template = f\"Summarize the chat dialogue:\\n{{dialogue}}\\n---\\nSummary:\\n\"\n",
    "\n",
    "fomatted_sample = {\n",
    "  \"inputs\": prompt_template.format(dialogue=sample[\"dialogue\"]),\n",
    "  \"parameters\": {\n",
    "    \"do_sample\": True, # sample output predicted probabilities\n",
    "    \"top_p\": 0.9, # sampling technique Fan et. al (2018)\n",
    "    \"temperature\": 0.9, # increasing the likelihood of high probability words and decreasing the likelihood of low probability words\n",
    "    \"max_new_tokens\": 100, # \n",
    "  }\n",
    "}\n",
    "\n",
    "# 4. Invoke the SageMaker endpoint with the formatted sample\n",
    "res = predictor.predict(fomatted_sample)\n",
    "\n",
    "\n",
    "# 5. Print the model output\n",
    "print(res[0][\"generated_text\"].split(\"Summary:\")[-1])\n",
    "# Sample model output: Kirsten and Alex are going bowling this Friday at 7 pm. They will meet up and then go together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e16a001-2e9c-4aed-8ea9-16357fa4967a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpredictor\u001b[49m\u001b[38;5;241m.\u001b[39mdelete_model()\n\u001b[1;32m      2\u001b[0m predictor\u001b[38;5;241m.\u001b[39mdelete_endpoint()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predictor' is not defined"
     ]
    }
   ],
   "source": [
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84061534-7827-4ef2-93f9-c18e75a9413e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
